{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the basic libraries for implementation of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_set= pd.read_csv('./../Data/addition_dataset_2.csv')\n",
    "d_set.head()\n",
    "dset_features=d_set.copy()\n",
    "dset_labels=dset_features.pop('result')\n",
    "dset_features=np.array(dset_features)\n",
    "dset_model_Perceptron = tf.keras.Sequential([\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "dset_model_Perceptron.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.0000e+00 - loss: 350533920.0000 - val_accuracy: 0.0000e+00 - val_loss: 608271168.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.0000e+00 - loss: 120116080.0000 - val_accuracy: 0.0000e+00 - val_loss: 166104208.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 2.7539e-05 - loss: 31193032.0000 - val_accuracy: 0.0000e+00 - val_loss: 29711542.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 8.9453e-06 - loss: 5138413.5000 - val_accuracy: 0.0000e+00 - val_loss: 2926171.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 6.7295e-05 - loss: 441108.1250 - val_accuracy: 0.0000e+00 - val_loss: 131091.7656\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 3.4522e-06 - loss: 17354.0273 - val_accuracy: 0.0000e+00 - val_loss: 2161.1516\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 6.2757e-06 - loss: 245.1099 - val_accuracy: 0.0000e+00 - val_loss: 12.0356\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 2.8122e-05 - loss: 1.0215 - val_accuracy: 0.0000e+00 - val_loss: 0.3035\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 9.6648e-05 - loss: 0.0910 - val_accuracy: 0.0000e+00 - val_loss: 0.1964\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 4.6360e-05 - loss: 0.0876 - val_accuracy: 0.0000e+00 - val_loss: 0.1829\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 1.5445e-05 - loss: 0.0878 - val_accuracy: 0.0000e+00 - val_loss: 0.1756\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 6.9529e-05 - loss: 0.0883 - val_accuracy: 0.0000e+00 - val_loss: 0.1668\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 8.3495e-05 - loss: 0.0883 - val_accuracy: 0.0000e+00 - val_loss: 0.1620\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 2.4151e-05 - loss: 0.0884 - val_accuracy: 0.0000e+00 - val_loss: 0.1752\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 1.1811e-04 - loss: 0.0875 - val_accuracy: 0.0000e+00 - val_loss: 0.1734\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 8.0260e-05 - loss: 0.0870 - val_accuracy: 0.0000e+00 - val_loss: 0.1774\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 2.1462e-05 - loss: 0.0883 - val_accuracy: 0.0000e+00 - val_loss: 0.1765\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 8.7918e-05 - loss: 0.0872 - val_accuracy: 0.0000e+00 - val_loss: 0.1652\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 1.2697e-04 - loss: 0.0879 - val_accuracy: 0.0000e+00 - val_loss: 0.1682\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 2.4093e-06 - loss: 0.0876 - val_accuracy: 0.0000e+00 - val_loss: 0.1637\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 4.4049e-05 - loss: 0.0865 - val_accuracy: 0.0000e+00 - val_loss: 0.1482\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 3.0591e-06 - loss: 0.0865 - val_accuracy: 0.0000e+00 - val_loss: 0.1766\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 2.5388e-06 - loss: 0.0870 - val_accuracy: 0.0000e+00 - val_loss: 0.1868\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 3.1899e-06 - loss: 0.0857 - val_accuracy: 0.0000e+00 - val_loss: 0.1374\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 9.2331e-06 - loss: 0.0853 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 1.7263e-04 - loss: 0.0854 - val_accuracy: 0.0000e+00 - val_loss: 0.1777\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 5.6875e-05 - loss: 0.0842 - val_accuracy: 0.0000e+00 - val_loss: 0.2084\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 6.5492e-05 - loss: 0.0825 - val_accuracy: 0.0000e+00 - val_loss: 0.1494\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 7.5078e-05 - loss: 0.0819 - val_accuracy: 0.0000e+00 - val_loss: 0.1574\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 8.2554e-05 - loss: 0.0789 - val_accuracy: 0.0000e+00 - val_loss: 0.1576\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 9.3786e-05 - loss: 0.0790 - val_accuracy: 0.0000e+00 - val_loss: 0.1276\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 1.2989e-04 - loss: 0.0758 - val_accuracy: 0.0000e+00 - val_loss: 0.2368\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 4.7681e-05 - loss: 0.0731 - val_accuracy: 0.0000e+00 - val_loss: 0.0713\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 1.4701e-04 - loss: 0.0687 - val_accuracy: 0.0000e+00 - val_loss: 0.2426\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 1.7552e-05 - loss: 0.0651 - val_accuracy: 0.0000e+00 - val_loss: 0.1391\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 8.2088e-05 - loss: 0.0639 - val_accuracy: 0.0000e+00 - val_loss: 0.0605\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 4.1337e-05 - loss: 0.0544 - val_accuracy: 0.0000e+00 - val_loss: 0.0432\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 1.4028e-05 - loss: 0.0478 - val_accuracy: 0.0000e+00 - val_loss: 0.0364\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 8.3737e-06 - loss: 0.0399 - val_accuracy: 0.0000e+00 - val_loss: 0.1497\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 4.7415e-05 - loss: 0.0455 - val_accuracy: 0.0000e+00 - val_loss: 0.1083\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 7.3846e-05 - loss: 0.0458 - val_accuracy: 0.0000e+00 - val_loss: 0.1899\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 1.6344e-04 - loss: 0.3228 - val_accuracy: 0.0000e+00 - val_loss: 0.0187\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 2.0764e-05 - loss: 2.5994 - val_accuracy: 0.0000e+00 - val_loss: 0.0249\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 4.1821e-05 - loss: 0.0078 - val_accuracy: 0.0000e+00 - val_loss: 5.2778e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 1.4319e-04 - loss: 0.0064 - val_accuracy: 0.0000e+00 - val_loss: 0.0984\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 4.2065e-05 - loss: 0.4033 - val_accuracy: 0.0000e+00 - val_loss: 7.0364e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 3.2363e-05 - loss: 0.5995 - val_accuracy: 0.0000e+00 - val_loss: 0.0059\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 1.7887e-04 - loss: 0.3461 - val_accuracy: 0.0000e+00 - val_loss: 3.1136e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 1.6409e-05 - loss: 0.2008 - val_accuracy: 0.0000e+00 - val_loss: 0.2415\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 2.2882e-05 - loss: 0.4650 - val_accuracy: 0.0000e+00 - val_loss: 0.3045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27dff9a8590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_Perceptron.fit(dset_features, dset_labels, epochs=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.034064 ],\n",
       "       [ 3.0340316],\n",
       "       [ 5.0339994],\n",
       "       [ 7.033967 ],\n",
       "       [ 9.033935 ],\n",
       "       [11.033901 ],\n",
       "       [13.03387  ],\n",
       "       [15.033837 ],\n",
       "       [17.033804 ],\n",
       "       [19.033772 ],\n",
       "       [21.03374  ],\n",
       "       [23.033709 ],\n",
       "       [25.033676 ],\n",
       "       [27.033642 ],\n",
       "       [29.03361  ],\n",
       "       [31.033577 ],\n",
       "       [33.033546 ],\n",
       "       [35.033516 ],\n",
       "       [37.03348  ],\n",
       "       [39.03345  ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_Perceptron.predict(dset_features[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi layered Perceptron / Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dset_model_MultiLayerPerceptron = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='linear', input_shape=(dset_features.shape[1],)),  # Hidden layer 1\n",
    "    layers.Dense(32, activation='selu'),  # Hidden layer 2\n",
    "    layers.Dense(1, activation='linear')  # Output layer\n",
    "])\n",
    "\n",
    "\n",
    "dset_model_MultiLayerPerceptron.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 5.4149e-05 - loss: 47299644.0000 - val_accuracy: 0.0000e+00 - val_loss: 5.9694\n",
      "Epoch 2/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 2.9504e-05 - loss: 3.2245 - val_accuracy: 0.0000e+00 - val_loss: 7.2852\n",
      "Epoch 3/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 2.4335e-05 - loss: 3.1875 - val_accuracy: 0.0000e+00 - val_loss: 3.9175\n",
      "Epoch 4/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 1.0890e-04 - loss: 3.1935 - val_accuracy: 0.0000e+00 - val_loss: 4.7257\n",
      "Epoch 5/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 1.2890e-04 - loss: 3.1428 - val_accuracy: 0.0000e+00 - val_loss: 6.0673\n",
      "Epoch 6/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 7.7615e-05 - loss: 3.0639 - val_accuracy: 0.0000e+00 - val_loss: 6.1638\n",
      "Epoch 7/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 1.0962e-04 - loss: 3.0108 - val_accuracy: 0.0000e+00 - val_loss: 4.2391\n",
      "Epoch 8/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 3.0510e-05 - loss: 2.9688 - val_accuracy: 0.0000e+00 - val_loss: 4.4142\n",
      "Epoch 9/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 5.3267e-05 - loss: 2.8811 - val_accuracy: 0.0000e+00 - val_loss: 3.9804\n",
      "Epoch 10/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 4.0142e-05 - loss: 2.7212 - val_accuracy: 0.0000e+00 - val_loss: 4.7393\n",
      "Epoch 11/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 2.0074e-05 - loss: 2.6154 - val_accuracy: 0.0000e+00 - val_loss: 3.7642\n",
      "Epoch 12/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 5.3203e-06 - loss: 2.4367 - val_accuracy: 0.0000e+00 - val_loss: 3.6373\n",
      "Epoch 13/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 1.8581e-04 - loss: 2.3959 - val_accuracy: 0.0000e+00 - val_loss: 11.3917\n",
      "Epoch 14/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 1.3254e-05 - loss: 2.0451 - val_accuracy: 0.0000e+00 - val_loss: 0.0258\n",
      "Epoch 15/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 3.9670e-05 - loss: 2.0961 - val_accuracy: 0.0000e+00 - val_loss: 13.2276\n",
      "Epoch 16/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 1.9561e-05 - loss: 3.2299 - val_accuracy: 0.0000e+00 - val_loss: 2.0935\n",
      "Epoch 17/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 1.2989e-04 - loss: 396.3051 - val_accuracy: 0.0000e+00 - val_loss: 0.8932\n",
      "Epoch 18/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 3.0713e-05 - loss: 0.7896 - val_accuracy: 0.0000e+00 - val_loss: 1.2003\n",
      "Epoch 19/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 1.2186e-05 - loss: 0.9325 - val_accuracy: 0.0000e+00 - val_loss: 54.7870\n",
      "Epoch 20/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 9.9647e-05 - loss: 242.4864 - val_accuracy: 0.0000e+00 - val_loss: 0.0038\n",
      "Epoch 21/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 9.6648e-05 - loss: 176.4412 - val_accuracy: 0.0000e+00 - val_loss: 0.1269\n",
      "Epoch 22/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 2.8122e-05 - loss: 114.4342 - val_accuracy: 0.0000e+00 - val_loss: 4019.9321\n",
      "Epoch 23/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 6.5492e-05 - loss: 1888.3761 - val_accuracy: 0.0000e+00 - val_loss: 0.2074\n",
      "Epoch 24/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 2.7101e-04 - loss: 75.8353 - val_accuracy: 0.0000e+00 - val_loss: 49.9125\n",
      "Epoch 25/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 1.3836e-06 - loss: 145.8196 - val_accuracy: 0.0000e+00 - val_loss: 1.4332\n",
      "Epoch 26/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 4.6885e-05 - loss: 456.7597 - val_accuracy: 0.0000e+00 - val_loss: 1.4922e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 3.8276e-05 - loss: 422.7678 - val_accuracy: 0.0000e+00 - val_loss: 0.1491\n",
      "Epoch 28/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 2.7927e-05 - loss: 426.0061 - val_accuracy: 0.0000e+00 - val_loss: 6.6521e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 6.2757e-06 - loss: 0.0153 - val_accuracy: 0.0000e+00 - val_loss: 0.0060\n",
      "Epoch 30/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 3.4488e-05 - loss: 505.0703 - val_accuracy: 0.0000e+00 - val_loss: 8.1074e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27da8c34490>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_MultiLayerPerceptron.fit(dset_features, dset_labels, epochs=30,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.98607063],\n",
       "       [ 3.035985  ],\n",
       "       [ 5.0019226 ],\n",
       "       [ 6.9614844 ],\n",
       "       [ 9.000017  ],\n",
       "       [11.042909  ],\n",
       "       [13.023591  ],\n",
       "       [15.004663  ],\n",
       "       [17.000513  ],\n",
       "       [19.003408  ],\n",
       "       [21.008821  ],\n",
       "       [23.014183  ],\n",
       "       [25.0181    ],\n",
       "       [27.009024  ],\n",
       "       [28.999527  ],\n",
       "       [30.993029  ],\n",
       "       [32.98878   ],\n",
       "       [34.986233  ],\n",
       "       [36.984974  ],\n",
       "       [38.984684  ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_MultiLayerPerceptron.predict(dset_features[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "dset_model_Convolutional = tf.keras.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=2, activation='relu', input_shape=(2, 1)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n",
    "dset_model_Convolutional.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 79393888.0000 - mae: 4688.9287 - val_loss: 0.3089 - val_mae: 0.5492\n",
      "Epoch 2/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.2842 - mae: 0.3554 - val_loss: 0.2725 - val_mae: 0.5154\n",
      "Epoch 3/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.1744 - mae: 0.3281 - val_loss: 0.2730 - val_mae: 0.5159\n",
      "Epoch 4/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.1504 - mae: 0.3225 - val_loss: 0.3266 - val_mae: 0.5649\n",
      "Epoch 5/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - loss: 0.1494 - mae: 0.3227 - val_loss: 0.4828 - val_mae: 0.6885\n",
      "Epoch 6/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.8239 - mae: 0.3918 - val_loss: 0.3109 - val_mae: 0.5512\n",
      "Epoch 7/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.1490 - mae: 0.3222 - val_loss: 0.3498 - val_mae: 0.5850\n",
      "Epoch 8/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.1450 - mae: 0.3173 - val_loss: 0.3762 - val_mae: 0.6071\n",
      "Epoch 9/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.1433 - mae: 0.3151 - val_loss: 0.3466 - val_mae: 0.5824\n",
      "Epoch 10/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.1425 - mae: 0.3141 - val_loss: 0.4112 - val_mae: 0.6351\n",
      "Epoch 11/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 0.1429 - mae: 0.3153 - val_loss: 0.2426 - val_mae: 0.4862\n",
      "Epoch 12/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.1409 - mae: 0.3131 - val_loss: 0.1418 - val_mae: 0.3699\n",
      "Epoch 13/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.1343 - mae: 0.3060 - val_loss: 0.6527 - val_mae: 0.8021\n",
      "Epoch 14/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.1331 - mae: 0.3057 - val_loss: 0.6645 - val_mae: 0.8094\n",
      "Epoch 15/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.1265 - mae: 0.2980 - val_loss: 0.0028 - val_mae: 0.0437\n",
      "Epoch 16/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.1170 - mae: 0.2869 - val_loss: 0.1492 - val_mae: 0.3808\n",
      "Epoch 17/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.1114 - mae: 0.2810 - val_loss: 0.0530 - val_mae: 0.2239\n",
      "Epoch 18/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.1217 - mae: 0.2913 - val_loss: 0.0204 - val_mae: 0.1401\n",
      "Epoch 19/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.5310 - mae: 0.4471 - val_loss: 40.8623 - val_mae: 6.3771\n",
      "Epoch 20/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - loss: 260.9622 - mae: 7.8628 - val_loss: 0.1325 - val_mae: 0.3603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27da9e8c210>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_Convolutional.fit(dset_features, dset_labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.75783193],\n",
       "       [ 2.8495936 ],\n",
       "       [ 5.020532  ],\n",
       "       [ 7.1597867 ],\n",
       "       [ 9.27332   ],\n",
       "       [11.340355  ],\n",
       "       [13.387315  ],\n",
       "       [15.405082  ],\n",
       "       [17.420677  ],\n",
       "       [19.422428  ],\n",
       "       [21.42418   ],\n",
       "       [23.42593   ],\n",
       "       [25.427685  ],\n",
       "       [27.429438  ],\n",
       "       [29.43119   ],\n",
       "       [31.432941  ],\n",
       "       [33.434692  ],\n",
       "       [35.436447  ],\n",
       "       [37.43768   ],\n",
       "       [39.437634  ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_Convolutional.predict(dset_features[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "dset_model_LSTM = tf.keras.Sequential([\n",
    "    layers.LSTM(32, activation='relu', input_shape=(2, 1)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')  # Output layer with linear activation for regression\n",
    "])\n",
    "\n",
    "# Compile the model with Mean Squared Error loss\n",
    "dset_model_LSTM.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])  # Use mean absolute error (mae) as a metric if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 153019808.0000 - mae: 7869.6450 - val_loss: 1.6171 - val_mae: 1.2570\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.8384 - mae: 0.7402 - val_loss: 1.5789 - val_mae: 1.2419\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.6646 - mae: 0.6861 - val_loss: 1.6683 - val_mae: 1.2770\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.6510 - mae: 0.6822 - val_loss: 1.1190 - val_mae: 1.0428\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.6266 - mae: 0.6649 - val_loss: 1.9879 - val_mae: 1.3956\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - loss: 0.6280 - mae: 0.6636 - val_loss: 1.1316 - val_mae: 1.0488\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.5969 - mae: 0.6459 - val_loss: 1.9678 - val_mae: 1.3886\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.6083 - mae: 0.6542 - val_loss: 1.4025 - val_mae: 1.1699\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.5802 - mae: 0.6371 - val_loss: 2.2531 - val_mae: 1.4872\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.5753 - mae: 0.6348 - val_loss: 1.9422 - val_mae: 1.3799\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 0.5529 - mae: 0.6226 - val_loss: 1.1394 - val_mae: 1.0535\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.5518 - mae: 0.6209 - val_loss: 1.5890 - val_mae: 1.2473\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - loss: 0.5214 - mae: 0.6029 - val_loss: 2.0743 - val_mae: 1.4275\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.5150 - mae: 0.6025 - val_loss: 0.7876 - val_mae: 0.8743\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.4481 - mae: 0.5580 - val_loss: 1.3705 - val_mae: 1.1588\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.5394 - mae: 0.6190 - val_loss: 0.5043 - val_mae: 0.6977\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.4440 - mae: 0.5586 - val_loss: 2.7213 - val_mae: 1.6391\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.1284 - mae: 0.7682 - val_loss: 0.0102 - val_mae: 0.0826\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 12.2480 - mae: 2.4268 - val_loss: 749.1101 - val_mae: 27.3095\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 218.0685 - mae: 8.0481 - val_loss: 9.6892 - val_mae: 3.1019\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 2.1514 - mae: 0.8134 - val_loss: 173.8221 - val_mae: 13.1604\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - loss: 50.4535 - mae: 3.5060 - val_loss: 16.1693 - val_mae: 4.0097\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 81.2425 - mae: 4.1550 - val_loss: 15.1370 - val_mae: 3.8850\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 265.4842 - mae: 10.6601 - val_loss: 5.8811 - val_mae: 2.4219\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - loss: 55.7161 - mae: 3.5306 - val_loss: 3.3033 - val_mae: 1.8119\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 168.5642 - mae: 3.2295 - val_loss: 0.0074 - val_mae: 0.0812\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0766 - mae: 0.2116 - val_loss: 4.5509 - val_mae: 2.1301\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 18.4174 - mae: 1.3508 - val_loss: 9.9437 - val_mae: 3.1458\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 507.3294 - mae: 11.2681 - val_loss: 0.1104 - val_mae: 0.3303\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.0411 - mae: 0.1431 - val_loss: 0.0376 - val_mae: 0.1924\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - loss: 14.6779 - mae: 0.7244 - val_loss: 30.7070 - val_mae: 5.5293\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 38.2830 - mae: 3.7065 - val_loss: 51.8511 - val_mae: 7.1854\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 151.7967 - mae: 8.4279 - val_loss: 458.4060 - val_mae: 21.3660\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 70.3883 - mae: 4.3389 - val_loss: 350.5360 - val_mae: 18.6839\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - loss: 4.9005 - mae: 0.8697 - val_loss: 1.2068 - val_mae: 1.0965\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 135.2906 - mae: 5.5261 - val_loss: 0.0743 - val_mae: 0.2720\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 79.8047 - mae: 3.6608 - val_loss: 1.5166 - val_mae: 1.2290\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 1.1888 - mae: 0.3952 - val_loss: 0.0119 - val_mae: 0.1089\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 169.9459 - mae: 4.9814 - val_loss: 6.3028 - val_mae: 2.5051\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 1.3054 - mae: 0.5262 - val_loss: 0.0061 - val_mae: 0.0776\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 38.5425 - mae: 1.9210 - val_loss: 14.5179 - val_mae: 3.8022\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 827.9495 - mae: 12.1502 - val_loss: 9.3659e-05 - val_mae: 0.0092\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 4.7253e-04 - mae: 0.0170 - val_loss: 0.0019 - val_mae: 0.0437\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 259.2946 - mae: 2.0936 - val_loss: 46.8322 - val_mae: 6.8297\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 1.5220 - mae: 0.4784 - val_loss: 0.0029 - val_mae: 0.0533\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0015 - mae: 0.0328 - val_loss: 9.1776e-05 - val_mae: 0.0079\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.0015 - mae: 0.0319 - val_loss: 9.1943e-05 - val_mae: 0.0083\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0030 - mae: 0.0391 - val_loss: 0.0172 - val_mae: 0.1311\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 165.7841 - mae: 4.7097 - val_loss: 0.0173 - val_mae: 0.1309\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.0020 - mae: 0.0364 - val_loss: 9.0894e-05 - val_mae: 0.0092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27dabf687d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_LSTM.fit(dset_features, dset_labels, epochs=50, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.0093979],\n",
       "       [ 3.0404499],\n",
       "       [ 4.9764657],\n",
       "       [ 6.993775 ],\n",
       "       [ 9.001059 ],\n",
       "       [10.992594 ],\n",
       "       [12.979063 ],\n",
       "       [14.969446 ],\n",
       "       [16.9674   ],\n",
       "       [18.972647 ],\n",
       "       [20.983027 ],\n",
       "       [22.995966 ],\n",
       "       [25.009237 ],\n",
       "       [27.021204 ],\n",
       "       [29.030848 ],\n",
       "       [31.037672 ],\n",
       "       [33.041565 ],\n",
       "       [35.042686 ],\n",
       "       [37.041363 ],\n",
       "       [39.038033 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_LSTM.predict(dset_features[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TestOuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the dataset\n",
    "d_set = pd.read_csv('./../Data/addition_dataset.csv')\n",
    "dset_features = d_set['equation'].values\n",
    "dset_labels = d_set['result'].values\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dset_features)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert text to sequences and pad them\n",
    "sequences = tokenizer.texts_to_sequences(dset_features)\n",
    "padded_sequences = pad_sequences(sequences)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word_index) + 1, output_dim=16, input_length=padded_sequences.shape[1]),\n",
    "    #tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Convert labels to NumPy array\n",
    "dset_labels = tf.convert_to_tensor(dset_labels, dtype=tf.float32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences, dset_labels, epochs=200,validation_split=0.2)\n",
    "\n",
    "# Test the model with new data\n",
    "test_texts = [\"23+24\", \"27+28\"]\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "padded_test_sequences = pad_sequences(test_sequences, maxlen=padded_sequences.shape[1])\n",
    "predictions = model.predict(padded_test_sequences)\n",
    "\n",
    "# Print the predictions\n",
    "for text, prediction in zip(test_texts, predictions):\n",
    "    print(f\"Text: {text}, Prediction: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.predict(pad_sequences(tokenizer.texts_to_sequences(\"123+1\"), maxlen=padded_sequences.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
