{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the basic libraries for implementation of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_set= pd.read_csv('./../Data/addition_dataset_2.csv')\n",
    "d_set.head()\n",
    "dset_features=d_set.copy()\n",
    "dset_labels=dset_features.pop('result')\n",
    "dset_features=np.array(dset_features)\n",
    "dset_model_Perceptron = tf.keras.Sequential([\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "dset_model_Perceptron.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1239337472.0000 - accuracy: 0.0000e+00 - val_loss: 3640441600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 0s 884us/step - loss: 734437184.0000 - accuracy: 0.0000e+00 - val_loss: 2065890688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 0s 907us/step - loss: 400027456.0000 - accuracy: 6.2500e-05 - val_loss: 1062412544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 0s 954us/step - loss: 194782800.0000 - accuracy: 6.2500e-05 - val_loss: 478739936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 0s 997us/step - loss: 81383880.0000 - accuracy: 6.2500e-05 - val_loss: 178927968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 0s 963us/step - loss: 27601048.0000 - accuracy: 6.2500e-05 - val_loss: 51928732.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 0s 934us/step - loss: 7067985.5000 - accuracy: 6.2500e-05 - val_loss: 10675804.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 0s 904us/step - loss: 1245569.2500 - accuracy: 6.2500e-05 - val_loss: 1387577.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 0s 919us/step - loss: 134771.2031 - accuracy: 6.2500e-05 - val_loss: 99331.6797 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 0s 893us/step - loss: 7773.3677 - accuracy: 6.2500e-05 - val_loss: 3332.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 0s 895us/step - loss: 200.9776 - accuracy: 6.2500e-05 - val_loss: 55.1115 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 0s 876us/step - loss: 2.8101 - accuracy: 6.2500e-05 - val_loss: 2.8588 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 0s 865us/step - loss: 1.0083 - accuracy: 6.2500e-05 - val_loss: 2.1611 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 0s 869us/step - loss: 1.0026 - accuracy: 6.2500e-05 - val_loss: 1.9913 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 0s 900us/step - loss: 1.0018 - accuracy: 6.2500e-05 - val_loss: 1.9913 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 0s 933us/step - loss: 1.0015 - accuracy: 6.2500e-05 - val_loss: 1.8665 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 0s 865us/step - loss: 1.0015 - accuracy: 6.2500e-05 - val_loss: 1.9643 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 0s 881us/step - loss: 1.0009 - accuracy: 6.2500e-05 - val_loss: 1.9883 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 0s 877us/step - loss: 1.0007 - accuracy: 6.2500e-05 - val_loss: 1.8146 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 0s 865us/step - loss: 1.0003 - accuracy: 6.2500e-05 - val_loss: 1.9081 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 0s 896us/step - loss: 0.9995 - accuracy: 6.2500e-05 - val_loss: 1.9358 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 0s 919us/step - loss: 0.9989 - accuracy: 6.2500e-05 - val_loss: 2.0634 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 0s 828us/step - loss: 0.9977 - accuracy: 6.2500e-05 - val_loss: 1.9815 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 0s 821us/step - loss: 0.9964 - accuracy: 6.2500e-05 - val_loss: 1.9227 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 0s 825us/step - loss: 0.9948 - accuracy: 6.2500e-05 - val_loss: 1.8998 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 0s 822us/step - loss: 0.9921 - accuracy: 6.2500e-05 - val_loss: 2.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 0s 846us/step - loss: 0.9894 - accuracy: 6.2500e-05 - val_loss: 2.0843 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 0s 878us/step - loss: 0.9861 - accuracy: 6.2500e-05 - val_loss: 1.8316 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 0s 911us/step - loss: 0.9813 - accuracy: 6.2500e-05 - val_loss: 1.8435 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 0s 859us/step - loss: 0.9748 - accuracy: 6.2500e-05 - val_loss: 1.9027 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 0s 827us/step - loss: 0.9694 - accuracy: 6.2500e-05 - val_loss: 2.3498 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 0s 820us/step - loss: 0.9568 - accuracy: 6.2500e-05 - val_loss: 1.5656 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 0s 836us/step - loss: 0.9439 - accuracy: 6.2500e-05 - val_loss: 1.6850 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 0s 867us/step - loss: 0.9291 - accuracy: 6.2500e-05 - val_loss: 2.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 0s 845us/step - loss: 0.9120 - accuracy: 6.2500e-05 - val_loss: 1.2196 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 0s 895us/step - loss: 0.8892 - accuracy: 6.2500e-05 - val_loss: 2.3659 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 0s 838us/step - loss: 0.8527 - accuracy: 6.2500e-05 - val_loss: 1.3662 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 0s 900us/step - loss: 0.8200 - accuracy: 6.2500e-05 - val_loss: 2.5826 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 0s 879us/step - loss: 0.7728 - accuracy: 6.2500e-05 - val_loss: 1.9010 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 0s 874us/step - loss: 0.7305 - accuracy: 6.2500e-05 - val_loss: 1.1635 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 0s 891us/step - loss: 0.6638 - accuracy: 6.2500e-05 - val_loss: 0.6283 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 0s 921us/step - loss: 0.6010 - accuracy: 6.2500e-05 - val_loss: 0.9623 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 0s 947us/step - loss: 0.5413 - accuracy: 6.2500e-05 - val_loss: 1.5034 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 0s 880us/step - loss: 0.4695 - accuracy: 6.2500e-05 - val_loss: 2.7999 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 0s 935us/step - loss: 0.4085 - accuracy: 6.2500e-05 - val_loss: 3.9527 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 0s 923us/step - loss: 0.5450 - accuracy: 6.2500e-05 - val_loss: 0.0285 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 0s 948us/step - loss: 0.3558 - accuracy: 6.2500e-05 - val_loss: 2.5752 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 0s 912us/step - loss: 1.0034 - accuracy: 6.2500e-05 - val_loss: 0.5284 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 0s 882us/step - loss: 0.3387 - accuracy: 6.2500e-05 - val_loss: 1.4726 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 0s 882us/step - loss: 0.3583 - accuracy: 6.2500e-05 - val_loss: 0.1347 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x226c9338950>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_Perceptron.fit(dset_features, dset_labels, epochs=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.3895364],\n",
       "       [ 3.3894947],\n",
       "       [ 5.3894525],\n",
       "       [ 7.3894105],\n",
       "       [ 9.38937  ],\n",
       "       [11.389328 ],\n",
       "       [13.389286 ],\n",
       "       [15.389244 ],\n",
       "       [17.389202 ],\n",
       "       [19.38916  ],\n",
       "       [21.389118 ],\n",
       "       [23.389076 ],\n",
       "       [25.389034 ],\n",
       "       [27.388992 ],\n",
       "       [29.388952 ],\n",
       "       [31.388908 ],\n",
       "       [33.38887  ],\n",
       "       [35.38883  ],\n",
       "       [37.388786 ],\n",
       "       [39.38874  ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_Perceptron.predict(dset_features[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi layered Perceptron / Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_model_MultiLayerPerceptron = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='linear', input_shape=(dset_features.shape[1],)),  # Hidden layer 1\n",
    "    layers.Dense(32, activation='selu'),  # Hidden layer 2\n",
    "    layers.Dense(1, activation='linear')  # Output layer\n",
    "])\n",
    "\n",
    "\n",
    "dset_model_MultiLayerPerceptron.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 3308842.7500 - accuracy: 6.2500e-05 - val_loss: 2.0859 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 2.5664 - accuracy: 6.2500e-05 - val_loss: 8.6860 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "500/500 [==============================] - 0s 986us/step - loss: 3.7069 - accuracy: 6.2500e-05 - val_loss: 144.6802 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "500/500 [==============================] - 0s 989us/step - loss: 5.9788 - accuracy: 6.2500e-05 - val_loss: 0.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 9.8713 - accuracy: 6.2500e-05 - val_loss: 3.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "500/500 [==============================] - 0s 998us/step - loss: 5.0899 - accuracy: 6.2500e-05 - val_loss: 0.2281 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 7.5880 - accuracy: 6.2500e-05 - val_loss: 2.5476 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 6.6911 - accuracy: 6.2500e-05 - val_loss: 37.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "500/500 [==============================] - 0s 997us/step - loss: 5.6183 - accuracy: 6.2500e-05 - val_loss: 4.3519 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 11.2268 - accuracy: 6.2500e-05 - val_loss: 2.1792 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "500/500 [==============================] - 0s 991us/step - loss: 5.2813 - accuracy: 6.2500e-05 - val_loss: 21.9262 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 28.6522 - accuracy: 6.2500e-05 - val_loss: 1.1523 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 24.3949 - accuracy: 6.2500e-05 - val_loss: 16.7415 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 21.7502 - accuracy: 6.2500e-05 - val_loss: 13.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 933.7103 - accuracy: 6.2500e-05 - val_loss: 93010.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 508.1199 - accuracy: 6.2500e-05 - val_loss: 0.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4898 - accuracy: 6.2500e-05 - val_loss: 2.8231 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "500/500 [==============================] - 0s 990us/step - loss: 1361.5967 - accuracy: 6.2500e-05 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "500/500 [==============================] - 0s 994us/step - loss: 0.9739 - accuracy: 6.2500e-05 - val_loss: 41.8074 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 942.7451 - accuracy: 6.2500e-05 - val_loss: 6.9735 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.1778 - accuracy: 6.2500e-05 - val_loss: 49.4799 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 633.7167 - accuracy: 6.2500e-05 - val_loss: 5.5201 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "500/500 [==============================] - 0s 985us/step - loss: 234.2090 - accuracy: 6.2500e-05 - val_loss: 7622.8145 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "500/500 [==============================] - 1s 1000us/step - loss: 665.1582 - accuracy: 6.2500e-05 - val_loss: 15.7969 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "500/500 [==============================] - 0s 991us/step - loss: 875.1519 - accuracy: 6.2500e-05 - val_loss: 33320.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "500/500 [==============================] - 0s 996us/step - loss: 287.1637 - accuracy: 6.2500e-05 - val_loss: 0.0205 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "500/500 [==============================] - 0s 984us/step - loss: 0.0477 - accuracy: 6.2500e-05 - val_loss: 5.8121 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 977.5578 - accuracy: 6.2500e-05 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "500/500 [==============================] - 0s 954us/step - loss: 0.0513 - accuracy: 6.2500e-05 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "500/500 [==============================] - 0s 934us/step - loss: 1186.4031 - accuracy: 6.2500e-05 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x226cbd8df50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_MultiLayerPerceptron.fit(dset_features, dset_labels, epochs=30,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.0379713],\n",
       "       [ 3.0287118],\n",
       "       [ 5.034981 ],\n",
       "       [ 7.006753 ],\n",
       "       [ 9.006344 ],\n",
       "       [10.987668 ],\n",
       "       [12.993192 ],\n",
       "       [15.011741 ],\n",
       "       [17.036127 ],\n",
       "       [19.060934 ],\n",
       "       [21.083021 ],\n",
       "       [23.100744 ],\n",
       "       [25.112593 ],\n",
       "       [27.118288 ],\n",
       "       [29.118704 ],\n",
       "       [31.087624 ],\n",
       "       [33.05057  ],\n",
       "       [35.021183 ],\n",
       "       [36.99822  ],\n",
       "       [38.98062  ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_MultiLayerPerceptron.predict(dset_features[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_model_Convolutional = tf.keras.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=2, activation='relu', input_shape=(2, 1)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n",
    "dset_model_Convolutional.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 24814824.0000 - mae: 1715.2192 - val_loss: 0.5929 - val_mae: 0.7627\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2156 - mae: 0.3858 - val_loss: 0.4383 - val_mae: 0.6546\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 0s 989us/step - loss: 1.4276 - mae: 0.4854 - val_loss: 0.3698 - val_mae: 0.6005\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2012 - mae: 0.3739 - val_loss: 0.4241 - val_mae: 0.6437\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.4499 - mae: 0.4937 - val_loss: 0.3731 - val_mae: 0.6033\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.1999 - mae: 0.3725 - val_loss: 0.5468 - val_mae: 0.7321\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.1992 - mae: 0.3719 - val_loss: 0.4088 - val_mae: 0.6319\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.1980 - mae: 0.3711 - val_loss: 0.4219 - val_mae: 0.6421\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.7352 - mae: 0.5357 - val_loss: 0.3127 - val_mae: 0.5516\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.1959 - mae: 0.3693 - val_loss: 0.4439 - val_mae: 0.6589\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.1925 - mae: 0.3661 - val_loss: 0.4882 - val_mae: 0.6915\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7556 - mae: 0.4922 - val_loss: 0.5060 - val_mae: 0.7043\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.1853 - mae: 0.3594 - val_loss: 0.3805 - val_mae: 0.6097\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.1812 - mae: 0.3557 - val_loss: 0.8011 - val_mae: 0.8883\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.1749 - mae: 0.3498 - val_loss: 0.3806 - val_mae: 0.6102\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 0s 975us/step - loss: 0.1670 - mae: 0.3417 - val_loss: 0.4090 - val_mae: 0.6330\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 0s 990us/step - loss: 0.1689 - mae: 0.3474 - val_loss: 0.2772 - val_mae: 0.5201\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 1s 999us/step - loss: 57.0382 - mae: 2.1749 - val_loss: 1.4194 - val_mae: 1.1851\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 0s 947us/step - loss: 4.3034 - mae: 0.8248 - val_loss: 0.0599 - val_mae: 0.2377\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 0s 980us/step - loss: 0.1767 - mae: 0.3584 - val_loss: 0.0699 - val_mae: 0.2583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x226d18dbc90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_Convolutional.fit(dset_features, dset_labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000226CD338AE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.28406343],\n",
       "       [ 2.4249287 ],\n",
       "       [ 4.6652017 ],\n",
       "       [ 6.900585  ],\n",
       "       [ 9.061536  ],\n",
       "       [11.135099  ],\n",
       "       [13.20866   ],\n",
       "       [15.282221  ],\n",
       "       [17.344887  ],\n",
       "       [19.399569  ],\n",
       "       [21.435888  ],\n",
       "       [23.472208  ],\n",
       "       [25.508528  ],\n",
       "       [27.539839  ],\n",
       "       [29.569094  ],\n",
       "       [31.597746  ],\n",
       "       [33.611156  ],\n",
       "       [35.62041   ],\n",
       "       [37.62036   ],\n",
       "       [39.620316  ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_Convolutional.predict(dset_features[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_model_LSTM = tf.keras.Sequential([\n",
    "    layers.LSTM(32, activation='relu', input_shape=(2, 1)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')  # Output layer with linear activation for regression\n",
    "])\n",
    "\n",
    "# Compile the model with Mean Squared Error loss\n",
    "dset_model_LSTM.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])  # Use mean absolute error (mae) as a metric if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 58669876.0000 - mae: 3137.0920 - val_loss: 1.4783 - val_mae: 1.2015\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.1439 - mae: 0.7844 - val_loss: 0.8257 - val_mae: 0.8934\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9094 - mae: 0.7411 - val_loss: 0.9715 - val_mae: 0.9708\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7923 - mae: 0.7182 - val_loss: 2.3514 - val_mae: 1.5196\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7440 - mae: 0.7008 - val_loss: 0.8118 - val_mae: 0.8859\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7388 - mae: 0.7007 - val_loss: 1.6528 - val_mae: 1.2718\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6339 - mae: 0.6659 - val_loss: 3.2110 - val_mae: 1.7783\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6357 - mae: 0.6700 - val_loss: 0.5587 - val_mae: 0.7319\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6269 - mae: 0.6655 - val_loss: 0.1687 - val_mae: 0.3902\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6403 - mae: 0.6769 - val_loss: 0.6513 - val_mae: 0.7926\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7582 - mae: 0.7357 - val_loss: 0.1463 - val_mae: 0.3625\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6690 - mae: 0.6847 - val_loss: 0.2708 - val_mae: 0.5043\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9922 - mae: 0.8070 - val_loss: 7.5677 - val_mae: 2.7378\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.7317 - mae: 0.9067 - val_loss: 1.5587 - val_mae: 1.2373\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 11.4289 - mae: 1.7402 - val_loss: 0.1586 - val_mae: 0.3835\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 5.5663 - mae: 1.3832 - val_loss: 2.7651 - val_mae: 1.6626\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 19.5776 - mae: 1.7911 - val_loss: 0.2145 - val_mae: 0.4523\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 30.2015 - mae: 2.5204 - val_loss: 24.5933 - val_mae: 4.9446\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 279.3439 - mae: 4.7489 - val_loss: 1.3537 - val_mae: 1.1559\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 185.0358 - mae: 5.3531 - val_loss: 333.0321 - val_mae: 18.2083\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 7.8539 - mae: 1.1984 - val_loss: 0.0918 - val_mae: 0.3019\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 216.6902 - mae: 6.7325 - val_loss: 0.3391 - val_mae: 0.5773\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 434.5285 - mae: 6.9985 - val_loss: 3262.9304 - val_mae: 57.0071\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 12.0087 - mae: 0.8819 - val_loss: 0.6088 - val_mae: 0.7762\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4137 - mae: 0.3987 - val_loss: 0.3053 - val_mae: 0.5525\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 455.0795 - mae: 10.7162 - val_loss: 0.2430 - val_mae: 0.4903\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.0755 - mae: 0.2004 - val_loss: 0.8699 - val_mae: 0.9317\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 4.4934 - mae: 0.9588 - val_loss: 4.0469 - val_mae: 2.0084\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 197.8772 - mae: 4.3393 - val_loss: 0.7229 - val_mae: 0.8477\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 349.0569 - mae: 5.6693 - val_loss: 7.4433e-04 - val_mae: 0.0250\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.0310 - mae: 0.1129 - val_loss: 0.4653 - val_mae: 0.6812\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 226.4292 - mae: 6.4214 - val_loss: 0.0011 - val_mae: 0.0325\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 319.3317 - mae: 8.6826 - val_loss: 10.4632 - val_mae: 3.2285\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4900 - mae: 0.2852 - val_loss: 0.2187 - val_mae: 0.4663\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 158.9891 - mae: 5.1608 - val_loss: 11.5200 - val_mae: 3.3868\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 13.5808 - mae: 1.4395 - val_loss: 1.0534 - val_mae: 1.0240\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 227.8598 - mae: 6.7533 - val_loss: 0.2487 - val_mae: 0.4975\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 100.5335 - mae: 4.9545 - val_loss: 1.1893 - val_mae: 1.0885\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 552.4611 - mae: 7.3831 - val_loss: 7.6248e-04 - val_mae: 0.0274\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 4.8025e-04 - mae: 0.0118 - val_loss: 6.2296e-05 - val_mae: 0.0078\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 253.6034 - mae: 3.5212 - val_loss: 62432.0664 - val_mae: 249.3517\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 168.2534 - mae: 2.6315 - val_loss: 5.9231e-05 - val_mae: 0.0076\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.0146 - mae: 0.0555 - val_loss: 0.1715 - val_mae: 0.4133\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 341.1378 - mae: 4.8280 - val_loss: 1.8740e-06 - val_mae: 5.0830e-04\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.0182 - mae: 0.0638 - val_loss: 0.1736 - val_mae: 0.4157\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 604.5814 - mae: 10.1528 - val_loss: 2.0545e-04 - val_mae: 0.0134\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.0026 - mae: 0.0308 - val_loss: 0.0267 - val_mae: 0.1628\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.1807 - mae: 0.1744 - val_loss: 2.4749 - val_mae: 1.5701\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 302.6884 - mae: 6.2814 - val_loss: 0.0019 - val_mae: 0.0429\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.0010 - mae: 0.0157 - val_loss: 0.2440 - val_mae: 0.4930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x226cfdbbfd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_LSTM.fit(dset_features, dset_labels, epochs=50, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000226D2E80D60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.0587265],\n",
       "       [ 3.0541456],\n",
       "       [ 5.080892 ],\n",
       "       [ 6.977174 ],\n",
       "       [ 8.973065 ],\n",
       "       [10.988362 ],\n",
       "       [13.004357 ],\n",
       "       [15.015603 ],\n",
       "       [17.020046 ],\n",
       "       [19.017853 ],\n",
       "       [21.010542 ],\n",
       "       [23.000183 ],\n",
       "       [24.988811 ],\n",
       "       [26.978113 ],\n",
       "       [28.969303 ],\n",
       "       [30.963125 ],\n",
       "       [32.957077 ],\n",
       "       [34.95242  ],\n",
       "       [36.94988  ],\n",
       "       [38.949604 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_model_LSTM.predict(dset_features[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TestOuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the dataset\n",
    "d_set = pd.read_csv('./../Data/addition_dataset.csv')\n",
    "dset_features = d_set['equation'].values\n",
    "dset_labels = d_set['result'].values\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dset_features)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert text to sequences and pad them\n",
    "sequences = tokenizer.texts_to_sequences(dset_features)\n",
    "padded_sequences = pad_sequences(sequences)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word_index) + 1, output_dim=16, input_length=padded_sequences.shape[1]),\n",
    "    #tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Convert labels to NumPy array\n",
    "dset_labels = tf.convert_to_tensor(dset_labels, dtype=tf.float32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences, dset_labels, epochs=200,validation_split=0.2)\n",
    "\n",
    "# Test the model with new data\n",
    "test_texts = [\"23+24\", \"27+28\"]\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "padded_test_sequences = pad_sequences(test_sequences, maxlen=padded_sequences.shape[1])\n",
    "predictions = model.predict(padded_test_sequences)\n",
    "\n",
    "# Print the predictions\n",
    "for text, prediction in zip(test_texts, predictions):\n",
    "    print(f\"Text: {text}, Prediction: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.predict(pad_sequences(tokenizer.texts_to_sequences(\"123+1\"), maxlen=padded_sequences.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
