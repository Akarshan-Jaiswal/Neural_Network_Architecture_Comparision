{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlexNet\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import time\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Define a custom model with a similar architecture to AlexNet\n",
    "def create_alexnet(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(192, (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create the AlexNet-like model\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10\n",
    "alexnet_like_model = create_alexnet(input_shape, num_classes)\n",
    "\n",
    "# Compile and train the model (using CIFAR-10 data)\n",
    "alexnet_like_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "alexnet_like_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, model_name='AlexNet', dataset_name=\"CIFAR10\", total_epoch=50, ea=False, eamonitor=\"val_loss\"):\n",
    "    tensorboard_callback = TensorBoard(log_dir='./../../Observation/'+model_name+'/'+model_name+dataset_name+'logs')\n",
    "    # Define EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor=eamonitor, patience=10, min_delta=0.001, verbose=1)\n",
    "\n",
    "    start_time = time.time()\n",
    "    if ea:\n",
    "        history = model.fit(X_train, y_train, epochs=total_epoch, validation_data=(X_test, y_test), callbacks=[tensorboard_callback,early_stopping])\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train, epochs=total_epoch, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    return model, history, predictions, training_time\n",
    "\n",
    "def test_model(model, X_test, y_test, model_name='AlexNet', dataset_name=\"CIFAR10\", threshold=0.5):\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict(X_test)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    metrics = calculate_metrics(predictions, y_test, threshold)\n",
    "    metrics['Training Time'] = training_time\n",
    "    metrics['Inference Time'] = inference_time\n",
    "    metrics['Model type'] = model_name\n",
    "    metrics['dataset'] = dataset_name\n",
    "\n",
    "    print(\"Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    metrics_list = list(metrics.values())\n",
    "    pd.DataFrame([metrics_list], columns=metrics.keys()).to_csv('./../../Observation/'+model_name+'/'+model_name+dataset_name+'metrics.csv', index=False)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def calculate_metrics(predictions, true_labels, threshold=0.5):\n",
    "    interpredictions = predictions.argmax(axis=1)  # Convert one-hot encoded predictions to class labels\n",
    "    true_labels = true_labels.argmax(axis=1)  # Convert one-hot encoded true labels to class labels\n",
    "\n",
    "    correct_predictions = np.sum(np.abs(true_labels - interpredictions) <= threshold)\n",
    "    total_predictions = len(true_labels)\n",
    "    accuracy = correct_predictions / total_predictions  # Final accuracy\n",
    "    mse = mean_squared_error(true_labels, interpredictions)  # Mean Squared Error\n",
    "    mae = mean_absolute_error(true_labels, interpredictions)  # Mean Absolute Error\n",
    "    rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "    f1 = f1_score(true_labels, interpredictions, average='micro')  # F1 Score\n",
    "\n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(alexnet_like_model, x_train, y_train, x_test, y_test, model_name='AlexNet', dataset_name='CIFAR10', total_epoch=10, ea=True)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, x_test, y_test, model_name='AlexNet', dataset_name='CIFAR10')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
