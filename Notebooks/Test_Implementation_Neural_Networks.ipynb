{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-40.0 degrees Celsius = -40.0 degrees Fahrenheit\n",
      "-10.0 degrees Celsius = 14.0 degrees Fahrenheit\n",
      "0.0 degrees Celsius = 32.0 degrees Fahrenheit\n",
      "8.0 degrees Celsius = 46.0 degrees Fahrenheit\n",
      "15.0 degrees Celsius = 59.0 degrees Fahrenheit\n",
      "22.0 degrees Celsius = 72.0 degrees Fahrenheit\n",
      "38.0 degrees Celsius = 100.0 degrees Fahrenheit\n"
     ]
    }
   ],
   "source": [
    "celsius_q    = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)\n",
    "fahrenheit_a = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)\n",
    "\n",
    "for i,c in enumerate(celsius_q):\n",
    "  print(\"{} degrees Celsius = {} degrees Fahrenheit\".format(c, fahrenheit_a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(units=1, input_shape=[1])\n",
    "])\n",
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a5a34e2e90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-55.795628]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([100.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "# CBAM (Convolutional Block Attention Module) Layer\n",
    "class CBAM(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention()\n",
    "        self.spatial_attention = SpatialAttention()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        channel_att = self.channel_attention(inputs)\n",
    "        spatial_att = self.spatial_attention(inputs)\n",
    "        return tf.multiply(inputs, tf.expand_dims(tf.expand_dims(channel_att, axis=1), axis=1)) * spatial_att\n",
    "\n",
    "# Channel Attention Layer\n",
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.global_avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.dense1 = layers.Dense(64, activation='relu')\n",
    "        self.dense2 = layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        avg_pool = self.global_avgpool(inputs)\n",
    "        dense1_out = self.dense1(avg_pool)\n",
    "        attention = self.dense2(dense1_out)\n",
    "        return attention\n",
    "\n",
    "# Linear Attention Layer\n",
    "class LinearAttention(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearAttention, self).__init__()\n",
    "        self.dense = layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.sigmoid(self.dense(inputs))\n",
    "\n",
    "# NonLinear Attention Layer\n",
    "class NonLinearAttention(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(NonLinearAttention, self).__init__()\n",
    "        self.dense1 = layers.Dense(64, activation='relu')\n",
    "        self.dense2 = layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        dense1_out = self.dense1(inputs)\n",
    "        attention = self.dense2(dense1_out)\n",
    "        return attention\n",
    "\n",
    "# Configure model function\n",
    "def configure_model(layers_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy']):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    for layer_config in layers_config:\n",
    "        layer_type = layer_config[0]\n",
    "\n",
    "        if layer_type == 'dense':\n",
    "            neurons, activation = layer_config[1], layer_config[2]\n",
    "            if len(layer_config) > 3 and layer_config[3] == 'input':\n",
    "                input_shape = layer_config[4]\n",
    "                model.add(layers.Dense(neurons, activation=activation, input_shape=(input_shape,)))\n",
    "            else:\n",
    "                model.add(layers.Dense(neurons, activation=activation))\n",
    "        elif layer_type == 'dropout':\n",
    "            rate = layer_config[1]\n",
    "            model.add(layers.Dropout(rate))\n",
    "        elif layer_type == 'activation':\n",
    "            activation = layer_config[1]\n",
    "            model.add(layers.Activation(activation))\n",
    "        elif layer_type == 'conv2d':\n",
    "            filters, kernel_size, strides, activation = layer_config[1], layer_config[2], layer_config[3], layer_config[4]\n",
    "            model.add(layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, activation=activation))\n",
    "        elif layer_type == 'maxpool2d':\n",
    "            pool_size = layer_config[1]\n",
    "            model.add(layers.MaxPool2D(pool_size=pool_size))\n",
    "        elif layer_type == 'rnn':\n",
    "            units, return_sequences = layer_config[1], layer_config[2]\n",
    "            model.add(layers.SimpleRNN(units, return_sequences=return_sequences))\n",
    "        elif layer_type == 'lstm':\n",
    "            units, return_sequences = layer_config[1], layer_config[2]\n",
    "            model.add(layers.LSTM(units, return_sequences=return_sequences))\n",
    "        elif layer_type == 'gru':\n",
    "            units, return_sequences = layer_config[1], layer_config[2]\n",
    "            model.add(layers.GRU(units, return_sequences=return_sequences))\n",
    "        elif layer_type == 'attention':\n",
    "            model.add(layers.MultiHeadAttention(num_heads=layer_config[1], key_dim=layer_config[2]))\n",
    "        elif layer_type == 'cbam':\n",
    "            model.add(CBAM())\n",
    "        elif layer_type == 'channel_attention':\n",
    "            model.add(ChannelAttention())\n",
    "        elif layer_type == 'linear_attention':\n",
    "            model.add(LinearAttention())\n",
    "        elif layer_type == 'nonlinear_attention':\n",
    "            model.add(NonLinearAttention())\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train model function\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=50, batch_size=32, model_name='model', log_dir='./logs'):\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    training_time = time.time() - start_time\n",
    "    predictions = model.predict(X_test)\n",
    "    return model, history, predictions, training_time\n",
    "\n",
    "# Test model function\n",
    "def test_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "# Calculate metrics function\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    threshold = 0.5\n",
    "    correct_predictions = np.sum(np.abs(y_true - y_pred.flatten()) <= threshold)\n",
    "    total_predictions = len(y_true)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    f1 = f1_score(y_true, y_pred.round(), average='micro')\n",
    "    return accuracy, mse, mae, rmse, f1\n",
    "\n",
    "# Example usage\n",
    "mlp_config = [\n",
    "    ('dense', 64, 'linear', dset_features.shape[1]),  # Hidden layer 1 with input shape\n",
    "    ('dense', 32, 'selu'),  # Hidden layer 2\n",
    "    ('dense', 1, 'linear')  # Output layer\n",
    "]   \n",
    "\n",
    "model = configure_model(mlp_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    # Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test, model_name='multi_layer_perceptron')\n",
    "    # Test the model\n",
    "\n",
    "predictions = test_model(model, X_test, y_test)\n",
    "    # Calculate metrics\n",
    "accuracy, mse, mae, rmse, f1 = calculate_metrics(y_test, predictions)\n",
    "print(\"Metrics:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
