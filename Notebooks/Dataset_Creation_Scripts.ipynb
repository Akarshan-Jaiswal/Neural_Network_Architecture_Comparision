{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries for generating the synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import io\n",
    "import math\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Variables for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset_size = 20000\n",
    "\n",
    "#file \n",
    "file_name=\"integration_with_cos_dataset\"\n",
    "file_save_location='./../Data/'\n",
    "file_type='.csv'\n",
    "is_file_index_needed=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script for generating the list of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iteration = total_dataset_size\n",
    "result_list=[]\n",
    "for index in range(number_of_iteration):\n",
    "    intermediate_list=[]\n",
    "    interim=index\n",
    "    train=str(interim)+\"+\"+str(interim+1)\n",
    "    test=str(2*interim+1)\n",
    "    intermediate_list.append(train)\n",
    "    intermediate_list.append(test)\n",
    "    result_list.append(intermediate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iteration = total_dataset_size\n",
    "result_list=[]\n",
    "for index in range(number_of_iteration):\n",
    "    intermediate_list=[]\n",
    "    interim=index\n",
    "    train_1=interim\n",
    "    train_2=interim+1\n",
    "    test=str(2*interim+1)\n",
    "    #test=str(train_1**train_2)\n",
    "    test=str(math.cos(train_1))\n",
    "    intermediate_list.append(train_1)\n",
    "    #intermediate_list.append(train_2)\n",
    "    intermediate_list.append(test)\n",
    "    result_list.append(intermediate_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 10\n",
    "width = 20\n",
    "#data_uniform =scipy.stats.uniform.rvs(size=total_dataset_size, loc = start, scale=width)\n",
    "data_normal = scipy.stats.norm.rvs(size=total_dataset_size,loc=0,scale=1)\n",
    "data_gamma = scipy.stats.gamma.rvs(a=5, size=total_dataset_size)\n",
    "data_expon = scipy.stats.expon.rvs(scale=1,loc=0,size=total_dataset_size)\n",
    "data_poisson = scipy.stats.poisson.rvs(mu=3, size=total_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import expon, gamma, norm, poisson, binom\n",
    "\n",
    "def generate_exponential_dataset(num_samples, exp_lambda):\n",
    "    exp_data = expon(scale=1/exp_lambda).rvs(size=num_samples).reshape(-1, 1)\n",
    "    labels = np.random.randint(2, size=num_samples).reshape(-1, 1)  # Generating random binary labels\n",
    "    df = pd.DataFrame(np.concatenate([exp_data, labels], axis=1), columns=['var_1', 'result'])\n",
    "    return df\n",
    "\n",
    "def generate_gamma_dataset(num_samples, gamma_shape, gamma_scale):\n",
    "    gamma_data = gamma(a=gamma_shape, scale=gamma_scale).rvs(size=num_samples).reshape(-1, 1)\n",
    "    labels = np.random.randint(2, size=num_samples).reshape(-1, 1)  # Generating random binary labels\n",
    "    df = pd.DataFrame(np.concatenate([gamma_data, labels], axis=1), columns=['var_1', 'result'])\n",
    "    return df\n",
    "\n",
    "def generate_normal_dataset(num_samples, normal_mean, normal_std):\n",
    "    normal_data = norm(loc=normal_mean, scale=normal_std).rvs(size=num_samples).reshape(-1, 1)\n",
    "    labels = np.random.randint(2, size=num_samples).reshape(-1, 1)  # Generating random binary labels\n",
    "    df = pd.DataFrame(np.concatenate([normal_data, labels], axis=1), columns=['var_1', 'result'])\n",
    "    return df\n",
    "\n",
    "def generate_poisson_dataset(num_samples, poisson_lambda):\n",
    "    poisson_data = poisson(mu=poisson_lambda).rvs(size=num_samples).reshape(-1, 1)\n",
    "    labels = np.random.randint(2, size=num_samples).reshape(-1, 1)  # Generating random binary labels\n",
    "    df = pd.DataFrame(np.concatenate([poisson_data, labels], axis=1), columns=['var_1', 'result'])\n",
    "    return df\n",
    "\n",
    "def generate_binomial_dataset(num_samples, n_trials, p_success):\n",
    "    binomial_data = binom(n=n_trials, p=p_success).rvs(size=num_samples).reshape(-1, 1)\n",
    "    labels = np.random.randint(2, size=num_samples).reshape(-1, 1)  # Generating random binary labels\n",
    "    df = pd.DataFrame(np.concatenate([binomial_data, labels], axis=1), columns=['var_1', 'result'])\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "num_samples = total_dataset_size\n",
    "exp_lambda = 0.5\n",
    "gamma_shape = 2\n",
    "gamma_scale = 2\n",
    "normal_mean = 0\n",
    "normal_std = 1\n",
    "poisson_lambda = 3\n",
    "n_trials = 10\n",
    "p_success = 0.5\n",
    "\n",
    "exp_df = generate_exponential_dataset(num_samples, exp_lambda)\n",
    "gamma_df = generate_gamma_dataset(num_samples, gamma_shape, gamma_scale)\n",
    "normal_df = generate_normal_dataset(num_samples, normal_mean, normal_std)\n",
    "poisson_df = generate_poisson_dataset(num_samples, poisson_lambda)\n",
    "binomial_df = generate_binomial_dataset(num_samples, n_trials, p_success)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomial_df.to_csv(file_save_location+file_name+file_type,index=is_file_index_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def integrate_function(a):\n",
    "    return a**2 * np.cos(a)\n",
    "\n",
    "def generate_dataset(num_samples, upper_limit):\n",
    "    # Generate random values of 'a' within the specified range\n",
    "    a_values = np.random.uniform(0, upper_limit, num_samples)\n",
    "    \n",
    "    # Calculate the corresponding integral values\n",
    "    integral_values = [integrate_function(a) for a in a_values]\n",
    "    \n",
    "    # Create a DataFrame with 'var_1' and 'result' columns\n",
    "    df = pd.DataFrame({'var_1': a_values, 'result': integral_values})\n",
    "    \n",
    "    return df\n",
    "\n",
    "int_var_square_cos_df = generate_dataset(total_dataset_size, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_var_square_cos_df.to_csv(file_save_location+file_name+file_type,index=is_file_index_needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting it to Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf=pandas.DataFrame(result_list)\n",
    "dataf=dataf.rename(columns={0: \"equation\", 1: \"result\"})\n",
    "dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.859864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.639084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.092220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.293630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.873434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3.034998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3.934785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>6.036999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>11.059102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1.306916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           var_1\n",
       "0       6.859864\n",
       "1      11.639084\n",
       "2       7.092220\n",
       "3       9.293630\n",
       "4       3.873434\n",
       "...          ...\n",
       "19995   3.034998\n",
       "19996   3.934785\n",
       "19997   6.036999\n",
       "19998  11.059102\n",
       "19999   1.306916\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf=pandas.DataFrame(result_list)\n",
    "dataf=dataf.rename(columns={0: \"var_1\",1: \"var_2\", 2: \"result\"})\n",
    "dataf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_1\n",
       "0          2\n",
       "1          5\n",
       "2          3\n",
       "3          3\n",
       "4          4\n",
       "...      ...\n",
       "19995      3\n",
       "19996      4\n",
       "19997      5\n",
       "19998      6\n",
       "19999      1\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf=pandas.DataFrame(data_poisson)\n",
    "dataf=dataf.rename(columns={0: \"var_1\"})\n",
    "dataf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the pandas dataframe to a csv file in the local system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.to_csv(file_save_location+file_name+file_type,index=is_file_index_needed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
