{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset and setting inital variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='perceptron'\n",
    "dataset_name=\"addition_dataset_2\"\n",
    "validation_split=0.2\n",
    "total_epoch=50\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=validation_split, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "dset_model_Perceptron = tf.keras.Sequential([\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "dset_model_Perceptron.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Define TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(log_dir='./../../Observation/'+model_name+'/'+model_name+dataset_name+'logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 0.0000e+00 - loss: 678789632.0000 - val_accuracy: 2.5000e-04 - val_loss: 333033824.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.0000e+00 - loss: 261317216.0000 - val_accuracy: 2.5000e-04 - val_loss: 107326256.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 81310320.0000 - val_accuracy: 2.5000e-04 - val_loss: 24535076.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.0000e+00 - loss: 17264364.0000 - val_accuracy: 2.5000e-04 - val_loss: 3480003.2500\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.0000e+00 - loss: 2177467.5000 - val_accuracy: 2.5000e-04 - val_loss: 255507.5469\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.0000e+00 - loss: 142686.9688 - val_accuracy: 2.5000e-04 - val_loss: 8226.6660\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.0000e+00 - loss: 4007.5837 - val_accuracy: 2.5000e-04 - val_loss: 89.3816\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.0000e+00 - loss: 38.8245 - val_accuracy: 2.5000e-04 - val_loss: 1.4177\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.0000e+00 - loss: 1.3141 - val_accuracy: 2.5000e-04 - val_loss: 1.1935\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.0000e+00 - loss: 1.1902 - val_accuracy: 2.5000e-04 - val_loss: 1.1931\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.0000e+00 - loss: 1.2083 - val_accuracy: 2.5000e-04 - val_loss: 1.1933\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.0000e+00 - loss: 1.2186 - val_accuracy: 2.5000e-04 - val_loss: 1.1937\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 1.2161 - val_accuracy: 2.5000e-04 - val_loss: 1.1923\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.0000e+00 - loss: 1.2279 - val_accuracy: 2.5000e-04 - val_loss: 1.1916\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.0000e+00 - loss: 1.2086 - val_accuracy: 2.5000e-04 - val_loss: 1.1908\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.0000e+00 - loss: 1.2143 - val_accuracy: 2.5000e-04 - val_loss: 1.1920\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 1.1974 - val_accuracy: 2.5000e-04 - val_loss: 1.1903\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.0000e+00 - loss: 1.2050 - val_accuracy: 2.5000e-04 - val_loss: 1.1894\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 1.2042 - val_accuracy: 2.5000e-04 - val_loss: 1.1885\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.0000e+00 - loss: 1.2266 - val_accuracy: 2.5000e-04 - val_loss: 1.1865\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 1.2003 - val_accuracy: 2.5000e-04 - val_loss: 1.1871\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.0000e+00 - loss: 1.1963 - val_accuracy: 2.5000e-04 - val_loss: 1.1812\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.0000e+00 - loss: 1.2149 - val_accuracy: 2.5000e-04 - val_loss: 1.1785\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 1.2033 - val_accuracy: 2.5000e-04 - val_loss: 1.1729\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.0000e+00 - loss: 1.1824 - val_accuracy: 2.5000e-04 - val_loss: 1.1843\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.0000e+00 - loss: 1.1989 - val_accuracy: 2.5000e-04 - val_loss: 1.1595\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.0000e+00 - loss: 1.1714 - val_accuracy: 2.5000e-04 - val_loss: 1.1691\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.0000e+00 - loss: 1.1693 - val_accuracy: 2.5000e-04 - val_loss: 1.1839\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.0000e+00 - loss: 1.1666 - val_accuracy: 2.5000e-04 - val_loss: 1.1221\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 1.1464 - val_accuracy: 2.5000e-04 - val_loss: 1.1082\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.0000e+00 - loss: 1.1386 - val_accuracy: 2.5000e-04 - val_loss: 1.1075\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 1.1277 - val_accuracy: 2.5000e-04 - val_loss: 1.0654\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.0000e+00 - loss: 1.0707 - val_accuracy: 2.5000e-04 - val_loss: 1.0152\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.0000e+00 - loss: 1.0342 - val_accuracy: 2.5000e-04 - val_loss: 1.0915\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.0000e+00 - loss: 0.9984 - val_accuracy: 2.5000e-04 - val_loss: 0.9451\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.0000e+00 - loss: 0.9639 - val_accuracy: 2.5000e-04 - val_loss: 1.0283\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.0000e+00 - loss: 0.8757 - val_accuracy: 2.5000e-04 - val_loss: 0.8318\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 0.8607 - val_accuracy: 2.5000e-04 - val_loss: 0.6723\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.0000e+00 - loss: 0.7694 - val_accuracy: 2.5000e-04 - val_loss: 0.6737\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0000e+00 - loss: 0.7424 - val_accuracy: 2.5000e-04 - val_loss: 0.4774\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 0.7248 - val_accuracy: 2.5000e-04 - val_loss: 0.3823\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.0000e+00 - loss: 0.7120 - val_accuracy: 2.5000e-04 - val_loss: 1.5117\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.0000e+00 - loss: 0.6569 - val_accuracy: 2.5000e-04 - val_loss: 0.2824\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.0000e+00 - loss: 1.2711 - val_accuracy: 2.5000e-04 - val_loss: 0.3183\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 0.2525 - val_accuracy: 2.5000e-04 - val_loss: 5.4419\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.0000e+00 - loss: 1.5537 - val_accuracy: 2.5000e-04 - val_loss: 0.2787\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.0000e+00 - loss: 0.3406 - val_accuracy: 2.5000e-04 - val_loss: 0.1552\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 1.4068 - val_accuracy: 2.5000e-04 - val_loss: 0.0530\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 2.5000e-04 - val_loss: 0.0513\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.0000e+00 - loss: 1.3011 - val_accuracy: 2.5000e-04 - val_loss: 0.0564\n"
     ]
    }
   ],
   "source": [
    "# Start timer for training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model with TensorBoard callback\n",
    "history = dset_model_Perceptron.fit(X_train, y_train, epochs=total_epoch, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "# End timer for training time\n",
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction and calculating the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step\n",
      "Metrics:\n",
      "Model type: perceptron\n",
      "dataset: addition_dataset_2\n",
      "Accuracy: 1.0\n",
      "MSE: 0.05638053600668246\n",
      "MAE: 0.23360124123096465\n",
      "RMSE: 0.23744585910620228\n",
      "F1 Score: 1.0\n",
      "Training Time: 22.666709184646606\n",
      "Inference Time: 0.11066842079162598\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = dset_model_Perceptron.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "# Calculate accuracy with threshold\n",
    "threshold = 0.5  # Define the threshold\n",
    "correct_predictions = np.sum(np.abs(y_test - predictions.flatten()) <= threshold)\n",
    "total_predictions = len(y_test)\n",
    "accuracy = correct_predictions / total_predictions  # Final accuracy\n",
    "mse = mean_squared_error(y_test, predictions)  # Mean Squared Error\n",
    "mae = mean_absolute_error(y_test, predictions)  # Mean Absolute Error\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "f1 = f1_score(y_test, predictions.round(), average='micro')  # F1 Score\n",
    "\n",
    "# Calculate inference time\n",
    "start_time = time.time()\n",
    "predictions = dset_model_Perceptron.predict(X_test)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Print and store metrics\n",
    "metrics = {\n",
    "    'Model type': model_name,\n",
    "    'dataset': dataset_name,\n",
    "    'Accuracy': accuracy,\n",
    "    'MSE': mse,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'F1 Score': f1,\n",
    "    'Training Time': training_time,\n",
    "    'Inference Time': inference_time\n",
    "}\n",
    "\n",
    "print(\"Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "# Store metrics in a list\n",
    "metrics_list = list(metrics.values())\n",
    "pd.DataFrame([metrics_list], columns=metrics.keys()).to_csv('./../../Observation/'+model_name+'/'+model_name+dataset_name+'metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a function to generate models for different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_model_and_observation_generator(model_name,dataset_name,validation_split,total_epoch,optimizer='adam'):\n",
    "    # Load dataset\n",
    "    d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "    dset_features = d_set.copy()\n",
    "    dset_labels = dset_features.pop('result')\n",
    "    dset_features = np.array(dset_features)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=validation_split, random_state=42)\n",
    "\n",
    "    # Define the model\n",
    "    dset_model_Perceptron = tf.keras.Sequential([\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    dset_model_Perceptron.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "    # Define TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir='./../../Observation/'+model_name+'/'+model_name+dataset_name+'logs')\n",
    "\n",
    "    # Start timer for training time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train the model with TensorBoard callback\n",
    "    history = dset_model_Perceptron.fit(X_train, y_train, epochs=total_epoch, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "    # End timer for training time\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = dset_model_Perceptron.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    # Calculate accuracy with threshold\n",
    "    threshold = 0.5  # Define the threshold\n",
    "    correct_predictions = np.sum(np.abs(y_test - predictions.flatten()) <= threshold)\n",
    "    total_predictions = len(y_test)\n",
    "    accuracy = correct_predictions / total_predictions  # Final accuracy\n",
    "    mse = mean_squared_error(y_test, predictions)  # Mean Squared Error\n",
    "    mae = mean_absolute_error(y_test, predictions)  # Mean Absolute Error\n",
    "    rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "    f1 = f1_score(y_test, predictions.round(), average='micro')  # F1 Score\n",
    "\n",
    "    # Calculate inference time\n",
    "    start_time = time.time()\n",
    "    predictions = dset_model_Perceptron.predict(X_test)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    # Print and store metrics\n",
    "    metrics = {\n",
    "        'Model type': model_name,\n",
    "        'dataset': dataset_name,\n",
    "        \n",
    "        'Accuracy': accuracy,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'F1 Score': f1,\n",
    "        'Training Time': training_time,\n",
    "        'Inference Time': inference_time\n",
    "    }\n",
    "\n",
    "    print(\"Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    # Store metrics in a list\n",
    "    metrics_list = list(metrics.values())\n",
    "    pd.DataFrame([metrics_list], columns=metrics.keys()).to_csv('./../../Observation/'+model_name+'/'+model_name+dataset_name+'metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model_and_observation_generator('perceptron','multiplication_dataset',0.2,500,\"ADAMW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "model_name='perceptron'\n",
    "dataset_name=\"addition_dataset_2\"\n",
    "validation_split=0.2\n",
    "total_epoch=50\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=validation_split, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "dset_model_Perceptron = tf.keras.Sequential([\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "dset_model_Perceptron.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Define TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(log_dir='./../../Observation/'+model_name+'/'+model_name+dataset_name+'logs')\n",
    "\n",
    "# Start timer for training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model with TensorBoard callback\n",
    "history = dset_model_Perceptron.fit(X_train, y_train, epochs=total_epoch, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "# End timer for training time\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Make predictions\n",
    "predictions = dset_model_Perceptron.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "# Calculate accuracy with threshold\n",
    "threshold = 0.5  # Define the threshold\n",
    "correct_predictions = np.sum(np.abs(y_test - predictions.flatten()) <= threshold)\n",
    "total_predictions = len(y_test)\n",
    "accuracy = correct_predictions / total_predictions  # Final accuracy\n",
    "mse = mean_squared_error(y_test, predictions)  # Mean Squared Error\n",
    "mae = mean_absolute_error(y_test, predictions)  # Mean Absolute Error\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "f1 = f1_score(y_test, predictions.round(), average='micro')  # F1 Score\n",
    "\n",
    "# Calculate inference time\n",
    "start_time = time.time()\n",
    "predictions = dset_model_Perceptron.predict(X_test)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Print and store metrics\n",
    "metrics = {\n",
    "    'Model type': model_name,\n",
    "    'dataset': dataset_name,\n",
    "    'Accuracy': accuracy,\n",
    "    'MSE': mse,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'F1 Score': f1,\n",
    "    'Training Time': training_time,\n",
    "    'Inference Time': inference_time\n",
    "}\n",
    "\n",
    "print(\"Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "# Store metrics in a list\n",
    "metrics_list = list(metrics.values())\n",
    "pd.DataFrame([metrics_list], columns=metrics.keys()).to_csv('./../../Observation/'+model_name+'/'+model_name+dataset_name+'metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 0.0000e+00 - loss: 409372.3125 - val_accuracy: 2.5000e-04 - val_loss: 7.9395e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.0000e+00 - loss: 7.8865e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.8067e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 7.7587e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.6093e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.0000e+00 - loss: 7.6704e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.5604e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.0000e+00 - loss: 7.5816e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.5064e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.0000e+00 - loss: 7.5655e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.4927e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.0000e+00 - loss: 7.5512e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.3528e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.0000e+00 - loss: 7.4671e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.3334e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.0000e+00 - loss: 7.4361e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.2720e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.0000e+00 - loss: 7.3784e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.0676e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.0000e+00 - loss: 7.2253e-04 - val_accuracy: 2.5000e-04 - val_loss: 6.9938e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 7.0158e-04 - val_accuracy: 2.5000e-04 - val_loss: 6.7014e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.0000e+00 - loss: 6.9504e-04 - val_accuracy: 2.5000e-04 - val_loss: 6.8788e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 6.9167e-04 - val_accuracy: 2.5000e-04 - val_loss: 6.8391e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.0000e+00 - loss: 6.7790e-04 - val_accuracy: 2.5000e-04 - val_loss: 6.5664e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.0000e+00 - loss: 6.3579e-04 - val_accuracy: 2.5000e-04 - val_loss: 5.7482e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.0000e+00 - loss: 6.0980e-04 - val_accuracy: 2.5000e-04 - val_loss: 5.4481e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 5.9451e-04 - val_accuracy: 2.5000e-04 - val_loss: 5.2331e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.0000e+00 - loss: 5.4710e-04 - val_accuracy: 2.5000e-04 - val_loss: 4.7199e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 4.6202e-04 - val_accuracy: 2.5000e-04 - val_loss: 4.7405e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.0000e+00 - loss: 4.2324e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.0071e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.0000e+00 - loss: 4.1751e-04 - val_accuracy: 2.5000e-04 - val_loss: 2.3286e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 7.8296e-04 - val_accuracy: 2.5000e-04 - val_loss: 0.0020\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 0.3389 - val_accuracy: 2.5000e-04 - val_loss: 0.0024\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.0000e+00 - loss: 0.8879 - val_accuracy: 2.5000e-04 - val_loss: 8.2484e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.0000e+00 - loss: 0.5524 - val_accuracy: 2.5000e-04 - val_loss: 5.1735e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.0000e+00 - loss: 4.2935e-04 - val_accuracy: 2.5000e-04 - val_loss: 0.0296\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.0000e+00 - loss: 0.6701 - val_accuracy: 2.5000e-04 - val_loss: 1.7519e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.0000e+00 - loss: 0.1897 - val_accuracy: 2.5000e-04 - val_loss: 1.5957e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.0000e+00 - loss: 0.5203 - val_accuracy: 2.5000e-04 - val_loss: 0.0093\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.0000e+00 - loss: 4.1011e-04 - val_accuracy: 2.5000e-04 - val_loss: 9.3394e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 1.1455e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.1644e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.0000e+00 - loss: 2.6096 - val_accuracy: 2.5000e-04 - val_loss: 2.8785e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 8.9927e-06 - val_accuracy: 2.5000e-04 - val_loss: 4.4804e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0000e+00 - loss: 0.3638 - val_accuracy: 2.5000e-04 - val_loss: 3.3253e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 4.9741e-04 - val_accuracy: 2.5000e-04 - val_loss: 0.0064\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0000e+00 - loss: 0.8959 - val_accuracy: 2.5000e-04 - val_loss: 0.0061\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.0000e+00 - loss: 4.7832 - val_accuracy: 2.5000e-04 - val_loss: 3.3307e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.0000e+00 - loss: 1.1396e-05 - val_accuracy: 2.5000e-04 - val_loss: 1.5897e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.0000e+00 - loss: 9.7381e-04 - val_accuracy: 2.5000e-04 - val_loss: 10.7713\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 4.4188 - val_accuracy: 2.5000e-04 - val_loss: 1.9379e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.0000e+00 - loss: 0.0108 - val_accuracy: 2.5000e-04 - val_loss: 1.6022\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.0000e+00 - loss: 3.3168 - val_accuracy: 2.5000e-04 - val_loss: 9.2801e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0000e+00 - loss: 0.3151 - val_accuracy: 2.5000e-04 - val_loss: 0.0269\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.0000e+00 - loss: 0.0168 - val_accuracy: 2.5000e-04 - val_loss: 8.9070e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.0000e+00 - loss: 0.0697 - val_accuracy: 2.5000e-04 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 2.3514 - val_accuracy: 2.5000e-04 - val_loss: 7.9380e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 6.3137e-04 - val_accuracy: 2.5000e-04 - val_loss: 0.1417\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.0000e+00 - loss: 0.8332 - val_accuracy: 2.5000e-04 - val_loss: 3.4129e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.0000e+00 - loss: 4.1354e-05 - val_accuracy: 2.5000e-04 - val_loss: 6.2078e-05\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step\n",
      "Metrics:\n",
      "Accuracy: 1.0\n",
      "MSE: 6.207762708970676e-05\n",
      "MAE: 0.006620059728622437\n",
      "RMSE: 0.007878935657162505\n",
      "F1 Score: 1.0\n",
      "Training Time: 22.38504695892334\n",
      "Inference Time: 0.11205363273620605\n",
      "Model type: perceptron\n",
      "dataset: addition_dataset_2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "def configure_model(layers_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy']):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    for layer_config in layers_config:\n",
    "        neurons, layer_type = layer_config\n",
    "        if layer_type == 'dense':\n",
    "            model.add(layers.Dense(neurons))\n",
    "        elif layer_type == 'dropout':\n",
    "            model.add(layers.Dropout(neurons))\n",
    "        elif layer_type == 'activation':\n",
    "            model.add(layers.Activation(neurons))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, model_name='perceptron', dataset_name=\"addition_dataset_2\", total_epoch=50):\n",
    "    tensorboard_callback = TensorBoard(log_dir='./../../Observation/'+model_name+'test/'+model_name+dataset_name+'logs')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=total_epoch, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    return model, history, predictions, training_time\n",
    "\n",
    "def test_model(model, X_test, y_test, model_name='perceptron', dataset_name=\"addition_dataset_2\"):\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict(X_test)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    metrics = calculate_metrics(predictions, y_test)\n",
    "    metrics['Training Time'] = training_time\n",
    "    metrics['Inference Time'] = inference_time\n",
    "    metrics['Model type'] = model_name\n",
    "    metrics['dataset'] = dataset_name\n",
    "\n",
    "    print(\"Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    metrics_list = list(metrics.values())\n",
    "    pd.DataFrame([metrics_list], columns=metrics.keys()).to_csv('./../../Observation/'+model_name+'test/'+model_name+dataset_name+'metrics.csv', index=False)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def calculate_metrics(predictions, true_labels):\n",
    "    threshold = 0.5  # Define the threshold\n",
    "    correct_predictions = np.sum(np.abs(true_labels - predictions.flatten()) <= threshold)\n",
    "    total_predictions = len(true_labels)\n",
    "    accuracy = correct_predictions / total_predictions  # Final accuracy\n",
    "    mse = mean_squared_error(true_labels, predictions)  # Mean Squared Error\n",
    "    mae = mean_absolute_error(true_labels, predictions)  # Mean Absolute Error\n",
    "    rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "    f1 = f1_score(true_labels.round(), predictions.round(), average='micro')  # F1 Score\n",
    "\n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "# Load dataset\n",
    "dataset_name = \"addition_dataset_2\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "perceptron_config = [(1, 'dense')]\n",
    "model = configure_model(perceptron_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 1.1728e-04 - loss: 159425.9531 - val_accuracy: 2.5000e-04 - val_loss: 3.8371e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 2.2547e-04 - loss: 3.8681e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.7772e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 1.1978e-04 - loss: 3.8021e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.7665e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 6.8283e-06 - loss: 3.8980e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.7582e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 7.1065e-05 - loss: 3.8269e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.7245e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 6.8283e-06 - loss: 3.8414e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.6850e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 3.9906e-05 - loss: 3.7494e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.7178e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 8.1626e-05 - loss: 3.8197e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.6402e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 1.7717e-05 - loss: 3.7105e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.5402e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 2.4737e-04 - loss: 3.5749e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.5023e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 2.1638e-05 - loss: 3.6206e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.6255e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 4.0617e-05 - loss: 3.4103e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.2659e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 1.0840e-05 - loss: 3.3344e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.6241e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 3.7450e-07 - loss: 3.2383e-04 - val_accuracy: 2.5000e-04 - val_loss: 3.0502e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 1.6385e-06 - loss: 3.0605e-04 - val_accuracy: 2.5000e-04 - val_loss: 2.7400e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 1.8048e-05 - loss: 2.8534e-04 - val_accuracy: 2.5000e-04 - val_loss: 2.6288e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 2.2101e-04 - loss: 2.6118e-04 - val_accuracy: 2.5000e-04 - val_loss: 2.1641e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 1.7887e-04 - loss: 2.4444e-04 - val_accuracy: 2.5000e-04 - val_loss: 2.7121e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 1.7717e-05 - loss: 2.5162e-04 - val_accuracy: 2.5000e-04 - val_loss: 2.4233e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 3.7591e-05 - loss: 2.8510e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.0541e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 3.7818e-05 - loss: 1.5310 - val_accuracy: 2.5000e-04 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 1.7552e-05 - loss: 0.0051 - val_accuracy: 2.5000e-04 - val_loss: 0.4872\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 9.2677e-05 - loss: 0.9461 - val_accuracy: 2.5000e-04 - val_loss: 8.1936e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 2.3786e-05 - loss: 8.6079 - val_accuracy: 2.5000e-04 - val_loss: 5.2414e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 4.5128e-06 - loss: 8.4919e-05 - val_accuracy: 2.5000e-04 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 5.3559e-05 - loss: 0.0364 - val_accuracy: 2.5000e-04 - val_loss: 1.8639\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 2.4519e-05 - loss: 1.2197 - val_accuracy: 2.5000e-04 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 7.8048e-05 - loss: 0.4247 - val_accuracy: 2.5000e-04 - val_loss: 3.3396e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 8.3023e-05 - loss: 0.3768 - val_accuracy: 2.5000e-04 - val_loss: 1.4826e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 1.1894e-04 - loss: 3.0512e-04 - val_accuracy: 2.5000e-04 - val_loss: 2.5581e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 4.1821e-05 - loss: 1.3959 - val_accuracy: 2.5000e-04 - val_loss: 7.8063e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 9.2331e-06 - loss: 2.5047e-05 - val_accuracy: 2.5000e-04 - val_loss: 6.7343e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 1.9391e-05 - loss: 0.4509 - val_accuracy: 2.5000e-04 - val_loss: 0.0042\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 2.3027e-04 - loss: 0.4631 - val_accuracy: 2.5000e-04 - val_loss: 0.0076\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 1.7882e-05 - loss: 2.6146 - val_accuracy: 2.5000e-04 - val_loss: 2.2050e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 2.0938e-05 - loss: 3.8182 - val_accuracy: 2.5000e-04 - val_loss: 9.0204e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 1.1885e-05 - loss: 9.1872e-06 - val_accuracy: 2.5000e-04 - val_loss: 3.2837e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 4.4810e-05 - loss: 0.1266 - val_accuracy: 2.5000e-04 - val_loss: 0.1753\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 6.1700e-05 - loss: 0.0510 - val_accuracy: 2.5000e-04 - val_loss: 7.3041e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 6.0376e-05 - loss: 0.5022 - val_accuracy: 2.5000e-04 - val_loss: 3.4164e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 1.1728e-04 - loss: 8.3696 - val_accuracy: 2.5000e-04 - val_loss: 2.9487e-07\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 3.5579e-05 - loss: 8.8286e-07 - val_accuracy: 2.5000e-04 - val_loss: 5.7511e-07\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 2.5388e-06 - loss: 1.5509e-06 - val_accuracy: 2.5000e-04 - val_loss: 3.8752e-07\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 1.0692e-05 - loss: 1.2654e-05 - val_accuracy: 2.5000e-04 - val_loss: 2.2195e-07\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 5.7280e-06 - loss: 2.4026 - val_accuracy: 2.5000e-04 - val_loss: 1.9975e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 1.0089e-04 - loss: 8.1790e-06 - val_accuracy: 2.5000e-04 - val_loss: 2.2794e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 1.5543e-04 - loss: 0.3734 - val_accuracy: 2.5000e-04 - val_loss: 0.0157\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 3.1326e-05 - loss: 0.0164 - val_accuracy: 2.5000e-04 - val_loss: 22.1729\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 8.7918e-05 - loss: 17.0471 - val_accuracy: 2.5000e-04 - val_loss: 2.0206e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 4.7415e-05 - loss: 7.3123e-06 - val_accuracy: 2.5000e-04 - val_loss: 2.2359e-06\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step\n",
      "Metrics:\n",
      "Accuracy: 1.0\n",
      "MSE: 2.235883088324905e-06\n",
      "MAE: 0.0013517430410720408\n",
      "RMSE: 0.0014952869585216427\n",
      "F1 Score: 0.761\n",
      "Training Time: 21.80944514274597\n",
      "Inference Time: 0.10474991798400879\n",
      "Model type: perceptron\n",
      "dataset: addition_dataset_2\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"substraction_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "perceptron_config = [(1, 'dense')]\n",
    "model = configure_model(perceptron_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 0.0000e+00 - loss: 379521408.0000 - val_accuracy: 2.5000e-04 - val_loss: 234106256.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.0000e+00 - loss: 202580640.0000 - val_accuracy: 0.0000e+00 - val_loss: 115761824.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.0000e+00 - loss: 99336296.0000 - val_accuracy: 0.0000e+00 - val_loss: 49547948.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.0000e+00 - loss: 40549924.0000 - val_accuracy: 0.0000e+00 - val_loss: 17231136.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 13385227.0000 - val_accuracy: 0.0000e+00 - val_loss: 4510273.5000\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.0000e+00 - loss: 3283997.7500 - val_accuracy: 0.0000e+00 - val_loss: 799826.1875\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.0000e+00 - loss: 528286.1250 - val_accuracy: 0.0000e+00 - val_loss: 84685.1797\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.0000e+00 - loss: 50480.6953 - val_accuracy: 0.0000e+00 - val_loss: 4550.6870\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.0000e+00 - loss: 2427.5315 - val_accuracy: 0.0000e+00 - val_loss: 102.5801\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.0000e+00 - loss: 49.2413 - val_accuracy: 0.0000e+00 - val_loss: 1.5151\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.0000e+00 - loss: 1.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.8039\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.0000e+00 - loss: 0.8173 - val_accuracy: 0.0000e+00 - val_loss: 0.8013\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.0000e+00 - loss: 0.8202 - val_accuracy: 0.0000e+00 - val_loss: 0.8018\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 0.8152 - val_accuracy: 0.0000e+00 - val_loss: 0.8018\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.0000e+00 - loss: 0.8145 - val_accuracy: 0.0000e+00 - val_loss: 0.8011\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.0000e+00 - loss: 0.8251 - val_accuracy: 0.0000e+00 - val_loss: 0.8009\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.0000e+00 - loss: 0.8119 - val_accuracy: 0.0000e+00 - val_loss: 0.7999\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.0000e+00 - loss: 0.8106 - val_accuracy: 0.0000e+00 - val_loss: 0.7989\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 0.8073 - val_accuracy: 0.0000e+00 - val_loss: 0.7975\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.0000e+00 - loss: 0.8191 - val_accuracy: 0.0000e+00 - val_loss: 0.7974\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.0000e+00 - loss: 0.8179 - val_accuracy: 0.0000e+00 - val_loss: 0.7952\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.0000e+00 - loss: 0.8056 - val_accuracy: 0.0000e+00 - val_loss: 0.7938\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.0000e+00 - loss: 0.8081 - val_accuracy: 0.0000e+00 - val_loss: 0.7905\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.0000e+00 - loss: 0.8036 - val_accuracy: 0.0000e+00 - val_loss: 0.7874\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.0000e+00 - loss: 0.7923 - val_accuracy: 0.0000e+00 - val_loss: 0.7849\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.0000e+00 - loss: 0.7909 - val_accuracy: 0.0000e+00 - val_loss: 0.7789\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.0000e+00 - loss: 0.7948 - val_accuracy: 0.0000e+00 - val_loss: 0.7731\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.0000e+00 - loss: 0.7723 - val_accuracy: 0.0000e+00 - val_loss: 0.7663\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.0000e+00 - loss: 0.7794 - val_accuracy: 0.0000e+00 - val_loss: 0.7539\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 0.7584 - val_accuracy: 0.0000e+00 - val_loss: 0.7420\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 0.7488 - val_accuracy: 0.0000e+00 - val_loss: 0.7240\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.0000e+00 - loss: 0.7322 - val_accuracy: 0.0000e+00 - val_loss: 0.7095\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.0000e+00 - loss: 0.7186 - val_accuracy: 0.0000e+00 - val_loss: 0.6949\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.0000e+00 - loss: 0.7077 - val_accuracy: 0.0000e+00 - val_loss: 0.6568\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.0000e+00 - loss: 0.6618 - val_accuracy: 0.0000e+00 - val_loss: 0.6072\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.0000e+00 - loss: 0.6241 - val_accuracy: 0.0000e+00 - val_loss: 0.5598\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.0000e+00 - loss: 0.5786 - val_accuracy: 0.0000e+00 - val_loss: 0.5301\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.0000e+00 - loss: 0.5193 - val_accuracy: 0.0000e+00 - val_loss: 0.4451\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.0000e+00 - loss: 0.4553 - val_accuracy: 0.0000e+00 - val_loss: 0.4191\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.0000e+00 - loss: 0.3887 - val_accuracy: 0.0000e+00 - val_loss: 0.3204\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.0000e+00 - loss: 0.3108 - val_accuracy: 0.0000e+00 - val_loss: 0.3241\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.0000e+00 - loss: 0.2629 - val_accuracy: 0.0000e+00 - val_loss: 0.1974\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.0000e+00 - loss: 0.1906 - val_accuracy: 0.0000e+00 - val_loss: 0.1218\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 0.1328 - val_accuracy: 0.0000e+00 - val_loss: 0.1257\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.0000e+00 - loss: 0.2097 - val_accuracy: 2.5000e-04 - val_loss: 0.1109\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.0000e+00 - loss: 0.1111 - val_accuracy: 2.5000e-04 - val_loss: 0.0404\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.0000e+00 - loss: 0.5312 - val_accuracy: 2.5000e-04 - val_loss: 0.0299\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.0000e+00 - loss: 0.0188 - val_accuracy: 2.5000e-04 - val_loss: 0.0188\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.0000e+00 - loss: 0.1761 - val_accuracy: 2.5000e-04 - val_loss: 0.0034\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.0000e+00 - loss: 0.0795 - val_accuracy: 2.5000e-04 - val_loss: 0.0073\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step\n",
      "Metrics:\n",
      "Accuracy: 1.0\n",
      "MSE: 0.007339671165288483\n",
      "MAE: 0.07093316551670432\n",
      "RMSE: 0.08567188083197709\n",
      "F1 Score: 1.0\n",
      "Training Time: 21.081427335739136\n",
      "Inference Time: 0.10801959037780762\n",
      "Model type: perceptron\n",
      "dataset: addition_dataset_2\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"doubling_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "perceptron_config = [(1, 'dense')]\n",
    "model = configure_model(perceptron_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
