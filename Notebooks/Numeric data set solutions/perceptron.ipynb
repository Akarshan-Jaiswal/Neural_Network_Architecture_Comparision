{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset and setting inital variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='perceptron'\n",
    "dataset_name=\"addition_dataset_2\"\n",
    "validation_split=0.2\n",
    "total_epoch=50\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=validation_split, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "dset_model_Perceptron = tf.keras.Sequential([\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "dset_model_Perceptron.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Define TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(log_dir='./../../Observation/'+model_name+'/'+model_name+dataset_name+'logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 0.0000e+00 - loss: 678789632.0000 - val_accuracy: 2.5000e-04 - val_loss: 333033824.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.0000e+00 - loss: 261317216.0000 - val_accuracy: 2.5000e-04 - val_loss: 107326256.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 81310320.0000 - val_accuracy: 2.5000e-04 - val_loss: 24535076.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.0000e+00 - loss: 17264364.0000 - val_accuracy: 2.5000e-04 - val_loss: 3480003.2500\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.0000e+00 - loss: 2177467.5000 - val_accuracy: 2.5000e-04 - val_loss: 255507.5469\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.0000e+00 - loss: 142686.9688 - val_accuracy: 2.5000e-04 - val_loss: 8226.6660\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.0000e+00 - loss: 4007.5837 - val_accuracy: 2.5000e-04 - val_loss: 89.3816\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.0000e+00 - loss: 38.8245 - val_accuracy: 2.5000e-04 - val_loss: 1.4177\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.0000e+00 - loss: 1.3141 - val_accuracy: 2.5000e-04 - val_loss: 1.1935\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.0000e+00 - loss: 1.1902 - val_accuracy: 2.5000e-04 - val_loss: 1.1931\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.0000e+00 - loss: 1.2083 - val_accuracy: 2.5000e-04 - val_loss: 1.1933\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.0000e+00 - loss: 1.2186 - val_accuracy: 2.5000e-04 - val_loss: 1.1937\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 1.2161 - val_accuracy: 2.5000e-04 - val_loss: 1.1923\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.0000e+00 - loss: 1.2279 - val_accuracy: 2.5000e-04 - val_loss: 1.1916\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.0000e+00 - loss: 1.2086 - val_accuracy: 2.5000e-04 - val_loss: 1.1908\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.0000e+00 - loss: 1.2143 - val_accuracy: 2.5000e-04 - val_loss: 1.1920\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 1.1974 - val_accuracy: 2.5000e-04 - val_loss: 1.1903\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.0000e+00 - loss: 1.2050 - val_accuracy: 2.5000e-04 - val_loss: 1.1894\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 1.2042 - val_accuracy: 2.5000e-04 - val_loss: 1.1885\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.0000e+00 - loss: 1.2266 - val_accuracy: 2.5000e-04 - val_loss: 1.1865\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 1.2003 - val_accuracy: 2.5000e-04 - val_loss: 1.1871\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.0000e+00 - loss: 1.1963 - val_accuracy: 2.5000e-04 - val_loss: 1.1812\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.0000e+00 - loss: 1.2149 - val_accuracy: 2.5000e-04 - val_loss: 1.1785\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 1.2033 - val_accuracy: 2.5000e-04 - val_loss: 1.1729\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.0000e+00 - loss: 1.1824 - val_accuracy: 2.5000e-04 - val_loss: 1.1843\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.0000e+00 - loss: 1.1989 - val_accuracy: 2.5000e-04 - val_loss: 1.1595\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.0000e+00 - loss: 1.1714 - val_accuracy: 2.5000e-04 - val_loss: 1.1691\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.0000e+00 - loss: 1.1693 - val_accuracy: 2.5000e-04 - val_loss: 1.1839\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.0000e+00 - loss: 1.1666 - val_accuracy: 2.5000e-04 - val_loss: 1.1221\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 1.1464 - val_accuracy: 2.5000e-04 - val_loss: 1.1082\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.0000e+00 - loss: 1.1386 - val_accuracy: 2.5000e-04 - val_loss: 1.1075\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 1.1277 - val_accuracy: 2.5000e-04 - val_loss: 1.0654\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.0000e+00 - loss: 1.0707 - val_accuracy: 2.5000e-04 - val_loss: 1.0152\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.0000e+00 - loss: 1.0342 - val_accuracy: 2.5000e-04 - val_loss: 1.0915\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.0000e+00 - loss: 0.9984 - val_accuracy: 2.5000e-04 - val_loss: 0.9451\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.0000e+00 - loss: 0.9639 - val_accuracy: 2.5000e-04 - val_loss: 1.0283\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.0000e+00 - loss: 0.8757 - val_accuracy: 2.5000e-04 - val_loss: 0.8318\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 0.8607 - val_accuracy: 2.5000e-04 - val_loss: 0.6723\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.0000e+00 - loss: 0.7694 - val_accuracy: 2.5000e-04 - val_loss: 0.6737\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0000e+00 - loss: 0.7424 - val_accuracy: 2.5000e-04 - val_loss: 0.4774\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 0.7248 - val_accuracy: 2.5000e-04 - val_loss: 0.3823\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.0000e+00 - loss: 0.7120 - val_accuracy: 2.5000e-04 - val_loss: 1.5117\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.0000e+00 - loss: 0.6569 - val_accuracy: 2.5000e-04 - val_loss: 0.2824\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.0000e+00 - loss: 1.2711 - val_accuracy: 2.5000e-04 - val_loss: 0.3183\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 0.2525 - val_accuracy: 2.5000e-04 - val_loss: 5.4419\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.0000e+00 - loss: 1.5537 - val_accuracy: 2.5000e-04 - val_loss: 0.2787\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.0000e+00 - loss: 0.3406 - val_accuracy: 2.5000e-04 - val_loss: 0.1552\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 1.4068 - val_accuracy: 2.5000e-04 - val_loss: 0.0530\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 2.5000e-04 - val_loss: 0.0513\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.0000e+00 - loss: 1.3011 - val_accuracy: 2.5000e-04 - val_loss: 0.0564\n"
     ]
    }
   ],
   "source": [
    "# Start timer for training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model with TensorBoard callback\n",
    "history = dset_model_Perceptron.fit(X_train, y_train, epochs=total_epoch, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "# End timer for training time\n",
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction and calculating the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step\n",
      "Metrics:\n",
      "Model type: perceptron\n",
      "dataset: addition_dataset_2\n",
      "Accuracy: 1.0\n",
      "MSE: 0.05638053600668246\n",
      "MAE: 0.23360124123096465\n",
      "RMSE: 0.23744585910620228\n",
      "F1 Score: 1.0\n",
      "Training Time: 22.666709184646606\n",
      "Inference Time: 0.11066842079162598\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = dset_model_Perceptron.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "# Calculate accuracy with threshold\n",
    "threshold = 0.5  # Define the threshold\n",
    "correct_predictions = np.sum(np.abs(y_test - predictions.flatten()) <= threshold)\n",
    "total_predictions = len(y_test)\n",
    "accuracy = correct_predictions / total_predictions  # Final accuracy\n",
    "mse = mean_squared_error(y_test, predictions)  # Mean Squared Error\n",
    "mae = mean_absolute_error(y_test, predictions)  # Mean Absolute Error\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "f1 = f1_score(y_test, predictions.round(), average='micro')  # F1 Score\n",
    "\n",
    "# Calculate inference time\n",
    "start_time = time.time()\n",
    "predictions = dset_model_Perceptron.predict(X_test)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Print and store metrics\n",
    "metrics = {\n",
    "    'Model type': model_name,\n",
    "    'dataset': dataset_name,\n",
    "    'Accuracy': accuracy,\n",
    "    'MSE': mse,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'F1 Score': f1,\n",
    "    'Training Time': training_time,\n",
    "    'Inference Time': inference_time\n",
    "}\n",
    "\n",
    "print(\"Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "# Store metrics in a list\n",
    "metrics_list = list(metrics.values())\n",
    "pd.DataFrame([metrics_list], columns=metrics.keys()).to_csv('./../../Observation/'+model_name+'/'+model_name+dataset_name+'metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a function to generate models for different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 176566640.0000 - val_accuracy: 0.0000e+00 - val_loss: 40225732.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.0000e+00 - loss: 25304700.0000 - val_accuracy: 0.0000e+00 - val_loss: 2668801.2500\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.0000e+00 - loss: 1408125.5000 - val_accuracy: 2.5000e-04 - val_loss: 49373.0977\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.0000e+00 - loss: 22088.9355 - val_accuracy: 2.5000e-04 - val_loss: 185.2908\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.0000e+00 - loss: 70.7563 - val_accuracy: 2.5000e-04 - val_loss: 0.1200\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.0000e+00 - loss: 0.0775 - val_accuracy: 2.5000e-04 - val_loss: 0.0395\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.0000e+00 - loss: 0.0395 - val_accuracy: 2.5000e-04 - val_loss: 0.0387\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.0000e+00 - loss: 0.0394 - val_accuracy: 2.5000e-04 - val_loss: 0.0387\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.0000e+00 - loss: 0.0390 - val_accuracy: 2.5000e-04 - val_loss: 0.0387\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.0000e+00 - loss: 0.0397 - val_accuracy: 2.5000e-04 - val_loss: 0.0387\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 0.0389 - val_accuracy: 2.5000e-04 - val_loss: 0.0387\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.0000e+00 - loss: 0.0399 - val_accuracy: 2.5000e-04 - val_loss: 0.0387\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.0000e+00 - loss: 0.0393 - val_accuracy: 2.5000e-04 - val_loss: 0.0386\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 0.0393 - val_accuracy: 2.5000e-04 - val_loss: 0.0385\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.0000e+00 - loss: 0.0393 - val_accuracy: 2.5000e-04 - val_loss: 0.0385\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 0.0396 - val_accuracy: 2.5000e-04 - val_loss: 0.0387\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.0000e+00 - loss: 0.0392 - val_accuracy: 2.5000e-04 - val_loss: 0.0386\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 0.0392 - val_accuracy: 2.5000e-04 - val_loss: 0.0385\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.0000e+00 - loss: 0.0390 - val_accuracy: 2.5000e-04 - val_loss: 0.0382\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.0000e+00 - loss: 0.0388 - val_accuracy: 2.5000e-04 - val_loss: 0.0381\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.0000e+00 - loss: 0.0390 - val_accuracy: 2.5000e-04 - val_loss: 0.0378\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 0.0389 - val_accuracy: 2.5000e-04 - val_loss: 0.0385\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.0000e+00 - loss: 0.0385 - val_accuracy: 2.5000e-04 - val_loss: 0.0379\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.0000e+00 - loss: 0.0379 - val_accuracy: 2.5000e-04 - val_loss: 0.0370\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.0000e+00 - loss: 0.0380 - val_accuracy: 2.5000e-04 - val_loss: 0.0366\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 0.0373 - val_accuracy: 2.5000e-04 - val_loss: 0.0359\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.0000e+00 - loss: 0.0366 - val_accuracy: 2.5000e-04 - val_loss: 0.0351\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 0.0357 - val_accuracy: 2.5000e-04 - val_loss: 0.0354\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.0000e+00 - loss: 0.0347 - val_accuracy: 2.5000e-04 - val_loss: 0.0340\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.0000e+00 - loss: 0.0329 - val_accuracy: 2.5000e-04 - val_loss: 0.0337\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 0.0331 - val_accuracy: 2.5000e-04 - val_loss: 0.0296\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.0000e+00 - loss: 0.0304 - val_accuracy: 2.5000e-04 - val_loss: 0.0270\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.0000e+00 - loss: 0.0290 - val_accuracy: 2.5000e-04 - val_loss: 0.0248\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 0.0272 - val_accuracy: 2.5000e-04 - val_loss: 0.0224\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.0000e+00 - loss: 0.0239 - val_accuracy: 2.5000e-04 - val_loss: 0.0182\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.0000e+00 - loss: 0.0214 - val_accuracy: 2.5000e-04 - val_loss: 0.0204\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.0000e+00 - loss: 0.0209 - val_accuracy: 2.5000e-04 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.0000e+00 - loss: 0.0523 - val_accuracy: 2.5000e-04 - val_loss: 3.4203\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.0000e+00 - loss: 3.4265 - val_accuracy: 2.5000e-04 - val_loss: 0.0057\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.0000e+00 - loss: 0.6351 - val_accuracy: 2.5000e-04 - val_loss: 0.7261\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 2.1967 - val_accuracy: 2.5000e-04 - val_loss: 0.0088\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.0000e+00 - loss: 0.1233 - val_accuracy: 2.5000e-04 - val_loss: 0.0127\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.0000e+00 - loss: 1.2717 - val_accuracy: 2.5000e-04 - val_loss: 0.0058\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.0000e+00 - loss: 0.0785 - val_accuracy: 2.5000e-04 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.0000e+00 - loss: 6.4910 - val_accuracy: 2.5000e-04 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 2.5000e-04 - val_loss: 5.8415e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 2.5000e-04 - val_loss: 6.5957e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.0000e+00 - loss: 0.3997 - val_accuracy: 2.5000e-04 - val_loss: 0.0014\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.0000e+00 - loss: 0.3411 - val_accuracy: 2.5000e-04 - val_loss: 3.0289e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.0000e+00 - loss: 0.6952 - val_accuracy: 2.5000e-04 - val_loss: 3.3738e-04\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step\n",
      "Metrics:\n",
      "Accuracy: 1.0\n",
      "MSE: 0.00033737751769041325\n",
      "MAE: 0.01790964615345001\n",
      "RMSE: 0.018367839222140782\n",
      "F1 Score: 1.0\n",
      "Training Time: 21.378204107284546\n",
      "Inference Time: 0.10969090461730957\n",
      "Model type: perceptron\n",
      "dataset: addition_dataset_2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "def configure_model(layers_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy']):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    for layer_config in layers_config:\n",
    "        neurons, layer_type = layer_config\n",
    "        if layer_type == 'dense':\n",
    "            model.add(layers.Dense(neurons))\n",
    "        elif layer_type == 'dropout':\n",
    "            model.add(layers.Dropout(neurons))\n",
    "        elif layer_type == 'activation':\n",
    "            model.add(layers.Activation(neurons))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, model_name='perceptron', dataset_name=\"addition_dataset_2\", total_epoch=50):\n",
    "    tensorboard_callback = TensorBoard(log_dir='./../../Observation/'+model_name+'/'+model_name+dataset_name+'logs')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=total_epoch, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    return model, history, predictions, training_time\n",
    "\n",
    "def test_model(model, X_test, y_test, model_name='perceptron', dataset_name=\"addition_dataset_2\"):\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict(X_test)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    metrics = calculate_metrics(predictions, y_test)\n",
    "    metrics['Training Time'] = training_time\n",
    "    metrics['Inference Time'] = inference_time\n",
    "    metrics['Model type'] = model_name\n",
    "    metrics['dataset'] = dataset_name\n",
    "\n",
    "    print(\"Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    metrics_list = list(metrics.values())\n",
    "    pd.DataFrame([metrics_list], columns=metrics.keys()).to_csv('./../../Observation/'+model_name+'/'+model_name+dataset_name+'metrics.csv', index=False)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def calculate_metrics(predictions, true_labels):\n",
    "    threshold = 0.5  # Define the threshold\n",
    "    correct_predictions = np.sum(np.abs(true_labels - predictions.flatten()) <= threshold)\n",
    "    total_predictions = len(true_labels)\n",
    "    accuracy = correct_predictions / total_predictions  # Final accuracy\n",
    "    mse = mean_squared_error(true_labels, predictions)  # Mean Squared Error\n",
    "    mae = mean_absolute_error(true_labels, predictions)  # Mean Absolute Error\n",
    "    rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "    f1 = f1_score(true_labels.round(), predictions.round(), average='micro')  # F1 Score\n",
    "\n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "# Load dataset\n",
    "dataset_name = \"addition_dataset_2\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "perceptron_config = [(1, 'dense')]\n",
    "model = configure_model(perceptron_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 32999668.0000 - val_accuracy: 2.5000e-04 - val_loss: 200477.4688\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 2.7153e-05 - loss: 61796.8359 - val_accuracy: 2.5000e-04 - val_loss: 2.0011\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 3.3209e-06 - loss: 0.4779 - val_accuracy: 2.5000e-04 - val_loss: 0.0213\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 7.1847e-05 - loss: 0.0220 - val_accuracy: 2.5000e-04 - val_loss: 0.0207\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 2.6210e-04 - loss: 0.0211 - val_accuracy: 2.5000e-04 - val_loss: 0.0205\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 3.8047e-05 - loss: 0.0212 - val_accuracy: 2.5000e-04 - val_loss: 0.0203\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 8.9988e-05 - loss: 0.0205 - val_accuracy: 2.5000e-04 - val_loss: 0.0203\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 1.2794e-05 - loss: 0.0208 - val_accuracy: 2.5000e-04 - val_loss: 0.0203\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 1.1108e-04 - loss: 0.0207 - val_accuracy: 2.5000e-04 - val_loss: 0.0202\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 4.9031e-05 - loss: 0.0206 - val_accuracy: 2.5000e-04 - val_loss: 0.0202\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 1.4444e-04 - loss: 0.0208 - val_accuracy: 2.5000e-04 - val_loss: 0.0202\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 5.6875e-05 - loss: 0.0205 - val_accuracy: 2.5000e-04 - val_loss: 0.0202\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 1.1647e-04 - loss: 0.0207 - val_accuracy: 2.5000e-04 - val_loss: 0.0201\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 4.4049e-05 - loss: 0.0205 - val_accuracy: 2.5000e-04 - val_loss: 0.0201\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 1.5128e-05 - loss: 0.0205 - val_accuracy: 2.5000e-04 - val_loss: 0.0200\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 4.2383e-04 - loss: 0.0204 - val_accuracy: 2.5000e-04 - val_loss: 0.0200\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 8.9453e-06 - loss: 0.0202 - val_accuracy: 2.5000e-04 - val_loss: 0.0197\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 8.6589e-06 - loss: 0.0202 - val_accuracy: 2.5000e-04 - val_loss: 0.0196\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 9.2677e-05 - loss: 0.0201 - val_accuracy: 2.5000e-04 - val_loss: 0.0194\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 3.1946e-05 - loss: 0.0200 - val_accuracy: 2.5000e-04 - val_loss: 0.0194\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 1.7464e-04 - loss: 0.0196 - val_accuracy: 2.5000e-04 - val_loss: 0.0196\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 1.1489e-04 - loss: 0.0191 - val_accuracy: 2.5000e-04 - val_loss: 0.0192\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 6.9672e-06 - loss: 0.0188 - val_accuracy: 2.5000e-04 - val_loss: 0.0181\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 1.0890e-04 - loss: 0.0184 - val_accuracy: 2.5000e-04 - val_loss: 0.0175\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 3.8276e-05 - loss: 0.0179 - val_accuracy: 2.5000e-04 - val_loss: 0.0168\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 3.3416e-05 - loss: 0.0174 - val_accuracy: 2.5000e-04 - val_loss: 0.0167\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 4.5066e-05 - loss: 0.0169 - val_accuracy: 2.5000e-04 - val_loss: 0.0146\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 4.8218e-05 - loss: 0.0160 - val_accuracy: 2.5000e-04 - val_loss: 0.0132\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 7.8485e-05 - loss: 0.0145 - val_accuracy: 2.5000e-04 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 5.4745e-05 - loss: 0.0139 - val_accuracy: 2.5000e-04 - val_loss: 0.0128\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 6.1700e-05 - loss: 0.0123 - val_accuracy: 2.5000e-04 - val_loss: 0.0297\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 2.7346e-05 - loss: 0.0256 - val_accuracy: 2.5000e-04 - val_loss: 0.0066\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 1.5286e-05 - loss: 0.9756 - val_accuracy: 2.5000e-04 - val_loss: 0.0053\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 3.2993e-05 - loss: 0.0436 - val_accuracy: 2.5000e-04 - val_loss: 0.0049\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 1.2793e-04 - loss: 1.4938 - val_accuracy: 2.5000e-04 - val_loss: 0.0040\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 7.1065e-06 - loss: 0.0723 - val_accuracy: 2.5000e-04 - val_loss: 0.1773\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 9.7236e-05 - loss: 2.5030 - val_accuracy: 2.5000e-04 - val_loss: 0.0018\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 9.9036e-05 - loss: 0.3541 - val_accuracy: 2.5000e-04 - val_loss: 0.3596\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 1.1035e-04 - loss: 0.6211 - val_accuracy: 2.5000e-04 - val_loss: 1.3433\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 3.5838e-06 - loss: 0.5767 - val_accuracy: 2.5000e-04 - val_loss: 9.7891\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 8.7410e-05 - loss: 4.9477 - val_accuracy: 2.5000e-04 - val_loss: 0.0101\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 6.6930e-05 - loss: 0.2085 - val_accuracy: 2.5000e-04 - val_loss: 4.9217\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 8.0899e-06 - loss: 0.4795 - val_accuracy: 2.5000e-04 - val_loss: 0.0301\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 1.5395e-04 - loss: 4.3818 - val_accuracy: 2.5000e-04 - val_loss: 2.0839e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 2.7346e-05 - loss: 7.2877e-04 - val_accuracy: 2.5000e-04 - val_loss: 0.8946\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 1.9732e-05 - loss: 1.1628 - val_accuracy: 2.5000e-04 - val_loss: 5.5169e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 2.9704e-05 - loss: 1.6509 - val_accuracy: 2.5000e-04 - val_loss: 8.3952e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 5.0133e-05 - loss: 0.0090 - val_accuracy: 2.5000e-04 - val_loss: 0.0081\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 4.4302e-05 - loss: 14.5058 - val_accuracy: 2.5000e-04 - val_loss: 4.4866e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 3.8737e-05 - loss: 5.1492e-05 - val_accuracy: 2.5000e-04 - val_loss: 4.1730e-05\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step\n",
      "Metrics:\n",
      "Accuracy: 1.0\n",
      "MSE: 4.1729579976685926e-05\n",
      "MAE: 0.005596682674484327\n",
      "RMSE: 0.006459843649554216\n",
      "F1 Score: 0.7512500000000001\n",
      "Training Time: 21.00800061225891\n",
      "Inference Time: 0.09811186790466309\n",
      "Model type: perceptron\n",
      "dataset: substraction_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"substraction_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "perceptron_config = [(1, 'dense')]\n",
    "model = configure_model(perceptron_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 404240352.0000 - val_accuracy: 2.5000e-04 - val_loss: 257967552.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.0000e+00 - loss: 227182016.0000 - val_accuracy: 0.0000e+00 - val_loss: 131959088.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.0000e+00 - loss: 111914528.0000 - val_accuracy: 0.0000e+00 - val_loss: 58920136.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.0000e+00 - loss: 48665076.0000 - val_accuracy: 0.0000e+00 - val_loss: 21791256.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.0000e+00 - loss: 17112342.0000 - val_accuracy: 0.0000e+00 - val_loss: 6228235.5000\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.0000e+00 - loss: 4552762.5000 - val_accuracy: 0.0000e+00 - val_loss: 1244061.2500\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.0000e+00 - loss: 849058.8750 - val_accuracy: 0.0000e+00 - val_loss: 154499.4531\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.0000e+00 - loss: 95270.6797 - val_accuracy: 0.0000e+00 - val_loss: 10222.0508\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 5667.1787 - val_accuracy: 0.0000e+00 - val_loss: 301.4794\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.0000e+00 - loss: 147.9086 - val_accuracy: 0.0000e+00 - val_loss: 3.8855\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.0000e+00 - loss: 2.2540 - val_accuracy: 0.0000e+00 - val_loss: 0.8749\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.0000e+00 - loss: 0.8955 - val_accuracy: 0.0000e+00 - val_loss: 0.8686\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.0000e+00 - loss: 0.9009 - val_accuracy: 0.0000e+00 - val_loss: 0.8677\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 0.8858 - val_accuracy: 0.0000e+00 - val_loss: 0.8671\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.0000e+00 - loss: 0.8752 - val_accuracy: 0.0000e+00 - val_loss: 0.8671\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.0000e+00 - loss: 0.8657 - val_accuracy: 0.0000e+00 - val_loss: 0.8662\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 0.8960 - val_accuracy: 0.0000e+00 - val_loss: 0.8664\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.0000e+00 - loss: 0.8728 - val_accuracy: 0.0000e+00 - val_loss: 0.8667\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.0000e+00 - loss: 0.8743 - val_accuracy: 0.0000e+00 - val_loss: 0.8650\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 0.8790 - val_accuracy: 0.0000e+00 - val_loss: 0.8630\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 0.8719 - val_accuracy: 0.0000e+00 - val_loss: 0.8620\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.0000e+00 - loss: 0.8774 - val_accuracy: 0.0000e+00 - val_loss: 0.8617\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.0000e+00 - loss: 0.8889 - val_accuracy: 0.0000e+00 - val_loss: 0.8575\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.0000e+00 - loss: 0.8740 - val_accuracy: 0.0000e+00 - val_loss: 0.8547\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.0000e+00 - loss: 0.8690 - val_accuracy: 0.0000e+00 - val_loss: 0.8531\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 0.8445 - val_accuracy: 0.0000e+00 - val_loss: 0.8458\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.0000e+00 - loss: 0.8556 - val_accuracy: 0.0000e+00 - val_loss: 0.8394\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.0000e+00 - loss: 0.8550 - val_accuracy: 0.0000e+00 - val_loss: 0.8315\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0000e+00 - loss: 0.8334 - val_accuracy: 0.0000e+00 - val_loss: 0.8186\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.0000e+00 - loss: 0.8411 - val_accuracy: 0.0000e+00 - val_loss: 0.8084\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.0000e+00 - loss: 0.8186 - val_accuracy: 0.0000e+00 - val_loss: 0.7891\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.0000e+00 - loss: 0.7988 - val_accuracy: 0.0000e+00 - val_loss: 0.7680\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.0000e+00 - loss: 0.7737 - val_accuracy: 0.0000e+00 - val_loss: 0.7444\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.0000e+00 - loss: 0.7497 - val_accuracy: 0.0000e+00 - val_loss: 0.7217\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.0000e+00 - loss: 0.7153 - val_accuracy: 0.0000e+00 - val_loss: 0.6704\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.0000e+00 - loss: 0.6867 - val_accuracy: 0.0000e+00 - val_loss: 0.6571\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.0000e+00 - loss: 0.6385 - val_accuracy: 0.0000e+00 - val_loss: 0.5774\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.0000e+00 - loss: 0.5740 - val_accuracy: 0.0000e+00 - val_loss: 0.5121\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.0000e+00 - loss: 0.5132 - val_accuracy: 0.0000e+00 - val_loss: 0.4446\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.0000e+00 - loss: 0.4395 - val_accuracy: 0.0000e+00 - val_loss: 0.3556\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.0000e+00 - loss: 0.3736 - val_accuracy: 0.0000e+00 - val_loss: 0.2884\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.0000e+00 - loss: 0.3085 - val_accuracy: 0.0000e+00 - val_loss: 0.2597\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.0000e+00 - loss: 0.2505 - val_accuracy: 0.0000e+00 - val_loss: 0.1485\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0000e+00 - loss: 0.1750 - val_accuracy: 0.0000e+00 - val_loss: 0.0908\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.0000e+00 - loss: 0.1374 - val_accuracy: 2.5000e-04 - val_loss: 0.1710\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.0000e+00 - loss: 0.1886 - val_accuracy: 2.5000e-04 - val_loss: 0.0893\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.0000e+00 - loss: 0.1673 - val_accuracy: 2.5000e-04 - val_loss: 0.0215\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.0000e+00 - loss: 1.3033 - val_accuracy: 2.5000e-04 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.0000e+00 - loss: 0.0115 - val_accuracy: 2.5000e-04 - val_loss: 0.0071\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.0000e+00 - loss: 0.0104 - val_accuracy: 2.5000e-04 - val_loss: 0.0124\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step\n",
      "Metrics:\n",
      "Accuracy: 1.0\n",
      "MSE: 0.012357727905259502\n",
      "MAE: 0.11110236239805818\n",
      "RMSE: 0.1111653179065283\n",
      "F1 Score: 1.0\n",
      "Training Time: 21.08300805091858\n",
      "Inference Time: 0.1001291275024414\n",
      "Model type: perceptron\n",
      "dataset: doubling_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"doubling_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "perceptron_config = [(1, 'dense')]\n",
    "model = configure_model(perceptron_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.0000e+00 - loss: 259024576.0000 - val_accuracy: 2.5000e-04 - val_loss: 146256224.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.0000e+00 - loss: 121991432.0000 - val_accuracy: 2.5000e-04 - val_loss: 60912344.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.0000e+00 - loss: 48876856.0000 - val_accuracy: 2.5000e-04 - val_loss: 20386994.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.0000e+00 - loss: 15556241.0000 - val_accuracy: 2.5000e-04 - val_loss: 5007388.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.0000e+00 - loss: 3517842.7500 - val_accuracy: 2.5000e-04 - val_loss: 805112.8125\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 520289.2812 - val_accuracy: 2.5000e-04 - val_loss: 73434.8438\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 42843.9805 - val_accuracy: 2.5000e-04 - val_loss: 3190.6177\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.0000e+00 - loss: 1647.2328 - val_accuracy: 2.5000e-04 - val_loss: 54.0659\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.0000e+00 - loss: 24.8103 - val_accuracy: 2.5000e-04 - val_loss: 1.3391\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 1.1869 - val_accuracy: 2.5000e-04 - val_loss: 1.1079\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.0000e+00 - loss: 1.0614 - val_accuracy: 2.5000e-04 - val_loss: 1.1081\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 1.0676 - val_accuracy: 2.5000e-04 - val_loss: 1.1078\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.0000e+00 - loss: 1.0691 - val_accuracy: 2.5000e-04 - val_loss: 1.1075\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 1.0606 - val_accuracy: 2.5000e-04 - val_loss: 1.1075\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 1.0866 - val_accuracy: 2.5000e-04 - val_loss: 1.1067\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.0000e+00 - loss: 1.0603 - val_accuracy: 2.5000e-04 - val_loss: 1.1065\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.0000e+00 - loss: 1.0751 - val_accuracy: 2.5000e-04 - val_loss: 1.1062\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.0000e+00 - loss: 1.0722 - val_accuracy: 2.5000e-04 - val_loss: 1.1050\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.0000e+00 - loss: 1.0780 - val_accuracy: 2.5000e-04 - val_loss: 1.1052\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.0000e+00 - loss: 1.0695 - val_accuracy: 2.5000e-04 - val_loss: 1.1033\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.0000e+00 - loss: 1.0478 - val_accuracy: 2.5000e-04 - val_loss: 1.1014\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.0000e+00 - loss: 1.0583 - val_accuracy: 2.5000e-04 - val_loss: 1.1034\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.0000e+00 - loss: 1.0551 - val_accuracy: 2.5000e-04 - val_loss: 1.0985\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 1.0583 - val_accuracy: 2.5000e-04 - val_loss: 1.0945\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.0000e+00 - loss: 1.0611 - val_accuracy: 2.5000e-04 - val_loss: 1.0924\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0000e+00 - loss: 1.0677 - val_accuracy: 2.5000e-04 - val_loss: 1.0877\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.0000e+00 - loss: 1.0590 - val_accuracy: 2.5000e-04 - val_loss: 1.0791\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.0000e+00 - loss: 1.0613 - val_accuracy: 2.5000e-04 - val_loss: 1.0703\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.0000e+00 - loss: 1.0274 - val_accuracy: 2.5000e-04 - val_loss: 1.1420\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.0000e+00 - loss: 1.0542 - val_accuracy: 2.5000e-04 - val_loss: 1.0898\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.0000e+00 - loss: 1.0237 - val_accuracy: 2.5000e-04 - val_loss: 1.0375\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.0000e+00 - loss: 1.0048 - val_accuracy: 2.5000e-04 - val_loss: 1.1240\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.0000e+00 - loss: 0.9986 - val_accuracy: 2.5000e-04 - val_loss: 1.0266\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.0000e+00 - loss: 0.9748 - val_accuracy: 2.5000e-04 - val_loss: 0.9606\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.0000e+00 - loss: 0.9313 - val_accuracy: 2.5000e-04 - val_loss: 1.1256\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.0000e+00 - loss: 0.9341 - val_accuracy: 2.5000e-04 - val_loss: 0.8816\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.0000e+00 - loss: 0.9470 - val_accuracy: 2.5000e-04 - val_loss: 0.8446\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.0000e+00 - loss: 0.8391 - val_accuracy: 2.5000e-04 - val_loss: 0.8053\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.0000e+00 - loss: 0.8332 - val_accuracy: 2.5000e-04 - val_loss: 1.0869\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.0000e+00 - loss: 0.9192 - val_accuracy: 2.5000e-04 - val_loss: 0.7852\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.0000e+00 - loss: 0.7829 - val_accuracy: 2.5000e-04 - val_loss: 0.7215\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.0000e+00 - loss: 0.8551 - val_accuracy: 2.5000e-04 - val_loss: 0.6319\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.0000e+00 - loss: 0.8212 - val_accuracy: 2.5000e-04 - val_loss: 0.7392\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.0000e+00 - loss: 0.9303 - val_accuracy: 2.5000e-04 - val_loss: 2.2400\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.0000e+00 - loss: 1.2036 - val_accuracy: 2.5000e-04 - val_loss: 0.8139\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.0000e+00 - loss: 0.8224 - val_accuracy: 2.5000e-04 - val_loss: 2.2712\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.0000e+00 - loss: 0.8826 - val_accuracy: 2.5000e-04 - val_loss: 0.6688\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.0000e+00 - loss: 0.8575 - val_accuracy: 2.5000e-04 - val_loss: 0.6755\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.0000e+00 - loss: 0.8208 - val_accuracy: 2.5000e-04 - val_loss: 1.6178\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.0000e+00 - loss: 0.7654 - val_accuracy: 2.5000e-04 - val_loss: 0.6213\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step\n",
      "Metrics:\n",
      "Accuracy: 0.36975\n",
      "MSE: 0.6213223162992106\n",
      "MAE: 0.679725683070181\n",
      "RMSE: 0.7882400118613687\n",
      "F1 Score: 0.33275\n",
      "Training Time: 21.37050700187683\n",
      "Inference Time: 0.10793614387512207\n",
      "Model type: perceptron\n",
      "dataset: simple_sin_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"simple_sin_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "perceptron_config = [(1, 'dense')]\n",
    "model = configure_model(perceptron_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 0.0000e+00 - loss: 74690936.0000 - val_accuracy: 0.0000e+00 - val_loss: 24646334.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.0000e+00 - loss: 17297280.0000 - val_accuracy: 2.5000e-04 - val_loss: 3641549.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.0000e+00 - loss: 2281712.0000 - val_accuracy: 2.5000e-04 - val_loss: 244342.1875\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.0000e+00 - loss: 134401.2969 - val_accuracy: 2.5000e-04 - val_loss: 5829.6509\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.0000e+00 - loss: 2716.5352 - val_accuracy: 2.5000e-04 - val_loss: 37.4851\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 1.1117e-04 - loss: 15.3713 - val_accuracy: 2.5000e-04 - val_loss: 0.7211\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 4.1018e-04 - loss: 0.6972 - val_accuracy: 2.5000e-04 - val_loss: 0.6886\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 1.6660e-04 - loss: 0.6785 - val_accuracy: 2.5000e-04 - val_loss: 0.6885\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 1.0227e-04 - loss: 0.6842 - val_accuracy: 2.5000e-04 - val_loss: 0.6884\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 2.5098e-04 - loss: 0.6857 - val_accuracy: 2.5000e-04 - val_loss: 0.6887\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 2.7718e-04 - loss: 0.6830 - val_accuracy: 2.5000e-04 - val_loss: 0.6894\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 5.0363e-04 - loss: 0.6796 - val_accuracy: 2.5000e-04 - val_loss: 0.6884\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 3.4680e-04 - loss: 0.6858 - val_accuracy: 2.5000e-04 - val_loss: 0.6897\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 4.3564e-04 - loss: 0.6844 - val_accuracy: 2.5000e-04 - val_loss: 0.6877\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 4.2049e-04 - loss: 0.6897 - val_accuracy: 2.5000e-04 - val_loss: 0.6877\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 3.1083e-04 - loss: 0.6834 - val_accuracy: 2.5000e-04 - val_loss: 0.6887\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 4.1940e-04 - loss: 0.6810 - val_accuracy: 2.5000e-04 - val_loss: 0.6893\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 5.3024e-04 - loss: 0.6826 - val_accuracy: 2.5000e-04 - val_loss: 0.6859\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 3.3641e-04 - loss: 0.6877 - val_accuracy: 2.5000e-04 - val_loss: 0.6855\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 2.5180e-04 - loss: 0.6867 - val_accuracy: 2.5000e-04 - val_loss: 0.6846\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 1.9163e-04 - loss: 0.6741 - val_accuracy: 2.5000e-04 - val_loss: 0.6843\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 1.9975e-04 - loss: 0.6815 - val_accuracy: 2.5000e-04 - val_loss: 0.6835\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 2.0363e-04 - loss: 0.6637 - val_accuracy: 2.5000e-04 - val_loss: 0.6795\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 3.3820e-04 - loss: 0.6817 - val_accuracy: 2.5000e-04 - val_loss: 0.6773\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 2.8475e-04 - loss: 0.6807 - val_accuracy: 2.5000e-04 - val_loss: 0.6732\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 1.1412e-04 - loss: 0.6665 - val_accuracy: 2.5000e-04 - val_loss: 0.6727\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 6.9255e-05 - loss: 0.6752 - val_accuracy: 2.5000e-04 - val_loss: 0.6645\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 4.2110e-04 - loss: 0.6676 - val_accuracy: 2.5000e-04 - val_loss: 0.6575\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 2.7891e-04 - loss: 0.6747 - val_accuracy: 2.5000e-04 - val_loss: 0.7021\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 2.5553e-04 - loss: 0.6866 - val_accuracy: 2.5000e-04 - val_loss: 0.6407\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 2.4616e-04 - loss: 0.6754 - val_accuracy: 2.5000e-04 - val_loss: 0.7207\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 1.5798e-04 - loss: 0.6639 - val_accuracy: 2.5000e-04 - val_loss: 0.7342\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 1.3281e-04 - loss: 0.6591 - val_accuracy: 2.5000e-04 - val_loss: 0.6069\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 2.3317e-04 - loss: 0.6420 - val_accuracy: 2.5000e-04 - val_loss: 0.9712\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 8.3023e-05 - loss: 0.6499 - val_accuracy: 2.5000e-04 - val_loss: 0.5674\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 8.7410e-05 - loss: 0.6896 - val_accuracy: 0.0000e+00 - val_loss: 0.7446\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.0000e+00 - loss: 0.7807 - val_accuracy: 0.0000e+00 - val_loss: 0.6306\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.0000e+00 - loss: 0.9180 - val_accuracy: 0.0000e+00 - val_loss: 0.5246\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.0000e+00 - loss: 0.7185 - val_accuracy: 0.0000e+00 - val_loss: 0.5989\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.0000e+00 - loss: 0.8444 - val_accuracy: 0.0000e+00 - val_loss: 0.8280\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.0000e+00 - loss: 0.8087 - val_accuracy: 0.0000e+00 - val_loss: 0.5343\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.0000e+00 - loss: 1.0586 - val_accuracy: 0.0000e+00 - val_loss: 0.8520\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 0.9323 - val_accuracy: 0.0000e+00 - val_loss: 0.9236\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.0000e+00 - loss: 0.8955 - val_accuracy: 0.0000e+00 - val_loss: 0.5024\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.0000e+00 - loss: 0.8828 - val_accuracy: 0.0000e+00 - val_loss: 0.7318\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 1.0113 - val_accuracy: 0.0000e+00 - val_loss: 0.4974\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.0000e+00 - loss: 0.9047 - val_accuracy: 0.0000e+00 - val_loss: 0.8901\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.0000e+00 - loss: 1.3901 - val_accuracy: 0.0000e+00 - val_loss: 1.1454\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.0000e+00 - loss: 0.9377 - val_accuracy: 0.0000e+00 - val_loss: 1.1515\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.0000e+00 - loss: 1.1348 - val_accuracy: 0.0000e+00 - val_loss: 1.1827\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step\n",
      "Metrics:\n",
      "Accuracy: 0.34725\n",
      "MSE: 1.1826974049986385\n",
      "MAE: 0.8894893123682887\n",
      "RMSE: 1.087518921673843\n",
      "F1 Score: 0.3365\n",
      "Training Time: 20.675564527511597\n",
      "Inference Time: 0.11498403549194336\n",
      "Model type: perceptron\n",
      "dataset: simple_cos_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"simple_cos_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "perceptron_config = [(1, 'dense')]\n",
    "model = configure_model(perceptron_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,dataset_name=dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
