{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "def configure_model(layers_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'],debugflag=False):\n",
    "    if debugflag:\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Dense(64, activation='linear', input_shape=(dset_features.shape[1],)),  # Hidden layer 1\n",
    "            layers.Dense(32, activation='selu'),  # Hidden layer 2\n",
    "            layers.Dense(1, activation='linear')  # Output layer\n",
    "            ])\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        return model\n",
    "        \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    for layer_config in layers_config:\n",
    "        layer_type = layer_config[0]\n",
    "\n",
    "        if layer_type == 'dense':\n",
    "            neurons, activation = layer_config[1], layer_config[2]\n",
    "            if len(layer_config) > 3 and layer_config[3] == 'input':\n",
    "                input_shape = layer_config[4]\n",
    "                model.add(layers.Dense(neurons, activation=activation, input_shape=(input_shape,)))\n",
    "            else:\n",
    "                model.add(layers.Dense(neurons, activation=activation))\n",
    "        elif layer_type == 'dropout':\n",
    "            rate = layer_config[1]\n",
    "            model.add(layers.Dropout(rate))\n",
    "        elif layer_type == 'activation':\n",
    "            activation = layer_config[1]\n",
    "            model.add(layers.Activation(activation))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, model_name='perceptron', dataset_name=\"addition_dataset_2\", total_epoch=50):\n",
    "    tensorboard_callback = TensorBoard(log_dir='./../../Observation/'+model_name+'/'+model_name+dataset_name+'logs')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=total_epoch, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    return model, history, predictions, training_time\n",
    "\n",
    "def test_model(model, X_test, y_test, model_name='perceptron', dataset_name=\"addition_dataset_2\",threshold=0.5):\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict(X_test)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    metrics = calculate_metrics(predictions, y_test,threshold)\n",
    "    metrics['Training Time'] = training_time\n",
    "    metrics['Inference Time'] = inference_time\n",
    "    metrics['Model type'] = model_name\n",
    "    metrics['dataset'] = dataset_name\n",
    "\n",
    "    print(\"Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    metrics_list = list(metrics.values())\n",
    "    pd.DataFrame([metrics_list], columns=metrics.keys()).to_csv('./../../Observation/'+model_name+'/'+model_name+dataset_name+'metrics.csv', index=False)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def calculate_metrics(predictions, true_labels, threshold=0.5):\n",
    "    #threshold = 0.5  # Define the threshold\n",
    "    correct_predictions = np.sum(np.abs(true_labels - predictions.flatten()) <= threshold)\n",
    "    total_predictions = len(true_labels)\n",
    "    accuracy = correct_predictions / total_predictions  # Final accuracy\n",
    "    mse = mean_squared_error(true_labels, predictions)  # Mean Squared Error\n",
    "    mae = mean_absolute_error(true_labels, predictions)  # Mean Absolute Error\n",
    "    rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "    f1 = f1_score(true_labels.round(), predictions.round(), average='micro')  # F1 Score\n",
    "\n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'F1 Score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 481413152.0000 - val_accuracy: 2.5000e-04 - val_loss: 1.4088\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3338 - val_accuracy: 2.5000e-04 - val_loss: 1.3082\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3239 - val_accuracy: 2.5000e-04 - val_loss: 1.3076\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3419 - val_accuracy: 2.5000e-04 - val_loss: 1.3068\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3308 - val_accuracy: 2.5000e-04 - val_loss: 1.3015\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3218 - val_accuracy: 2.5000e-04 - val_loss: 1.3038\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3573 - val_accuracy: 2.5000e-04 - val_loss: 1.2927\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 1.3304 - val_accuracy: 2.5000e-04 - val_loss: 1.2868\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3113 - val_accuracy: 2.5000e-04 - val_loss: 1.2833\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3205 - val_accuracy: 2.5000e-04 - val_loss: 1.2676\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3000 - val_accuracy: 2.5000e-04 - val_loss: 1.2599\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.2814 - val_accuracy: 2.5000e-04 - val_loss: 1.2544\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.2925 - val_accuracy: 2.5000e-04 - val_loss: 1.2241\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.2390 - val_accuracy: 2.5000e-04 - val_loss: 1.1962\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.2550 - val_accuracy: 2.5000e-04 - val_loss: 1.2134\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.2223 - val_accuracy: 2.5000e-04 - val_loss: 1.1143\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1000us/step - accuracy: 0.0000e+00 - loss: 1.1695 - val_accuracy: 2.5000e-04 - val_loss: 1.1884\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.1223 - val_accuracy: 2.5000e-04 - val_loss: 1.1437\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.1339 - val_accuracy: 2.5000e-04 - val_loss: 0.9674\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.1040 - val_accuracy: 2.5000e-04 - val_loss: 0.9322\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.0370 - val_accuracy: 2.5000e-04 - val_loss: 0.7471\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.0274 - val_accuracy: 2.5000e-04 - val_loss: 0.6508\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 5.0209 - val_accuracy: 2.5000e-04 - val_loss: 0.5092\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 133.5172 - val_accuracy: 2.5000e-04 - val_loss: 1.0982\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.8914 - val_accuracy: 2.5000e-04 - val_loss: 0.3348\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 7.3442 - val_accuracy: 2.5000e-04 - val_loss: 8.1824\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 166.0576 - val_accuracy: 2.5000e-04 - val_loss: 0.8739\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.3997 - val_accuracy: 2.5000e-04 - val_loss: 2.0879\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 57.5084 - val_accuracy: 2.5000e-04 - val_loss: 0.2426\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2.0936 - val_accuracy: 2.5000e-04 - val_loss: 2.7429\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 552.8361 - val_accuracy: 2.5000e-04 - val_loss: 0.1079\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1512 - val_accuracy: 2.5000e-04 - val_loss: 1.1680\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4758 - val_accuracy: 2.5000e-04 - val_loss: 0.8924\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 71.1151 - val_accuracy: 2.5000e-04 - val_loss: 0.0370\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 18.9953 - val_accuracy: 2.5000e-04 - val_loss: 0.0399\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 63.3721 - val_accuracy: 2.5000e-04 - val_loss: 23.5496\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 28.9150 - val_accuracy: 2.5000e-04 - val_loss: 214.1750\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 43.2572 - val_accuracy: 2.5000e-04 - val_loss: 0.0090\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2391 - val_accuracy: 2.5000e-04 - val_loss: 250.3193\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 127.2085 - val_accuracy: 2.5000e-04 - val_loss: 0.9693\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 101.2685 - val_accuracy: 2.5000e-04 - val_loss: 0.0057\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1113 - val_accuracy: 2.5000e-04 - val_loss: 0.2819\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 58.5002 - val_accuracy: 2.5000e-04 - val_loss: 23.5292\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3843 - val_accuracy: 2.5000e-04 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0027 - val_accuracy: 2.5000e-04 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 6.0301 - val_accuracy: 2.5000e-04 - val_loss: 16.7471\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 131.1038 - val_accuracy: 2.5000e-04 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 96.1629 - val_accuracy: 2.5000e-04 - val_loss: 4.7340\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.3715 - val_accuracy: 2.5000e-04 - val_loss: 1.5389e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2.5601e-04 - val_accuracy: 2.5000e-04 - val_loss: 7.4129e-04\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step\n",
      "Metrics:\n",
      "Accuracy: 1.0\n",
      "MSE: 0.0007412884949295666\n",
      "MAE: 0.027078717559576033\n",
      "RMSE: 0.02722661372498546\n",
      "F1 Score: 1.0\n",
      "Training Time: 32.38858103752136\n",
      "Inference Time: 0.1409907341003418\n",
      "Model type: multi_layer_perceptron\n",
      "dataset: addition_dataset_2\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"addition_dataset_2\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "#perceptron_config = [(1, 'dense')]\n",
    "mlp_config = [\n",
    "    ('dense', 64, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 32, 'selu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "mlp_config = [\n",
    "    ('dense', 3, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 6, 'relu'),\n",
    "    ('dense', 2, 'relu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "model = configure_model(mlp_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'],debugflag=False)\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2128811.5000 - val_accuracy: 2.5000e-04 - val_loss: 13249.8789\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 7985.8442 - val_accuracy: 2.5000e-04 - val_loss: 1491.3162\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1066.1755 - val_accuracy: 2.5000e-04 - val_loss: 357.1552\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 276.7928 - val_accuracy: 2.5000e-04 - val_loss: 113.7858\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 90.3148 - val_accuracy: 2.5000e-04 - val_loss: 40.2912\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 32.0452 - val_accuracy: 2.5000e-04 - val_loss: 14.2867\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 11.4246 - val_accuracy: 2.5000e-04 - val_loss: 4.7982\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.8734 - val_accuracy: 2.5000e-04 - val_loss: 1.6412\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3690 - val_accuracy: 2.5000e-04 - val_loss: 0.7801\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.7359 - val_accuracy: 2.5000e-04 - val_loss: 0.6048\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5933 - val_accuracy: 2.5000e-04 - val_loss: 0.5765\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5845 - val_accuracy: 2.5000e-04 - val_loss: 0.5727\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5831 - val_accuracy: 2.5000e-04 - val_loss: 0.5712\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5735 - val_accuracy: 2.5000e-04 - val_loss: 0.5691\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5724 - val_accuracy: 2.5000e-04 - val_loss: 0.5669\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5717 - val_accuracy: 2.5000e-04 - val_loss: 0.5635\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5714 - val_accuracy: 2.5000e-04 - val_loss: 0.5598\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5676 - val_accuracy: 2.5000e-04 - val_loss: 0.5551\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5654 - val_accuracy: 2.5000e-04 - val_loss: 0.5494\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5544 - val_accuracy: 2.5000e-04 - val_loss: 0.5431\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5418 - val_accuracy: 2.5000e-04 - val_loss: 0.5363\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5357 - val_accuracy: 2.5000e-04 - val_loss: 0.5288\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5316 - val_accuracy: 2.5000e-04 - val_loss: 0.5220\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5226 - val_accuracy: 2.5000e-04 - val_loss: 0.5158\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5144 - val_accuracy: 2.5000e-04 - val_loss: 0.5110\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5076 - val_accuracy: 2.5000e-04 - val_loss: 0.5074\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5066 - val_accuracy: 2.5000e-04 - val_loss: 0.5054\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.4982 - val_accuracy: 2.5000e-04 - val_loss: 0.5047\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5016 - val_accuracy: 2.5000e-04 - val_loss: 0.5045\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5021 - val_accuracy: 2.5000e-04 - val_loss: 0.5047\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4966 - val_accuracy: 2.5000e-04 - val_loss: 0.5046\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4946 - val_accuracy: 2.5000e-04 - val_loss: 0.5046\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.4976 - val_accuracy: 2.5000e-04 - val_loss: 0.5048\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4991 - val_accuracy: 2.5000e-04 - val_loss: 0.5048\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4975 - val_accuracy: 2.5000e-04 - val_loss: 0.5046\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.4988 - val_accuracy: 2.5000e-04 - val_loss: 0.5046\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.4989 - val_accuracy: 2.5000e-04 - val_loss: 0.5047\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5024 - val_accuracy: 2.5000e-04 - val_loss: 0.5050\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4965 - val_accuracy: 2.5000e-04 - val_loss: 0.5046\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4987 - val_accuracy: 2.5000e-04 - val_loss: 0.5046\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4980 - val_accuracy: 2.5000e-04 - val_loss: 0.5046\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5013 - val_accuracy: 2.5000e-04 - val_loss: 0.5047\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5006 - val_accuracy: 2.5000e-04 - val_loss: 0.5047\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4964 - val_accuracy: 2.5000e-04 - val_loss: 0.5048\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4959 - val_accuracy: 2.5000e-04 - val_loss: 0.5046\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4976 - val_accuracy: 2.5000e-04 - val_loss: 0.5047\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4954 - val_accuracy: 2.5000e-04 - val_loss: 0.5047\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4975 - val_accuracy: 2.5000e-04 - val_loss: 0.5046\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4970 - val_accuracy: 2.5000e-04 - val_loss: 0.5046\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4974 - val_accuracy: 2.5000e-04 - val_loss: 0.5050\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step\n",
      "Metrics:\n",
      "Accuracy: 0.71125\n",
      "MSE: 0.5050413401408207\n",
      "MAE: 0.6422266559305176\n",
      "RMSE: 0.7106626064039254\n",
      "F1 Score: 0.3305\n",
      "Training Time: 37.612273931503296\n",
      "Inference Time: 0.15517735481262207\n",
      "Model type: multi_layer_perceptron\n",
      "dataset: simple_sin_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"simple_sin_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "#perceptron_config = [(1, 'dense')]\n",
    "mlp_config = [\n",
    "    ('dense', 8, 'relu', 'input', dset_features.shape[1]),\n",
    "    ('dense', 6, 'relu'),\n",
    "    ('dense', 3, 'relu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "model = configure_model(mlp_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,model_name='multi_layer_perceptron',total_epoch=50,dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,dataset_name=dataset_name,model_name='multi_layer_perceptron',threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 647.2635 - val_accuracy: 0.0000e+00 - val_loss: 0.4975\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5015 - val_accuracy: 0.0000e+00 - val_loss: 0.4981\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5024 - val_accuracy: 0.0000e+00 - val_loss: 0.4960\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5048 - val_accuracy: 0.0000e+00 - val_loss: 0.5266\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5038 - val_accuracy: 0.0000e+00 - val_loss: 0.4979\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5065 - val_accuracy: 0.0000e+00 - val_loss: 0.4980\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5139 - val_accuracy: 0.0000e+00 - val_loss: 0.4987\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5173 - val_accuracy: 0.0000e+00 - val_loss: 0.5252\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5149 - val_accuracy: 0.0000e+00 - val_loss: 0.5479\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5213 - val_accuracy: 0.0000e+00 - val_loss: 0.5813\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5270 - val_accuracy: 0.0000e+00 - val_loss: 0.5507\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5475 - val_accuracy: 0.0000e+00 - val_loss: 0.5000\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5301 - val_accuracy: 0.0000e+00 - val_loss: 0.5018\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5730 - val_accuracy: 0.0000e+00 - val_loss: 0.6315\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5876 - val_accuracy: 0.0000e+00 - val_loss: 0.5054\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5828 - val_accuracy: 0.0000e+00 - val_loss: 0.4970\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5629 - val_accuracy: 0.0000e+00 - val_loss: 0.4982\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5589 - val_accuracy: 0.0000e+00 - val_loss: 0.5226\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5458 - val_accuracy: 0.0000e+00 - val_loss: 0.7139\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5514 - val_accuracy: 0.0000e+00 - val_loss: 0.5129\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5222 - val_accuracy: 0.0000e+00 - val_loss: 0.5224\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5291 - val_accuracy: 0.0000e+00 - val_loss: 0.4975\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5329 - val_accuracy: 0.0000e+00 - val_loss: 0.5020\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5137 - val_accuracy: 0.0000e+00 - val_loss: 0.4957\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.6636 - val_accuracy: 0.0000e+00 - val_loss: 0.4970\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5182 - val_accuracy: 0.0000e+00 - val_loss: 0.5021\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5170 - val_accuracy: 0.0000e+00 - val_loss: 0.5021\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5153 - val_accuracy: 0.0000e+00 - val_loss: 0.5214\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5160 - val_accuracy: 0.0000e+00 - val_loss: 0.5096\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5107 - val_accuracy: 0.0000e+00 - val_loss: 0.4959\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5086 - val_accuracy: 0.0000e+00 - val_loss: 0.4954\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5009 - val_accuracy: 0.0000e+00 - val_loss: 0.4956\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5047 - val_accuracy: 0.0000e+00 - val_loss: 0.4956\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5000 - val_accuracy: 0.0000e+00 - val_loss: 0.4959\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5054 - val_accuracy: 0.0000e+00 - val_loss: 0.4955\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5012 - val_accuracy: 0.0000e+00 - val_loss: 0.4956\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5009 - val_accuracy: 0.0000e+00 - val_loss: 0.4954\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4996 - val_accuracy: 0.0000e+00 - val_loss: 0.4955\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5009 - val_accuracy: 0.0000e+00 - val_loss: 0.4954\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5053 - val_accuracy: 0.0000e+00 - val_loss: 0.4957\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5028 - val_accuracy: 0.0000e+00 - val_loss: 0.4953\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5032 - val_accuracy: 0.0000e+00 - val_loss: 0.4953\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4974 - val_accuracy: 0.0000e+00 - val_loss: 0.4954\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4997 - val_accuracy: 0.0000e+00 - val_loss: 0.4955\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4992 - val_accuracy: 0.0000e+00 - val_loss: 0.4956\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4973 - val_accuracy: 0.0000e+00 - val_loss: 0.4954\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5005 - val_accuracy: 0.0000e+00 - val_loss: 0.4954\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5025 - val_accuracy: 0.0000e+00 - val_loss: 0.4954\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5057 - val_accuracy: 0.0000e+00 - val_loss: 0.4954\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4993 - val_accuracy: 0.0000e+00 - val_loss: 0.4955\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step\n",
      "Metrics:\n",
      "Accuracy: 0.7155\n",
      "MSE: 0.49550518843313535\n",
      "MAE: 0.634099730815216\n",
      "RMSE: 0.7039212942035035\n",
      "F1 Score: 0.337\n",
      "Training Time: 34.822160720825195\n",
      "Inference Time: 0.14689111709594727\n",
      "Model type: multi_layer_perceptron\n",
      "dataset: simple_cos_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"simple_cos_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "#perceptron_config = [(1, 'dense')]\n",
    "mlp_config = [\n",
    "    ('dense', 8, 'relu', 'input', dset_features.shape[1]),\n",
    "    ('dense', 6, 'relu'),\n",
    "    ('dense', 3, 'relu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "model = configure_model(mlp_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,model_name='multi_layer_perceptron',total_epoch=50,dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,dataset_name=dataset_name,model_name='multi_layer_perceptron',threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 6.0050e-05 - loss: 13228188.0000 - val_accuracy: 2.5000e-04 - val_loss: 2.6897\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.4151e-05 - loss: 2.7073 - val_accuracy: 2.5000e-04 - val_loss: 2.6594\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.2150e-04 - loss: 2.7643 - val_accuracy: 2.5000e-04 - val_loss: 2.6464\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 4.1130e-06 - loss: 2.6970 - val_accuracy: 2.5000e-04 - val_loss: 2.6275\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 4.0379e-05 - loss: 2.6502 - val_accuracy: 2.5000e-04 - val_loss: 2.5144\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 9.1050e-05 - loss: 2.6267 - val_accuracy: 2.5000e-04 - val_loss: 2.9362\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.3968e-05 - loss: 2.5274 - val_accuracy: 2.5000e-04 - val_loss: 2.4258\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0988e-05 - loss: 2.4382 - val_accuracy: 2.5000e-04 - val_loss: 2.3929\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.5634e-05 - loss: 2.3464 - val_accuracy: 2.5000e-04 - val_loss: 2.0973\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 8.0260e-05 - loss: 2.1881 - val_accuracy: 2.5000e-04 - val_loss: 1.9130\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 4.2310e-05 - loss: 2.2330 - val_accuracy: 2.5000e-04 - val_loss: 1.8214\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 3.7818e-05 - loss: 2.0388 - val_accuracy: 2.5000e-04 - val_loss: 2.1452\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 3.6242e-05 - loss: 2.3719 - val_accuracy: 2.5000e-04 - val_loss: 8.8766\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.6011e-04 - loss: 4.2648 - val_accuracy: 2.5000e-04 - val_loss: 3.0415\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.4519e-05 - loss: 2135.7456 - val_accuracy: 2.5000e-04 - val_loss: 0.8110\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 9.6673e-06 - loss: 179.1543 - val_accuracy: 2.5000e-04 - val_loss: 3.4895\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 5980.0952 - val_accuracy: 2.5000e-04 - val_loss: 0.5197\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.6984 - val_accuracy: 2.5000e-04 - val_loss: 0.4113\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 4.5889 - val_accuracy: 2.5000e-04 - val_loss: 2.1086\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 5147.7944 - val_accuracy: 2.5000e-04 - val_loss: 0.3242\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2664 - val_accuracy: 2.5000e-04 - val_loss: 0.1665\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0820e-04 - loss: 0.5062 - val_accuracy: 2.5000e-04 - val_loss: 0.3393\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.9361e-04 - loss: 802.9732 - val_accuracy: 2.5000e-04 - val_loss: 6.3537\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.4444e-04 - loss: 260.7915 - val_accuracy: 2.5000e-04 - val_loss: 0.2763\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 4.4302e-05 - loss: 162.3606 - val_accuracy: 2.5000e-04 - val_loss: 1977.2255\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.2703e-05 - loss: 695.4271 - val_accuracy: 2.5000e-04 - val_loss: 0.1038\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.9391e-05 - loss: 615.7020 - val_accuracy: 2.5000e-04 - val_loss: 0.6317\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.9304e-05 - loss: 105.9305 - val_accuracy: 2.5000e-04 - val_loss: 1.3150\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.3402e-04 - loss: 1955.7717 - val_accuracy: 2.5000e-04 - val_loss: 0.0775\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 5.7497e-05 - loss: 1661.5134 - val_accuracy: 2.5000e-04 - val_loss: 0.3481\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.4950e-07 - loss: 0.3093 - val_accuracy: 2.5000e-04 - val_loss: 0.2428\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 6.8283e-06 - loss: 0.2663 - val_accuracy: 2.5000e-04 - val_loss: 0.1688\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 7.9812e-05 - loss: 0.2741 - val_accuracy: 2.5000e-04 - val_loss: 4.8779\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 7.4664e-05 - loss: 354.4912 - val_accuracy: 2.5000e-04 - val_loss: 1989.9795\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 6.1035e-05 - loss: 129.9467 - val_accuracy: 2.5000e-04 - val_loss: 0.0503\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.8908e-05 - loss: 0.1360 - val_accuracy: 2.5000e-04 - val_loss: 0.0672\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.6409e-05 - loss: 95.8369 - val_accuracy: 2.5000e-04 - val_loss: 67.2527\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0612e-04 - loss: 383.3625 - val_accuracy: 2.5000e-04 - val_loss: 188.5289\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 3.1121e-05 - loss: 584.7255 - val_accuracy: 2.5000e-04 - val_loss: 331.6730\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.1334e-04 - loss: 89.4313 - val_accuracy: 2.5000e-04 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 7.7185e-05 - loss: 223.5655 - val_accuracy: 2.5000e-04 - val_loss: 0.4995\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.4654e-05 - loss: 0.5942 - val_accuracy: 2.5000e-04 - val_loss: 93.0359\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 6.2035e-05 - loss: 587.1091 - val_accuracy: 2.5000e-04 - val_loss: 662.7859\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.6011e-05 - loss: 771.0031 - val_accuracy: 2.5000e-04 - val_loss: 0.0052\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.3062e-05 - loss: 0.2253 - val_accuracy: 2.5000e-04 - val_loss: 0.5722\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 2.0074e-05 - loss: 1467.4766 - val_accuracy: 2.5000e-04 - val_loss: 0.0023\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.8341e-04 - loss: 0.0139 - val_accuracy: 2.5000e-04 - val_loss: 0.1683\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 4.7415e-05 - loss: 284.2609 - val_accuracy: 2.5000e-04 - val_loss: 382.8218\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 4.4302e-05 - loss: 5172.7871 - val_accuracy: 2.5000e-04 - val_loss: 0.0253\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 3.2363e-05 - loss: 0.0349 - val_accuracy: 2.5000e-04 - val_loss: 0.0155\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step\n",
      "Metrics:\n",
      "Accuracy: 1.0\n",
      "MSE: 0.015487226144225489\n",
      "MAE: 0.10750718969106675\n",
      "RMSE: 0.12444768436666666\n",
      "F1 Score: 0.75025\n",
      "Training Time: 32.981199979782104\n",
      "Inference Time: 0.12770295143127441\n",
      "Model type: multi_layer_perceptron\n",
      "dataset: substraction_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"substraction_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "#perceptron_config = [(1, 'dense')]\n",
    "mlp_config = [\n",
    "    ('dense', 64, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 32, 'selu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "mlp_config = [\n",
    "    ('dense', 3, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 6, 'relu'),\n",
    "    ('dense', 2, 'relu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "model = configure_model(mlp_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'],debugflag=True)\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 60435236.0000 - val_accuracy: 0.0000e+00 - val_loss: 26.9355\n",
      "Epoch 2/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 9.7074 - val_accuracy: 0.0000e+00 - val_loss: 8.6100\n",
      "Epoch 3/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 8.6249 - val_accuracy: 0.0000e+00 - val_loss: 8.5611\n",
      "Epoch 4/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 8.7294 - val_accuracy: 0.0000e+00 - val_loss: 8.6797\n",
      "Epoch 5/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 8.6514 - val_accuracy: 2.5000e-04 - val_loss: 8.4656\n",
      "Epoch 6/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 8.5430 - val_accuracy: 2.5000e-04 - val_loss: 8.4286\n",
      "Epoch 7/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 8.3908 - val_accuracy: 2.5000e-04 - val_loss: 8.0060\n",
      "Epoch 8/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 8.1659 - val_accuracy: 2.5000e-04 - val_loss: 7.7765\n",
      "Epoch 9/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 8.0529 - val_accuracy: 2.5000e-04 - val_loss: 7.5195\n",
      "Epoch 10/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 7.9038 - val_accuracy: 2.5000e-04 - val_loss: 7.4529\n",
      "Epoch 11/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 7.3087 - val_accuracy: 2.5000e-04 - val_loss: 6.7446\n",
      "Epoch 12/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 7.0392 - val_accuracy: 2.5000e-04 - val_loss: 6.3064\n",
      "Epoch 13/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 6.5018 - val_accuracy: 2.5000e-04 - val_loss: 7.5645\n",
      "Epoch 14/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 5.8575 - val_accuracy: 2.5000e-04 - val_loss: 6.6569\n",
      "Epoch 15/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 5.9601 - val_accuracy: 2.5000e-04 - val_loss: 5.7902\n",
      "Epoch 16/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 5.7825 - val_accuracy: 2.5000e-04 - val_loss: 3.2685\n",
      "Epoch 17/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 9.0573 - val_accuracy: 2.5000e-04 - val_loss: 2.6009\n",
      "Epoch 18/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 298.2971 - val_accuracy: 2.5000e-04 - val_loss: 4.6727\n",
      "Epoch 19/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 16.4011 - val_accuracy: 2.5000e-04 - val_loss: 1.8206\n",
      "Epoch 20/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 418.4140 - val_accuracy: 2.5000e-04 - val_loss: 2143.5935\n",
      "Epoch 21/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 9621.0547 - val_accuracy: 2.5000e-04 - val_loss: 0.4207\n",
      "Epoch 22/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.2561 - val_accuracy: 2.5000e-04 - val_loss: 1.0440\n",
      "Epoch 23/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 6.4867 - val_accuracy: 2.5000e-04 - val_loss: 0.5630\n",
      "Epoch 24/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 237.8194 - val_accuracy: 2.5000e-04 - val_loss: 0.3090\n",
      "Epoch 25/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1329.9340 - val_accuracy: 2.5000e-04 - val_loss: 0.1497\n",
      "Epoch 26/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4885 - val_accuracy: 2.5000e-04 - val_loss: 0.0997\n",
      "Epoch 27/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 681.2280 - val_accuracy: 2.5000e-04 - val_loss: 3.7265\n",
      "Epoch 28/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.3129 - val_accuracy: 2.5000e-04 - val_loss: 0.1976\n",
      "Epoch 29/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0888 - val_accuracy: 2.5000e-04 - val_loss: 0.1181\n",
      "Epoch 30/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 8.6547 - val_accuracy: 2.5000e-04 - val_loss: 12989.6240\n",
      "Epoch 31/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 5449.9814 - val_accuracy: 2.5000e-04 - val_loss: 0.0409\n",
      "Epoch 32/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0907 - val_accuracy: 2.5000e-04 - val_loss: 8.2758\n",
      "Epoch 33/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 41.7239 - val_accuracy: 2.5000e-04 - val_loss: 0.7258\n",
      "Epoch 34/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 355.2556 - val_accuracy: 2.5000e-04 - val_loss: 2464.9597\n",
      "Epoch 35/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 146.5321 - val_accuracy: 2.5000e-04 - val_loss: 77.8461\n",
      "Epoch 36/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 599.7705 - val_accuracy: 2.5000e-04 - val_loss: 1.7430\n",
      "Epoch 37/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1731 - val_accuracy: 2.5000e-04 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 648.9313 - val_accuracy: 2.5000e-04 - val_loss: 0.2536\n",
      "Epoch 39/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.4835 - val_accuracy: 2.5000e-04 - val_loss: 0.0023\n",
      "Epoch 40/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0033 - val_accuracy: 2.5000e-04 - val_loss: 0.3120\n",
      "Epoch 41/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 339.1908 - val_accuracy: 2.5000e-04 - val_loss: 0.0146\n",
      "Epoch 42/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 11.1696 - val_accuracy: 2.5000e-04 - val_loss: 0.4767\n",
      "Epoch 43/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1267.6917 - val_accuracy: 2.5000e-04 - val_loss: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 2.5000e-04 - val_loss: 0.0022\n",
      "Epoch 45/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 114.6600 - val_accuracy: 2.5000e-04 - val_loss: 0.0024\n",
      "Epoch 46/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 89.7462 - val_accuracy: 2.5000e-04 - val_loss: 6428.3389\n",
      "Epoch 47/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 404.1997 - val_accuracy: 2.5000e-04 - val_loss: 0.0052\n",
      "Epoch 48/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0017 - val_accuracy: 2.5000e-04 - val_loss: 0.0142\n",
      "Epoch 49/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 280.7107 - val_accuracy: 2.5000e-04 - val_loss: 4.8109e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 291.1207 - val_accuracy: 2.5000e-04 - val_loss: 0.1032\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step\n",
      "Metrics:\n",
      "Accuracy: 0.94025\n",
      "MSE: 0.10317527524702752\n",
      "MAE: 0.2904771137088537\n",
      "RMSE: 0.32120908338188\n",
      "F1 Score: 0.94025\n",
      "Training Time: 33.28531217575073\n",
      "Inference Time: 0.15511107444763184\n",
      "Model type: multi_layer_perceptron\n",
      "dataset: doubling_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"doubling_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "#perceptron_config = [(1, 'dense')]\n",
    "\n",
    "mlp_config = [\n",
    "    ('dense', 3, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 6, 'relu'),\n",
    "    ('dense', 2, 'relu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "model = configure_model(mlp_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'],debugflag=True)\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 31942395482341376.0000 - val_accuracy: 0.0000e+00 - val_loss: 30399538002919424.0000\n",
      "Epoch 2/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 29740290587754496.0000 - val_accuracy: 0.0000e+00 - val_loss: 20758889054076928.0000\n",
      "Epoch 3/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 16953341871390720.0000 - val_accuracy: 0.0000e+00 - val_loss: 5263451282735104.0000\n",
      "Epoch 4/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 3984535918215168.0000 - val_accuracy: 0.0000e+00 - val_loss: 2025107815923712.0000\n",
      "Epoch 5/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2022711626825728.0000 - val_accuracy: 0.0000e+00 - val_loss: 1998691216916480.0000\n",
      "Epoch 6/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2018558930321408.0000 - val_accuracy: 0.0000e+00 - val_loss: 1998748527886336.0000\n",
      "Epoch 7/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1999263655526400.0000 - val_accuracy: 0.0000e+00 - val_loss: 1999634230673408.0000\n",
      "Epoch 8/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2016716255133696.0000 - val_accuracy: 0.0000e+00 - val_loss: 1998108846194688.0000\n",
      "Epoch 9/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1988598446424064.0000 - val_accuracy: 0.0000e+00 - val_loss: 1999358279024640.0000\n",
      "Epoch 10/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2030410624139264.0000 - val_accuracy: 0.0000e+00 - val_loss: 1997824707264512.0000\n",
      "Epoch 11/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2018594095366144.0000 - val_accuracy: 0.0000e+00 - val_loss: 2000103321632768.0000\n",
      "Epoch 12/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2001247796199424.0000 - val_accuracy: 0.0000e+00 - val_loss: 1998444122079232.0000\n",
      "Epoch 13/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1984486015238144.0000 - val_accuracy: 0.0000e+00 - val_loss: 2005184804814848.0000\n",
      "Epoch 14/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1996994302181376.0000 - val_accuracy: 0.0000e+00 - val_loss: 2002895184592896.0000\n",
      "Epoch 15/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 1988559925936128.0000 - val_accuracy: 0.0000e+00 - val_loss: 1998377013215232.0000\n",
      "Epoch 16/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2000942853521408.0000 - val_accuracy: 0.0000e+00 - val_loss: 1998327218438144.0000\n",
      "Epoch 17/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1989134914682880.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999149973110784.0000\n",
      "Epoch 18/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2018745224527872.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998132065861632.0000\n",
      "Epoch 19/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2017709868974080.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997406082170880.0000\n",
      "Epoch 20/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2005897769385984.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998328157962240.0000\n",
      "Epoch 21/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1983432540291072.0000 - val_accuracy: 2.5000e-04 - val_loss: 2002362608648192.0000\n",
      "Epoch 22/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1998155151310848.0000 - val_accuracy: 2.5000e-04 - val_loss: 2007693199933440.0000\n",
      "Epoch 23/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1996130611101696.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997822559780864.0000\n",
      "Epoch 24/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1982199079370752.0000 - val_accuracy: 2.5000e-04 - val_loss: 2004757052915712.0000\n",
      "Epoch 25/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1992030662164480.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997653982314496.0000\n",
      "Epoch 26/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1987231841517568.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997562445824000.0000\n",
      "Epoch 27/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2023861470101504.0000 - val_accuracy: 2.5000e-04 - val_loss: 2001702794297344.0000\n",
      "Epoch 28/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1973453183778816.0000 - val_accuracy: 2.5000e-04 - val_loss: 2031936142835712.0000\n",
      "Epoch 29/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2006025007792128.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998265344065536.0000\n",
      "Epoch 30/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1994922651549696.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998497138081792.0000\n",
      "Epoch 31/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2018866288918528.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996892296708096.0000\n",
      "Epoch 32/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1993619263193088.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998715912978432.0000\n",
      "Epoch 33/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1991659281711104.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999543902142464.0000\n",
      "Epoch 34/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1993236742668288.0000 - val_accuracy: 2.5000e-04 - val_loss: 2008934445481984.0000\n",
      "Epoch 35/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2003212206866432.0000 - val_accuracy: 2.5000e-04 - val_loss: 2002695334395904.0000\n",
      "Epoch 36/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1982302292803584.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996741972852736.0000\n",
      "Epoch 37/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2018354516721664.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997109997862912.0000\n",
      "Epoch 38/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1998063749038080.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998996830683136.0000\n",
      "Epoch 39/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1996730698563584.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997447555448832.0000\n",
      "Epoch 40/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2003626402775040.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997022219468800.0000\n",
      "Epoch 41/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1987826560270336.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996553396944896.0000\n",
      "Epoch 42/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 1998105356533760.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997466345930752.0000\n",
      "Epoch 43/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2012134732988416.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999810324332544.0000\n",
      "Epoch 44/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1981483833098240.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997937047502848.0000\n",
      "Epoch 45/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2009372263710720.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996308718026752.0000\n",
      "Epoch 46/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1991712700366848.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997843095093248.0000\n",
      "Epoch 47/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1989198131232768.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998732690194432.0000\n",
      "Epoch 48/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2012554029170688.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996437030174720.0000\n",
      "Epoch 49/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2006956076171264.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997026246000640.0000\n",
      "Epoch 50/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2013569788936192.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996804384096256.0000\n",
      "Epoch 51/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1994678509502464.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999830993862656.0000\n",
      "Epoch 52/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1986392041193472.0000 - val_accuracy: 2.5000e-04 - val_loss: 2000235391877120.0000\n",
      "Epoch 53/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2008568165302272.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998172465397760.0000\n",
      "Epoch 54/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2001695814975488.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998400769753088.0000\n",
      "Epoch 55/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2016563783794688.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996219731673088.0000\n",
      "Epoch 56/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1997185830879232.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996689493721088.0000\n",
      "Epoch 57/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1993098766843904.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996551249461248.0000\n",
      "Epoch 58/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2007059155386368.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996825858932736.0000\n",
      "Epoch 59/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2012496986636288.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997358837530624.0000\n",
      "Epoch 60/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1988345714442240.0000 - val_accuracy: 2.5000e-04 - val_loss: 2000364509331456.0000\n",
      "Epoch 61/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2004128511295488.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996890686095360.0000\n",
      "Epoch 62/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2027898068271104.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995769028542464.0000\n",
      "Epoch 63/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1993168291627008.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996693251817472.0000\n",
      "Epoch 64/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1992706985295872.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999809921679360.0000\n",
      "Epoch 65/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1987037225811968.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997262469201920.0000\n",
      "Epoch 66/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2016259109552128.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996535814422528.0000\n",
      "Epoch 67/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2004108512854016.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999254260285440.0000\n",
      "Epoch 68/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2002389049540608.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997946845396992.0000\n",
      "Epoch 69/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1992774094159872.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998624644923392.0000\n",
      "Epoch 70/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1986355668189184.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998153138044928.0000\n",
      "Epoch 71/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2002291741687808.0000 - val_accuracy: 2.5000e-04 - val_loss: 2003781558468608.0000\n",
      "Epoch 72/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2003168854540288.0000 - val_accuracy: 2.5000e-04 - val_loss: 2005389621067776.0000\n",
      "Epoch 73/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1981657645056000.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999717982535680.0000\n",
      "Epoch 74/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2004156025929728.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999233859190784.0000\n",
      "Epoch 75/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2003355417182208.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997761624932352.0000\n",
      "Epoch 76/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1997740418531328.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995393755774976.0000\n",
      "Epoch 77/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1985079660249088.0000 - val_accuracy: 2.5000e-04 - val_loss: 2004664040030208.0000\n",
      "Epoch 78/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1995181691764736.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995245579403264.0000\n",
      "Epoch 79/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2015800756011008.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995744869351424.0000\n",
      "Epoch 80/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1994131706478592.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995714401927168.0000\n",
      "Epoch 81/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1993436324429824.0000 - val_accuracy: 2.5000e-04 - val_loss: 2002128130277376.0000\n",
      "Epoch 82/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2009555873562624.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999119371468800.0000\n",
      "Epoch 83/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2020252355395584.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996658892079104.0000\n",
      "Epoch 84/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2004022613508096.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995010564161536.0000\n",
      "Epoch 85/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2008838748241920.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998970926661632.0000\n",
      "Epoch 86/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1987499471667200.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996910550319104.0000\n",
      "Epoch 87/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1988307462389760.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995051232133120.0000\n",
      "Epoch 88/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2010662767165440.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994690589097984.0000\n",
      "Epoch 89/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2016274410373120.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994649786908672.0000\n",
      "Epoch 90/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1978963358384128.0000 - val_accuracy: 2.5000e-04 - val_loss: 2001002177757184.0000\n",
      "Epoch 91/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2000911849226240.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994877554393088.0000\n",
      "Epoch 92/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2001888148979712.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995156593049600.0000\n",
      "Epoch 93/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1986545854709760.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997698408382464.0000\n",
      "Epoch 94/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2002374688243712.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994576772464640.0000\n",
      "Epoch 95/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2021980408643584.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998201993297920.0000\n",
      "Epoch 96/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1967670681403392.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995574681272320.0000\n",
      "Epoch 97/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 1989219471851520.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999366868959232.0000\n",
      "Epoch 98/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2015704790335488.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996326300549120.0000\n",
      "Epoch 99/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2008898072477696.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995148942639104.0000\n",
      "Epoch 100/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1994466042839040.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994400410370048.0000\n",
      "Epoch 101/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1989180414492672.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996502528425984.0000\n",
      "Epoch 102/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2017742618099712.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998969852919808.0000\n",
      "Epoch 103/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1985841614290944.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994093320208384.0000\n",
      "Epoch 104/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1968046893694976.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998438887587840.0000\n",
      "Epoch 105/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2019777761509376.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998517673394176.0000\n",
      "Epoch 106/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2007139686023168.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994078824693760.0000\n",
      "Epoch 107/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1980327681589248.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997483123146752.0000\n",
      "Epoch 108/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1998258901614592.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996169936896000.0000\n",
      "Epoch 109/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1998055024885760.0000 - val_accuracy: 2.5000e-04 - val_loss: 1999807505760256.0000\n",
      "Epoch 110/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2018595571761152.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993944070094848.0000\n",
      "Epoch 111/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1994086340886528.0000 - val_accuracy: 2.5000e-04 - val_loss: 2002854113968128.0000\n",
      "Epoch 112/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2026093645135872.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993837635436544.0000\n",
      "Epoch 113/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2010995895566336.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994983586398208.0000\n",
      "Epoch 114/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1994080837959680.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995022509539328.0000\n",
      "Epoch 115/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1994157878935552.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993857633878016.0000\n",
      "Epoch 116/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1987530878615552.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995759096430592.0000\n",
      "Epoch 117/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1994491275771904.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993563831271424.0000\n",
      "Epoch 118/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1953295694299136.0000 - val_accuracy: 2.5000e-04 - val_loss: 2000626233901056.0000\n",
      "Epoch 119/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1999675032862720.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996482664202240.0000\n",
      "Epoch 120/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2007903921766400.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993873471569920.0000\n",
      "Epoch 121/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2011385798066176.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996522258432000.0000\n",
      "Epoch 122/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2005745029611520.0000 - val_accuracy: 2.5000e-04 - val_loss: 2000579660349440.0000\n",
      "Epoch 123/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1997563788001280.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994090904289280.0000\n",
      "Epoch 124/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1989863448510464.0000 - val_accuracy: 2.5000e-04 - val_loss: 2003087921250304.0000\n",
      "Epoch 125/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2017313926676480.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994030103658496.0000\n",
      "Epoch 126/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1986434588213248.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994400678805504.0000\n",
      "Epoch 127/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1973828724981760.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993529471533056.0000\n",
      "Epoch 128/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1996945581146112.0000 - val_accuracy: 2.5000e-04 - val_loss: 1995794127257600.0000\n",
      "Epoch 129/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1980207019851776.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997649016258560.0000\n",
      "Epoch 130/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1987213319471104.0000 - val_accuracy: 2.5000e-04 - val_loss: 2001324971393024.0000\n",
      "Epoch 131/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1970038282125312.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993898301849600.0000\n",
      "Epoch 132/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2017372714041344.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993656173068288.0000\n",
      "Epoch 133/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1995757620035584.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993145206177792.0000\n",
      "Epoch 134/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1975456786022400.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994841718259712.0000\n",
      "Epoch 135/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1996166984105984.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994825075261440.0000\n",
      "Epoch 136/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2002395894644736.0000 - val_accuracy: 2.5000e-04 - val_loss: 1992808856551424.0000\n",
      "Epoch 137/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1994472619507712.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993326668546048.0000\n",
      "Epoch 138/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2011908844552192.0000 - val_accuracy: 2.5000e-04 - val_loss: 1992935826522112.0000\n",
      "Epoch 139/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1986234335363072.0000 - val_accuracy: 2.5000e-04 - val_loss: 1992788589674496.0000\n",
      "Epoch 140/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2014961224122368.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993523968606208.0000\n",
      "Epoch 141/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1999993665748992.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998479421341696.0000\n",
      "Epoch 142/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2015657411477504.0000 - val_accuracy: 2.5000e-04 - val_loss: 1992893816373248.0000\n",
      "Epoch 143/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1995711449137152.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994154120839168.0000\n",
      "Epoch 144/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1986712553127936.0000 - val_accuracy: 2.5000e-04 - val_loss: 1997858127478784.0000\n",
      "Epoch 145/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1982074391101440.0000 - val_accuracy: 2.5000e-04 - val_loss: 1996422400442368.0000\n",
      "Epoch 146/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2005912533336064.0000 - val_accuracy: 2.5000e-04 - val_loss: 1994715956248576.0000\n",
      "Epoch 147/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1992901064130560.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993526384525312.0000\n",
      "Epoch 148/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1997603784884224.0000 - val_accuracy: 2.5000e-04 - val_loss: 2003636603322368.0000\n",
      "Epoch 149/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2002844987162624.0000 - val_accuracy: 2.5000e-04 - val_loss: 1998018920316928.0000\n",
      "Epoch 150/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 2002455084662784.0000 - val_accuracy: 2.5000e-04 - val_loss: 1993642080206848.0000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step\n",
      "Metrics:\n",
      "Accuracy: 0.0\n",
      "MSE: 1993641707014927.8\n",
      "MAE: 39708701.11638544\n",
      "RMSE: 44650215.08363569\n",
      "F1 Score: 0.0\n",
      "Training Time: 97.35672807693481\n",
      "Inference Time: 0.1303699016571045\n",
      "Model type: multi_layer_perceptron\n",
      "dataset: multiplication_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"multiplication_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "#perceptron_config = [(1, 'dense')]\n",
    "\n",
    "mlp_config = [\n",
    "    ('dense', 10, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 6, 'relu'),\n",
    "    ('dense', 2, 'relu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "model = configure_model(mlp_config, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['accuracy'],debugflag=False)\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name,total_epoch=150)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 57818.7930 - val_accuracy: 2.5000e-04 - val_loss: 79.4324\n",
      "Epoch 2/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 79.1628 - val_accuracy: 2.5000e-04 - val_loss: 78.1897\n",
      "Epoch 3/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 77.7473 - val_accuracy: 2.5000e-04 - val_loss: 76.3890\n",
      "Epoch 4/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 75.7212 - val_accuracy: 2.5000e-04 - val_loss: 74.0126\n",
      "Epoch 5/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 0.0000e+00 - loss: 72.9952 - val_accuracy: 0.0000e+00 - val_loss: 71.0392\n",
      "Epoch 6/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 0.0000e+00 - loss: 70.3203 - val_accuracy: 0.0000e+00 - val_loss: 67.4655\n",
      "Epoch 7/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 66.4372 - val_accuracy: 0.0000e+00 - val_loss: 63.3329\n",
      "Epoch 8/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 0.0000e+00 - loss: 62.1940 - val_accuracy: 0.0000e+00 - val_loss: 58.7288\n",
      "Epoch 9/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 57.3388 - val_accuracy: 0.0000e+00 - val_loss: 53.7892\n",
      "Epoch 10/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.0000e+00 - loss: 52.3869 - val_accuracy: 0.0000e+00 - val_loss: 48.6718\n",
      "Epoch 11/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 0.0000e+00 - loss: 47.3355 - val_accuracy: 0.0000e+00 - val_loss: 43.5327\n",
      "Epoch 12/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.0000e+00 - loss: 42.1471 - val_accuracy: 0.0000e+00 - val_loss: 38.5034\n",
      "Epoch 13/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.0000e+00 - loss: 37.3727 - val_accuracy: 0.0000e+00 - val_loss: 33.6876\n",
      "Epoch 14/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 32.4000 - val_accuracy: 0.0000e+00 - val_loss: 29.1492\n",
      "Epoch 15/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.0000e+00 - loss: 27.9731 - val_accuracy: 0.0000e+00 - val_loss: 24.9406\n",
      "Epoch 16/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 23.8420 - val_accuracy: 0.0000e+00 - val_loss: 21.0836\n",
      "Epoch 17/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.0000e+00 - loss: 20.0473 - val_accuracy: 0.0000e+00 - val_loss: 17.5950\n",
      "Epoch 18/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 16.7236 - val_accuracy: 0.0000e+00 - val_loss: 14.4758\n",
      "Epoch 19/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.0000e+00 - loss: 13.6899 - val_accuracy: 0.0000e+00 - val_loss: 11.7254\n",
      "Epoch 20/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 11.0463 - val_accuracy: 0.0000e+00 - val_loss: 9.3383\n",
      "Epoch 21/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.0000e+00 - loss: 8.7789 - val_accuracy: 0.0000e+00 - val_loss: 7.3030\n",
      "Epoch 22/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - accuracy: 0.0000e+00 - loss: 6.8247 - val_accuracy: 0.0000e+00 - val_loss: 5.6042\n",
      "Epoch 23/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 5.2451 - val_accuracy: 0.0000e+00 - val_loss: 4.2262\n",
      "Epoch 24/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 3.9792 - val_accuracy: 0.0000e+00 - val_loss: 3.1430\n",
      "Epoch 25/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 2.9259 - val_accuracy: 0.0000e+00 - val_loss: 2.3285\n",
      "Epoch 26/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.0000e+00 - loss: 2.1771 - val_accuracy: 0.0000e+00 - val_loss: 1.7520\n",
      "Epoch 27/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.0000e+00 - loss: 1.6643 - val_accuracy: 0.0000e+00 - val_loss: 1.3721\n",
      "Epoch 28/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.3239 - val_accuracy: 0.0000e+00 - val_loss: 1.1476\n",
      "Epoch 29/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.1566 - val_accuracy: 0.0000e+00 - val_loss: 1.0310\n",
      "Epoch 30/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.0000e+00 - loss: 1.0770 - val_accuracy: 0.0000e+00 - val_loss: 0.9814\n",
      "Epoch 31/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.0000e+00 - loss: 1.0091 - val_accuracy: 0.0000e+00 - val_loss: 0.9651\n",
      "Epoch 32/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.0000e+00 - loss: 1.0116 - val_accuracy: 0.0000e+00 - val_loss: 0.9614\n",
      "Epoch 33/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.0000e+00 - loss: 1.0181 - val_accuracy: 0.0000e+00 - val_loss: 0.9604\n",
      "Epoch 34/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.0000e+00 - loss: 1.0033 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 35/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 1.0803 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 36/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - accuracy: 0.0000e+00 - loss: 0.9913 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 37/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.0019 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 38/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.0000e+00 - loss: 0.9680 - val_accuracy: 0.0000e+00 - val_loss: 0.9603\n",
      "Epoch 39/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 1.0363 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 40/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.0000e+00 - loss: 1.0368 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 41/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.0000e+00 - loss: 1.0060 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 42/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.0000e+00 - loss: 1.0289 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 43/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 0.0000e+00 - loss: 1.0525 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 44/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.0209 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 45/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.0000e+00 - loss: 0.9787 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 46/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.0000e+00 - loss: 0.9866 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 47/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.0000e+00 - loss: 0.9871 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 48/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.0000e+00 - loss: 0.9936 - val_accuracy: 0.0000e+00 - val_loss: 0.9603\n",
      "Epoch 49/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 0.9854 - val_accuracy: 0.0000e+00 - val_loss: 0.9604\n",
      "Epoch 50/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 0.0000e+00 - loss: 1.0478 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 51/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.0000e+00 - loss: 1.0096 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 52/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 0.0000e+00 - loss: 1.0418 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 53/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.0000e+00 - loss: 1.0108 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 54/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 0.9849 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 55/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 1.0163 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "Epoch 56/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.0000e+00 - loss: 1.0287 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 57/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.0000e+00 - loss: 0.9966 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 58/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.9790 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 59/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 1.0145 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 60/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.0000e+00 - loss: 0.9782 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 61/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.0000e+00 - loss: 0.9922 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 62/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 1.0470 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 63/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.0000e+00 - loss: 0.9958 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 64/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.0000e+00 - loss: 0.9745 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 65/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.9868 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 66/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 0.9654 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 67/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.0000e+00 - loss: 1.0422 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 68/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 1.0043 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 69/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 1.0356 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 70/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 0.9862 - val_accuracy: 0.0000e+00 - val_loss: 0.9604\n",
      "Epoch 71/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 1.0412 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 72/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.0397 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "Epoch 73/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.0000e+00 - loss: 0.9928 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "Epoch 74/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.0000e+00 - loss: 0.9704 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "Epoch 75/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.0000e+00 - loss: 0.9948 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 76/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.0000e+00 - loss: 1.0330 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 77/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.0000e+00 - loss: 1.0332 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 78/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 0.0000e+00 - loss: 0.9755 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 79/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.0000e+00 - loss: 0.9462 - val_accuracy: 0.0000e+00 - val_loss: 0.9603\n",
      "Epoch 80/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 0.0000e+00 - loss: 1.0073 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 81/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 0.9844 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 82/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 0.0000e+00 - loss: 0.9884 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 83/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 0.0000e+00 - loss: 1.0038 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 84/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.9955 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 85/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - accuracy: 0.0000e+00 - loss: 0.9766 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 86/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.0000e+00 - loss: 1.0011 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 87/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - accuracy: 0.0000e+00 - loss: 0.9797 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 88/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 1.0146 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 89/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.0000e+00 - loss: 0.9928 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 90/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 0.0000e+00 - loss: 1.0193 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 91/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 1.0058 - val_accuracy: 0.0000e+00 - val_loss: 0.9604\n",
      "Epoch 92/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 1.0505 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 93/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.0000e+00 - loss: 0.9942 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 94/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - accuracy: 0.0000e+00 - loss: 0.9901 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 95/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 1.0066 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 96/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.0000e+00 - loss: 0.9897 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 97/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.0000e+00 - loss: 1.0077 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 98/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 1.0181 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 99/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.0000e+00 - loss: 1.0294 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 100/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.0000e+00 - loss: 1.0170 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 101/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 0.9980 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 102/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.0000e+00 - loss: 1.0081 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 103/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 1.0294 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 104/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 1.0411 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 105/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 1.0355 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 106/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 0.9979 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 107/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.0000e+00 - loss: 1.0099 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "Epoch 108/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.9906 - val_accuracy: 0.0000e+00 - val_loss: 0.9603\n",
      "Epoch 109/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 0.9974 - val_accuracy: 0.0000e+00 - val_loss: 0.9603\n",
      "Epoch 110/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 1.0121 - val_accuracy: 0.0000e+00 - val_loss: 0.9603\n",
      "Epoch 111/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 1.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "Epoch 112/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.0000e+00 - loss: 1.0063 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 113/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.0000e+00 - loss: 1.0125 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 114/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 1.0013 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 115/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 0.9788 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 116/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.0000e+00 - loss: 1.0147 - val_accuracy: 0.0000e+00 - val_loss: 0.9603\n",
      "Epoch 117/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 0.9901 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "Epoch 118/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.0000e+00 - loss: 1.0385 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 119/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.0000e+00 - loss: 1.0173 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 120/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 1.0093 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 121/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 1.0294 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 122/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 1.0328 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 123/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.0000e+00 - loss: 0.9996 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 124/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.0000e+00 - loss: 0.9755 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 125/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.0000e+00 - loss: 1.0218 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 126/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 1.0284 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 127/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.0000e+00 - loss: 0.9833 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "Epoch 128/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 1.0062 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 129/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 0.9915 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 130/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 1.0006 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 131/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - accuracy: 0.0000e+00 - loss: 1.0159 - val_accuracy: 0.0000e+00 - val_loss: 0.9603\n",
      "Epoch 132/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.0000e+00 - loss: 0.9996 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 133/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 0.9866 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 134/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 0.9925 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 135/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.0000e+00 - loss: 1.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 136/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.0000e+00 - loss: 1.0059 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 137/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 1.0294 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 138/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 1.0110 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 139/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 0.9948 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 140/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.0000e+00 - loss: 0.9724 - val_accuracy: 0.0000e+00 - val_loss: 0.9601\n",
      "Epoch 141/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.0000e+00 - loss: 1.0072 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 142/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 1.0283 - val_accuracy: 0.0000e+00 - val_loss: 0.9599\n",
      "Epoch 143/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.0000e+00 - loss: 0.9979 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 144/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 0.9937 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "Epoch 145/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 1.0458 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 146/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1000us/step - accuracy: 0.0000e+00 - loss: 0.9762 - val_accuracy: 0.0000e+00 - val_loss: 0.9603\n",
      "Epoch 147/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 0.9700 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "Epoch 148/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.0000e+00 - loss: 1.0027 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 149/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 0.9733 - val_accuracy: 0.0000e+00 - val_loss: 0.9600\n",
      "Epoch 150/150\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.0000e+00 - loss: 1.0148 - val_accuracy: 0.0000e+00 - val_loss: 0.9602\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step\n",
      "Metrics:\n",
      "Accuracy: 0.38775\n",
      "MSE: 0.9601903000963607\n",
      "MAE: 0.7204698066642674\n",
      "RMSE: 0.9798930044124005\n",
      "F1 Score: 0.42975\n",
      "Training Time: 75.83415102958679\n",
      "Inference Time: 0.12098956108093262\n",
      "Model type: multi_layer_perceptron\n",
      "dataset: natural_log_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"natural_log_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "#perceptron_config = [(1, 'dense')]\n",
    "\n",
    "mlp_config = [\n",
    "    ('dense', 10, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 6, 'relu'),\n",
    "    ('dense', 2, 'relu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "model = configure_model(mlp_config, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['accuracy'],debugflag=False)\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name,total_epoch=150)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1131.7239 - val_accuracy: 0.0000e+00 - val_loss: 1030.9840\n",
      "Epoch 2/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 1030.3702 - val_accuracy: 0.0000e+00 - val_loss: 1013.6716\n",
      "Epoch 3/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.0000e+00 - loss: 1017.1518 - val_accuracy: 0.0000e+00 - val_loss: 991.4341\n",
      "Epoch 4/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.0000e+00 - loss: 993.3772 - val_accuracy: 0.0000e+00 - val_loss: 966.7371\n",
      "Epoch 5/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 0.0000e+00 - loss: 981.0616 - val_accuracy: 0.0000e+00 - val_loss: 918.3064\n",
      "Epoch 6/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.0000e+00 - loss: 906.8375 - val_accuracy: 0.0000e+00 - val_loss: 770.0994\n",
      "Epoch 7/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.0000e+00 - loss: 710.2152 - val_accuracy: 0.0000e+00 - val_loss: 393.5238\n",
      "Epoch 8/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step - accuracy: 0.0000e+00 - loss: 300.9943 - val_accuracy: 0.0000e+00 - val_loss: 96.8904\n",
      "Epoch 9/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.0000e+00 - loss: 74.1368 - val_accuracy: 0.0000e+00 - val_loss: 40.2657\n",
      "Epoch 10/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.0000e+00 - loss: 36.8034 - val_accuracy: 0.0000e+00 - val_loss: 31.9231\n",
      "Epoch 11/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.0000e+00 - loss: 30.9775 - val_accuracy: 0.0000e+00 - val_loss: 29.0302\n",
      "Epoch 12/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.0000e+00 - loss: 28.4417 - val_accuracy: 0.0000e+00 - val_loss: 27.0961\n",
      "Epoch 13/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.0000e+00 - loss: 27.1137 - val_accuracy: 0.0000e+00 - val_loss: 25.1723\n",
      "Epoch 14/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 24.6315 - val_accuracy: 0.0000e+00 - val_loss: 23.3816\n",
      "Epoch 15/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 23.1272 - val_accuracy: 0.0000e+00 - val_loss: 22.1044\n",
      "Epoch 16/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.0000e+00 - loss: 21.6187 - val_accuracy: 0.0000e+00 - val_loss: 20.2720\n",
      "Epoch 17/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 0.0000e+00 - loss: 20.3392 - val_accuracy: 0.0000e+00 - val_loss: 19.2452\n",
      "Epoch 18/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.0000e+00 - loss: 19.2969 - val_accuracy: 0.0000e+00 - val_loss: 17.8685\n",
      "Epoch 19/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.0000e+00 - loss: 17.2134 - val_accuracy: 0.0000e+00 - val_loss: 16.5940\n",
      "Epoch 20/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 16.7970 - val_accuracy: 0.0000e+00 - val_loss: 15.6637\n",
      "Epoch 21/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 15.8252 - val_accuracy: 0.0000e+00 - val_loss: 14.9248\n",
      "Epoch 22/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.0000e+00 - loss: 15.7779 - val_accuracy: 0.0000e+00 - val_loss: 14.1378\n",
      "Epoch 23/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.0000e+00 - loss: 14.1206 - val_accuracy: 0.0000e+00 - val_loss: 13.6588\n",
      "Epoch 24/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 0.0000e+00 - loss: 14.2112 - val_accuracy: 0.0000e+00 - val_loss: 13.3637\n",
      "Epoch 25/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - accuracy: 0.0000e+00 - loss: 13.5732 - val_accuracy: 0.0000e+00 - val_loss: 13.1154\n",
      "Epoch 26/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 13.4741 - val_accuracy: 0.0000e+00 - val_loss: 12.9140\n",
      "Epoch 27/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.0000e+00 - loss: 13.0532 - val_accuracy: 0.0000e+00 - val_loss: 12.7433\n",
      "Epoch 28/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.0000e+00 - loss: 13.1699 - val_accuracy: 0.0000e+00 - val_loss: 12.6360\n",
      "Epoch 29/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 13.3642 - val_accuracy: 0.0000e+00 - val_loss: 12.8131\n",
      "Epoch 30/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 13.0835 - val_accuracy: 0.0000e+00 - val_loss: 12.5353\n",
      "Epoch 31/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.0000e+00 - loss: 12.9990 - val_accuracy: 0.0000e+00 - val_loss: 12.5148\n",
      "Epoch 32/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 12.8935 - val_accuracy: 0.0000e+00 - val_loss: 12.4107\n",
      "Epoch 33/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 12.6786 - val_accuracy: 0.0000e+00 - val_loss: 12.3163\n",
      "Epoch 34/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.0000e+00 - loss: 12.3620 - val_accuracy: 0.0000e+00 - val_loss: 12.2393\n",
      "Epoch 35/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0000e+00 - loss: 12.4240 - val_accuracy: 0.0000e+00 - val_loss: 12.2016\n",
      "Epoch 36/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.0000e+00 - loss: 12.3115 - val_accuracy: 0.0000e+00 - val_loss: 12.3675\n",
      "Epoch 37/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.0000e+00 - loss: 12.1549 - val_accuracy: 0.0000e+00 - val_loss: 12.0631\n",
      "Epoch 38/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.0000e+00 - loss: 12.0690 - val_accuracy: 0.0000e+00 - val_loss: 12.0165\n",
      "Epoch 39/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.0000e+00 - loss: 12.2976 - val_accuracy: 0.0000e+00 - val_loss: 11.9870\n",
      "Epoch 40/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 12.5532 - val_accuracy: 0.0000e+00 - val_loss: 12.2260\n",
      "Epoch 41/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.0000e+00 - loss: 12.5640 - val_accuracy: 0.0000e+00 - val_loss: 12.0929\n",
      "Epoch 42/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.0000e+00 - loss: 12.2712 - val_accuracy: 0.0000e+00 - val_loss: 12.0694\n",
      "Epoch 43/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 12.1381 - val_accuracy: 0.0000e+00 - val_loss: 11.8506\n",
      "Epoch 44/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 12.0164 - val_accuracy: 0.0000e+00 - val_loss: 11.6410\n",
      "Epoch 45/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 12.2224 - val_accuracy: 0.0000e+00 - val_loss: 11.5567\n",
      "Epoch 46/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 11.8521 - val_accuracy: 0.0000e+00 - val_loss: 11.5241\n",
      "Epoch 47/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.0000e+00 - loss: 11.6626 - val_accuracy: 0.0000e+00 - val_loss: 11.6448\n",
      "Epoch 48/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 11.7513 - val_accuracy: 0.0000e+00 - val_loss: 11.3753\n",
      "Epoch 49/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 11.7435 - val_accuracy: 0.0000e+00 - val_loss: 11.3337\n",
      "Epoch 50/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 11.4353 - val_accuracy: 0.0000e+00 - val_loss: 11.3285\n",
      "Epoch 51/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.0000e+00 - loss: 11.6380 - val_accuracy: 0.0000e+00 - val_loss: 11.2698\n",
      "Epoch 52/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 11.4812 - val_accuracy: 0.0000e+00 - val_loss: 11.3366\n",
      "Epoch 53/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.0000e+00 - loss: 11.2174 - val_accuracy: 0.0000e+00 - val_loss: 11.2266\n",
      "Epoch 54/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 11.3516 - val_accuracy: 0.0000e+00 - val_loss: 11.2106\n",
      "Epoch 55/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 11.2164 - val_accuracy: 0.0000e+00 - val_loss: 11.2032\n",
      "Epoch 56/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.0000e+00 - loss: 11.4490 - val_accuracy: 0.0000e+00 - val_loss: 11.1959\n",
      "Epoch 57/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 11.2110 - val_accuracy: 0.0000e+00 - val_loss: 11.1742\n",
      "Epoch 58/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 11.2568 - val_accuracy: 0.0000e+00 - val_loss: 11.0769\n",
      "Epoch 59/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.0000e+00 - loss: 10.9938 - val_accuracy: 0.0000e+00 - val_loss: 11.0371\n",
      "Epoch 60/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 11.2917 - val_accuracy: 0.0000e+00 - val_loss: 11.0011\n",
      "Epoch 61/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 11.3124 - val_accuracy: 0.0000e+00 - val_loss: 10.9419\n",
      "Epoch 62/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 11.1464 - val_accuracy: 0.0000e+00 - val_loss: 10.9515\n",
      "Epoch 63/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.0000e+00 - loss: 10.9933 - val_accuracy: 0.0000e+00 - val_loss: 10.9329\n",
      "Epoch 64/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.0000e+00 - loss: 11.1915 - val_accuracy: 0.0000e+00 - val_loss: 10.9641\n",
      "Epoch 65/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 10.9941 - val_accuracy: 0.0000e+00 - val_loss: 10.8922\n",
      "Epoch 66/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 10.8914 - val_accuracy: 0.0000e+00 - val_loss: 10.8692\n",
      "Epoch 67/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.0000e+00 - loss: 11.0684 - val_accuracy: 0.0000e+00 - val_loss: 10.8059\n",
      "Epoch 68/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.0000e+00 - loss: 10.6804 - val_accuracy: 0.0000e+00 - val_loss: 10.8761\n",
      "Epoch 69/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.0000e+00 - loss: 10.9124 - val_accuracy: 0.0000e+00 - val_loss: 10.7311\n",
      "Epoch 70/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.0000e+00 - loss: 10.8320 - val_accuracy: 0.0000e+00 - val_loss: 10.7264\n",
      "Epoch 71/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.0000e+00 - loss: 10.9876 - val_accuracy: 0.0000e+00 - val_loss: 10.7116\n",
      "Epoch 72/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 10.9428 - val_accuracy: 0.0000e+00 - val_loss: 10.6666\n",
      "Epoch 73/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 10.7233 - val_accuracy: 0.0000e+00 - val_loss: 10.6435\n",
      "Epoch 74/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 10.6721 - val_accuracy: 0.0000e+00 - val_loss: 10.5926\n",
      "Epoch 75/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.0000e+00 - loss: 10.6755 - val_accuracy: 0.0000e+00 - val_loss: 10.5579\n",
      "Epoch 76/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.0000e+00 - loss: 10.7717 - val_accuracy: 0.0000e+00 - val_loss: 10.5529\n",
      "Epoch 77/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 10.5491 - val_accuracy: 0.0000e+00 - val_loss: 10.5436\n",
      "Epoch 78/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 10.7168 - val_accuracy: 0.0000e+00 - val_loss: 10.5651\n",
      "Epoch 79/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 10.3660 - val_accuracy: 0.0000e+00 - val_loss: 10.5341\n",
      "Epoch 80/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.0000e+00 - loss: 10.5196 - val_accuracy: 0.0000e+00 - val_loss: 10.4262\n",
      "Epoch 81/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.0000e+00 - loss: 10.5352 - val_accuracy: 0.0000e+00 - val_loss: 10.4821\n",
      "Epoch 82/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 10.4211 - val_accuracy: 0.0000e+00 - val_loss: 10.4518\n",
      "Epoch 83/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.0000e+00 - loss: 10.6881 - val_accuracy: 0.0000e+00 - val_loss: 10.3952\n",
      "Epoch 84/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.0000e+00 - loss: 10.5204 - val_accuracy: 0.0000e+00 - val_loss: 10.4499\n",
      "Epoch 85/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 10.3104 - val_accuracy: 0.0000e+00 - val_loss: 10.6328\n",
      "Epoch 86/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 10.5111 - val_accuracy: 0.0000e+00 - val_loss: 10.3074\n",
      "Epoch 87/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.0000e+00 - loss: 10.3589 - val_accuracy: 0.0000e+00 - val_loss: 10.3368\n",
      "Epoch 88/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.0000e+00 - loss: 10.4002 - val_accuracy: 0.0000e+00 - val_loss: 10.3163\n",
      "Epoch 89/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 0.0000e+00 - loss: 10.3121 - val_accuracy: 0.0000e+00 - val_loss: 10.3154\n",
      "Epoch 90/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.0000e+00 - loss: 10.2392 - val_accuracy: 0.0000e+00 - val_loss: 10.2654\n",
      "Epoch 91/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.0000e+00 - loss: 10.3145 - val_accuracy: 0.0000e+00 - val_loss: 10.2614\n",
      "Epoch 92/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 10.3222 - val_accuracy: 0.0000e+00 - val_loss: 10.3183\n",
      "Epoch 93/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 10.4066 - val_accuracy: 0.0000e+00 - val_loss: 10.2802\n",
      "Epoch 94/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 10.2582 - val_accuracy: 0.0000e+00 - val_loss: 10.2753\n",
      "Epoch 95/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0000e+00 - loss: 10.3641 - val_accuracy: 0.0000e+00 - val_loss: 10.1872\n",
      "Epoch 96/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0000e+00 - loss: 10.2134 - val_accuracy: 0.0000e+00 - val_loss: 10.2125\n",
      "Epoch 97/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 10.2852 - val_accuracy: 0.0000e+00 - val_loss: 10.2004\n",
      "Epoch 98/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 0.0000e+00 - loss: 10.2695 - val_accuracy: 0.0000e+00 - val_loss: 10.2579\n",
      "Epoch 99/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.0000e+00 - loss: 10.1301 - val_accuracy: 0.0000e+00 - val_loss: 10.1508\n",
      "Epoch 100/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 10.0568 - val_accuracy: 0.0000e+00 - val_loss: 10.1510\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step\n",
      "Metrics:\n",
      "Accuracy: 0.25925\n",
      "MSE: 10.151035312560664\n",
      "MAE: 2.287249270260521\n",
      "RMSE: 3.1860689434726086\n",
      "F1 Score: 0.2545\n",
      "Training Time: 48.2197163105011\n",
      "Inference Time: 0.1779015064239502\n",
      "Model type: multi_layer_perceptron\n",
      "dataset: integration_with_cos_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"integration_with_cos_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "#perceptron_config = [(1, 'dense')]\n",
    "mlp_config = [\n",
    "    ('dense', 64, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 32, 'selu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "mlp_config = [\n",
    "    ('dense', 3, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 6, 'relu'),\n",
    "    ('dense', 2, 'relu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "model = configure_model(mlp_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'],debugflag=False)\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,total_epoch=100,model_name='multi_layer_perceptron',dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 838.3007 - val_accuracy: 0.0000e+00 - val_loss: 640.0233\n",
      "Epoch 2/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 620.8826 - val_accuracy: 0.0000e+00 - val_loss: 590.7372\n",
      "Epoch 3/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.0000e+00 - loss: 591.8002 - val_accuracy: 0.0000e+00 - val_loss: 567.0081\n",
      "Epoch 4/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 561.8916 - val_accuracy: 0.0000e+00 - val_loss: 536.4796\n",
      "Epoch 5/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.0000e+00 - loss: 538.4566 - val_accuracy: 0.0000e+00 - val_loss: 509.4155\n",
      "Epoch 6/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 507.8850 - val_accuracy: 0.0000e+00 - val_loss: 489.3781\n",
      "Epoch 7/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 0.0000e+00 - loss: 492.0490 - val_accuracy: 0.0000e+00 - val_loss: 472.0224\n",
      "Epoch 8/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 468.4976 - val_accuracy: 0.0000e+00 - val_loss: 451.3208\n",
      "Epoch 9/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 456.6690 - val_accuracy: 0.0000e+00 - val_loss: 431.0922\n",
      "Epoch 10/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.0000e+00 - loss: 423.6883 - val_accuracy: 0.0000e+00 - val_loss: 414.2097\n",
      "Epoch 11/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 409.7810 - val_accuracy: 0.0000e+00 - val_loss: 400.1052\n",
      "Epoch 12/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 0.0000e+00 - loss: 393.9478 - val_accuracy: 0.0000e+00 - val_loss: 389.3749\n",
      "Epoch 13/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 383.8256 - val_accuracy: 0.0000e+00 - val_loss: 379.5573\n",
      "Epoch 14/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 375.6641 - val_accuracy: 0.0000e+00 - val_loss: 372.7174\n",
      "Epoch 15/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 366.3639 - val_accuracy: 0.0000e+00 - val_loss: 365.1536\n",
      "Epoch 16/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 0.0000e+00 - loss: 352.2105 - val_accuracy: 0.0000e+00 - val_loss: 357.8162\n",
      "Epoch 17/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 361.7593 - val_accuracy: 0.0000e+00 - val_loss: 350.5184\n",
      "Epoch 18/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.0000e+00 - loss: 352.8678 - val_accuracy: 0.0000e+00 - val_loss: 342.5186\n",
      "Epoch 19/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.0000e+00 - loss: 337.1488 - val_accuracy: 0.0000e+00 - val_loss: 332.0631\n",
      "Epoch 20/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 337.4352 - val_accuracy: 0.0000e+00 - val_loss: 318.9461\n",
      "Epoch 21/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.0000e+00 - loss: 328.2097 - val_accuracy: 0.0000e+00 - val_loss: 302.6303\n",
      "Epoch 22/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.0000e+00 - loss: 288.3027 - val_accuracy: 0.0000e+00 - val_loss: 284.9788\n",
      "Epoch 23/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.0000e+00 - loss: 276.0521 - val_accuracy: 0.0000e+00 - val_loss: 258.4273\n",
      "Epoch 24/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.0000e+00 - loss: 252.4217 - val_accuracy: 0.0000e+00 - val_loss: 231.6124\n",
      "Epoch 25/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - accuracy: 0.0000e+00 - loss: 225.9710 - val_accuracy: 0.0000e+00 - val_loss: 198.8587\n",
      "Epoch 26/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.0000e+00 - loss: 188.0457 - val_accuracy: 0.0000e+00 - val_loss: 165.3388\n",
      "Epoch 27/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 0.0000e+00 - loss: 158.3786 - val_accuracy: 0.0000e+00 - val_loss: 133.4873\n",
      "Epoch 28/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 134.2393 - val_accuracy: 0.0000e+00 - val_loss: 106.4451\n",
      "Epoch 29/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.0000e+00 - loss: 100.2838 - val_accuracy: 0.0000e+00 - val_loss: 78.5427\n",
      "Epoch 30/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 79.1342 - val_accuracy: 0.0000e+00 - val_loss: 58.1422\n",
      "Epoch 31/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.0000e+00 - loss: 59.3033 - val_accuracy: 0.0000e+00 - val_loss: 43.3005\n",
      "Epoch 32/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 0.0000e+00 - loss: 44.0795 - val_accuracy: 0.0000e+00 - val_loss: 32.6719\n",
      "Epoch 33/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.0000e+00 - loss: 33.1093 - val_accuracy: 0.0000e+00 - val_loss: 25.0493\n",
      "Epoch 34/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 24.5445 - val_accuracy: 0.0000e+00 - val_loss: 19.0982\n",
      "Epoch 35/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 19.1825 - val_accuracy: 0.0000e+00 - val_loss: 15.2646\n",
      "Epoch 36/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 15.7259 - val_accuracy: 0.0000e+00 - val_loss: 13.0194\n",
      "Epoch 37/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.0000e+00 - loss: 13.1994 - val_accuracy: 0.0000e+00 - val_loss: 10.8052\n",
      "Epoch 38/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 10.9446 - val_accuracy: 0.0000e+00 - val_loss: 9.9134\n",
      "Epoch 39/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - accuracy: 0.0000e+00 - loss: 9.3944 - val_accuracy: 0.0000e+00 - val_loss: 8.7004\n",
      "Epoch 40/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 8.5097 - val_accuracy: 0.0000e+00 - val_loss: 7.2566\n",
      "Epoch 41/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.0000e+00 - loss: 7.2277 - val_accuracy: 0.0000e+00 - val_loss: 6.2395\n",
      "Epoch 42/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 6.5178 - val_accuracy: 0.0000e+00 - val_loss: 5.4685\n",
      "Epoch 43/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 5.9649 - val_accuracy: 0.0000e+00 - val_loss: 5.3815\n",
      "Epoch 44/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 5.3103 - val_accuracy: 0.0000e+00 - val_loss: 4.7144\n",
      "Epoch 45/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.0000e+00 - loss: 4.8490 - val_accuracy: 0.0000e+00 - val_loss: 4.8170\n",
      "Epoch 46/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.0000e+00 - loss: 4.4350 - val_accuracy: 0.0000e+00 - val_loss: 4.2697\n",
      "Epoch 47/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 4.4375 - val_accuracy: 0.0000e+00 - val_loss: 4.3421\n",
      "Epoch 48/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0000e+00 - loss: 4.3141 - val_accuracy: 0.0000e+00 - val_loss: 3.9557\n",
      "Epoch 49/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 4.1383 - val_accuracy: 0.0000e+00 - val_loss: 5.4509\n",
      "Epoch 50/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 4.2041 - val_accuracy: 0.0000e+00 - val_loss: 3.8776\n",
      "Epoch 51/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 4.0652 - val_accuracy: 0.0000e+00 - val_loss: 3.8144\n",
      "Epoch 52/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 0.0000e+00 - loss: 3.8905 - val_accuracy: 0.0000e+00 - val_loss: 3.8502\n",
      "Epoch 53/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 4.0373 - val_accuracy: 0.0000e+00 - val_loss: 4.1628\n",
      "Epoch 54/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.0000e+00 - loss: 4.0701 - val_accuracy: 0.0000e+00 - val_loss: 3.9789\n",
      "Epoch 55/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.0000e+00 - loss: 3.8966 - val_accuracy: 0.0000e+00 - val_loss: 4.2690\n",
      "Epoch 56/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.0000e+00 - loss: 4.0934 - val_accuracy: 0.0000e+00 - val_loss: 4.4394\n",
      "Epoch 57/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.0000e+00 - loss: 4.0103 - val_accuracy: 0.0000e+00 - val_loss: 4.3193\n",
      "Epoch 58/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.0000e+00 - loss: 4.1209 - val_accuracy: 0.0000e+00 - val_loss: 3.8587\n",
      "Epoch 59/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.0000e+00 - loss: 3.9208 - val_accuracy: 0.0000e+00 - val_loss: 3.7092\n",
      "Epoch 60/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.0000e+00 - loss: 4.0172 - val_accuracy: 0.0000e+00 - val_loss: 4.2548\n",
      "Epoch 61/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 4.1405 - val_accuracy: 0.0000e+00 - val_loss: 3.8170\n",
      "Epoch 62/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.0000e+00 - loss: 4.0650 - val_accuracy: 0.0000e+00 - val_loss: 3.9075\n",
      "Epoch 63/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 4.0021 - val_accuracy: 0.0000e+00 - val_loss: 3.7410\n",
      "Epoch 64/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 3.9757 - val_accuracy: 0.0000e+00 - val_loss: 4.1139\n",
      "Epoch 65/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.0000e+00 - loss: 4.0260 - val_accuracy: 0.0000e+00 - val_loss: 4.2156\n",
      "Epoch 66/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 3.9621 - val_accuracy: 0.0000e+00 - val_loss: 3.7068\n",
      "Epoch 67/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0000e+00 - loss: 3.9814 - val_accuracy: 0.0000e+00 - val_loss: 3.6639\n",
      "Epoch 68/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 4.0248 - val_accuracy: 0.0000e+00 - val_loss: 3.8279\n",
      "Epoch 69/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 3.9175 - val_accuracy: 0.0000e+00 - val_loss: 4.2719\n",
      "Epoch 70/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 4.0628 - val_accuracy: 0.0000e+00 - val_loss: 4.0603\n",
      "Epoch 71/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.0000e+00 - loss: 3.9608 - val_accuracy: 0.0000e+00 - val_loss: 3.7122\n",
      "Epoch 72/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.0000e+00 - loss: 3.9477 - val_accuracy: 0.0000e+00 - val_loss: 3.7207\n",
      "Epoch 73/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 3.9286 - val_accuracy: 0.0000e+00 - val_loss: 4.0767\n",
      "Epoch 74/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.0000e+00 - loss: 4.0400 - val_accuracy: 0.0000e+00 - val_loss: 3.8314\n",
      "Epoch 75/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 3.9511 - val_accuracy: 0.0000e+00 - val_loss: 3.9803\n",
      "Epoch 76/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.0000e+00 - loss: 3.9226 - val_accuracy: 0.0000e+00 - val_loss: 3.6713\n",
      "Epoch 77/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 3.9568 - val_accuracy: 0.0000e+00 - val_loss: 3.7194\n",
      "Epoch 78/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 3.9065 - val_accuracy: 0.0000e+00 - val_loss: 3.9819\n",
      "Epoch 79/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 3.9551 - val_accuracy: 0.0000e+00 - val_loss: 3.6814\n",
      "Epoch 80/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.0000e+00 - loss: 3.9515 - val_accuracy: 0.0000e+00 - val_loss: 4.1709\n",
      "Epoch 81/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 4.0823 - val_accuracy: 0.0000e+00 - val_loss: 3.6827\n",
      "Epoch 82/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.0000e+00 - loss: 3.9355 - val_accuracy: 0.0000e+00 - val_loss: 3.8338\n",
      "Epoch 83/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 3.9508 - val_accuracy: 0.0000e+00 - val_loss: 4.0417\n",
      "Epoch 84/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 3.9867 - val_accuracy: 0.0000e+00 - val_loss: 3.9786\n",
      "Epoch 85/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.0000e+00 - loss: 4.1667 - val_accuracy: 0.0000e+00 - val_loss: 3.7710\n",
      "Epoch 86/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 3.9106 - val_accuracy: 0.0000e+00 - val_loss: 3.8382\n",
      "Epoch 87/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 4.0482 - val_accuracy: 0.0000e+00 - val_loss: 3.7985\n",
      "Epoch 88/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 3.9387 - val_accuracy: 0.0000e+00 - val_loss: 3.8615\n",
      "Epoch 89/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.0000e+00 - loss: 4.0554 - val_accuracy: 0.0000e+00 - val_loss: 3.9424\n",
      "Epoch 90/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.0000e+00 - loss: 3.8860 - val_accuracy: 0.0000e+00 - val_loss: 3.6605\n",
      "Epoch 91/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 3.9888 - val_accuracy: 0.0000e+00 - val_loss: 3.7720\n",
      "Epoch 92/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 4.0075 - val_accuracy: 0.0000e+00 - val_loss: 3.8663\n",
      "Epoch 93/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.0000e+00 - loss: 3.9189 - val_accuracy: 0.0000e+00 - val_loss: 3.9284\n",
      "Epoch 94/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 3.9418 - val_accuracy: 0.0000e+00 - val_loss: 3.9264\n",
      "Epoch 95/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 3.8853 - val_accuracy: 0.0000e+00 - val_loss: 3.6441\n",
      "Epoch 96/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.0000e+00 - loss: 4.0291 - val_accuracy: 0.0000e+00 - val_loss: 3.6869\n",
      "Epoch 97/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.0000e+00 - loss: 3.9873 - val_accuracy: 0.0000e+00 - val_loss: 3.7209\n",
      "Epoch 98/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 3.9945 - val_accuracy: 0.0000e+00 - val_loss: 3.8289\n",
      "Epoch 99/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 3.8943 - val_accuracy: 0.0000e+00 - val_loss: 4.0562\n",
      "Epoch 100/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.0000e+00 - loss: 3.9332 - val_accuracy: 0.0000e+00 - val_loss: 4.2863\n",
      "Epoch 101/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 3.9758 - val_accuracy: 0.0000e+00 - val_loss: 3.7365\n",
      "Epoch 102/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 4.0101 - val_accuracy: 0.0000e+00 - val_loss: 4.2043\n",
      "Epoch 103/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 4.0172 - val_accuracy: 0.0000e+00 - val_loss: 3.8036\n",
      "Epoch 104/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 3.9241 - val_accuracy: 0.0000e+00 - val_loss: 3.7049\n",
      "Epoch 105/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.0000e+00 - loss: 3.9499 - val_accuracy: 0.0000e+00 - val_loss: 3.9215\n",
      "Epoch 106/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 4.0409 - val_accuracy: 0.0000e+00 - val_loss: 3.9492\n",
      "Epoch 107/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.0000e+00 - loss: 3.8432 - val_accuracy: 0.0000e+00 - val_loss: 3.6535\n",
      "Epoch 108/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.0000e+00 - loss: 4.0243 - val_accuracy: 0.0000e+00 - val_loss: 3.7590\n",
      "Epoch 109/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 3.9989 - val_accuracy: 0.0000e+00 - val_loss: 3.7939\n",
      "Epoch 110/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.0000e+00 - loss: 3.9873 - val_accuracy: 0.0000e+00 - val_loss: 4.6857\n",
      "Epoch 111/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0000e+00 - loss: 4.0517 - val_accuracy: 0.0000e+00 - val_loss: 3.6970\n",
      "Epoch 112/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.0000e+00 - loss: 3.9075 - val_accuracy: 0.0000e+00 - val_loss: 3.7116\n",
      "Epoch 113/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 3.8839 - val_accuracy: 0.0000e+00 - val_loss: 3.7913\n",
      "Epoch 114/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 0.0000e+00 - loss: 3.9521 - val_accuracy: 0.0000e+00 - val_loss: 4.4545\n",
      "Epoch 115/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 4.1005 - val_accuracy: 0.0000e+00 - val_loss: 4.1499\n",
      "Epoch 116/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0000e+00 - loss: 3.8390 - val_accuracy: 0.0000e+00 - val_loss: 4.2101\n",
      "Epoch 117/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 4.0028 - val_accuracy: 0.0000e+00 - val_loss: 3.8706\n",
      "Epoch 118/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 3.9700 - val_accuracy: 0.0000e+00 - val_loss: 3.7660\n",
      "Epoch 119/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.0000e+00 - loss: 4.0421 - val_accuracy: 0.0000e+00 - val_loss: 3.8199\n",
      "Epoch 120/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.0000e+00 - loss: 4.0377 - val_accuracy: 0.0000e+00 - val_loss: 3.6676\n",
      "Epoch 121/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 3.9103 - val_accuracy: 0.0000e+00 - val_loss: 3.9237\n",
      "Epoch 122/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 3.9503 - val_accuracy: 0.0000e+00 - val_loss: 3.8945\n",
      "Epoch 123/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 3.8742 - val_accuracy: 0.0000e+00 - val_loss: 3.9048\n",
      "Epoch 124/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 3.9462 - val_accuracy: 0.0000e+00 - val_loss: 3.6449\n",
      "Epoch 125/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.0000e+00 - loss: 3.8999 - val_accuracy: 0.0000e+00 - val_loss: 3.8694\n",
      "Epoch 126/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.0000e+00 - loss: 3.8001 - val_accuracy: 0.0000e+00 - val_loss: 4.4625\n",
      "Epoch 127/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 3.9807 - val_accuracy: 0.0000e+00 - val_loss: 3.8169\n",
      "Epoch 128/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.0000e+00 - loss: 3.9601 - val_accuracy: 0.0000e+00 - val_loss: 3.6213\n",
      "Epoch 129/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.0000e+00 - loss: 3.8617 - val_accuracy: 0.0000e+00 - val_loss: 3.7122\n",
      "Epoch 130/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.0000e+00 - loss: 3.9551 - val_accuracy: 0.0000e+00 - val_loss: 3.6573\n",
      "Epoch 131/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 3.8916 - val_accuracy: 0.0000e+00 - val_loss: 3.6988\n",
      "Epoch 132/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.0000e+00 - loss: 4.0004 - val_accuracy: 0.0000e+00 - val_loss: 3.6204\n",
      "Epoch 133/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 3.9105 - val_accuracy: 0.0000e+00 - val_loss: 3.5958\n",
      "Epoch 134/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.0000e+00 - loss: 3.7887 - val_accuracy: 0.0000e+00 - val_loss: 4.2497\n",
      "Epoch 135/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 3.8454 - val_accuracy: 0.0000e+00 - val_loss: 4.0637\n",
      "Epoch 136/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.0000e+00 - loss: 3.8912 - val_accuracy: 0.0000e+00 - val_loss: 4.0658\n",
      "Epoch 137/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 3.9618 - val_accuracy: 0.0000e+00 - val_loss: 3.7663\n",
      "Epoch 138/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 3.8519 - val_accuracy: 0.0000e+00 - val_loss: 3.6996\n",
      "Epoch 139/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.8879 - val_accuracy: 0.0000e+00 - val_loss: 3.9632\n",
      "Epoch 140/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.0000e+00 - loss: 3.8163 - val_accuracy: 0.0000e+00 - val_loss: 4.1928\n",
      "Epoch 141/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.0000e+00 - loss: 3.9053 - val_accuracy: 0.0000e+00 - val_loss: 3.9285\n",
      "Epoch 142/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.0000e+00 - loss: 3.8757 - val_accuracy: 0.0000e+00 - val_loss: 4.1151\n",
      "Epoch 143/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.0000e+00 - loss: 3.9219 - val_accuracy: 0.0000e+00 - val_loss: 4.2130\n",
      "Epoch 144/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.0000e+00 - loss: 3.8861 - val_accuracy: 0.0000e+00 - val_loss: 3.9843\n",
      "Epoch 145/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.0000e+00 - loss: 3.8867 - val_accuracy: 0.0000e+00 - val_loss: 3.7577\n",
      "Epoch 146/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 3.8650 - val_accuracy: 0.0000e+00 - val_loss: 3.5566\n",
      "Epoch 147/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0000e+00 - loss: 3.8691 - val_accuracy: 0.0000e+00 - val_loss: 3.6826\n",
      "Epoch 148/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.0000e+00 - loss: 3.8344 - val_accuracy: 0.0000e+00 - val_loss: 3.5867\n",
      "Epoch 149/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0000e+00 - loss: 3.9416 - val_accuracy: 0.0000e+00 - val_loss: 3.6493\n",
      "Epoch 150/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 3.8068 - val_accuracy: 0.0000e+00 - val_loss: 3.6251\n",
      "Epoch 151/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.0000e+00 - loss: 3.9149 - val_accuracy: 0.0000e+00 - val_loss: 3.6345\n",
      "Epoch 152/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.0000e+00 - loss: 3.8239 - val_accuracy: 0.0000e+00 - val_loss: 3.7685\n",
      "Epoch 153/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 0.0000e+00 - loss: 3.7295 - val_accuracy: 0.0000e+00 - val_loss: 3.5636\n",
      "Epoch 154/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 3.8492 - val_accuracy: 0.0000e+00 - val_loss: 3.6377\n",
      "Epoch 155/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.0000e+00 - loss: 3.7819 - val_accuracy: 0.0000e+00 - val_loss: 3.7140\n",
      "Epoch 156/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 3.9428 - val_accuracy: 0.0000e+00 - val_loss: 4.0631\n",
      "Epoch 157/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.0000e+00 - loss: 3.8568 - val_accuracy: 0.0000e+00 - val_loss: 3.8205\n",
      "Epoch 158/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.0000e+00 - loss: 3.9104 - val_accuracy: 0.0000e+00 - val_loss: 4.0569\n",
      "Epoch 159/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.0000e+00 - loss: 3.9521 - val_accuracy: 0.0000e+00 - val_loss: 3.6371\n",
      "Epoch 160/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 3.9324 - val_accuracy: 0.0000e+00 - val_loss: 4.2761\n",
      "Epoch 161/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.0000e+00 - loss: 3.9434 - val_accuracy: 0.0000e+00 - val_loss: 3.8041\n",
      "Epoch 162/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.0000e+00 - loss: 3.7836 - val_accuracy: 0.0000e+00 - val_loss: 3.6247\n",
      "Epoch 163/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.0000e+00 - loss: 3.9708 - val_accuracy: 0.0000e+00 - val_loss: 3.5666\n",
      "Epoch 164/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0000e+00 - loss: 3.8908 - val_accuracy: 0.0000e+00 - val_loss: 4.2181\n",
      "Epoch 165/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 3.8731 - val_accuracy: 0.0000e+00 - val_loss: 3.7194\n",
      "Epoch 166/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 3.8480 - val_accuracy: 0.0000e+00 - val_loss: 3.5912\n",
      "Epoch 167/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.0000e+00 - loss: 3.8965 - val_accuracy: 0.0000e+00 - val_loss: 3.9449\n",
      "Epoch 168/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.0000e+00 - loss: 3.8436 - val_accuracy: 0.0000e+00 - val_loss: 3.7775\n",
      "Epoch 169/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 3.7983 - val_accuracy: 0.0000e+00 - val_loss: 3.6257\n",
      "Epoch 170/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 3.9182 - val_accuracy: 0.0000e+00 - val_loss: 3.9359\n",
      "Epoch 171/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 3.8530 - val_accuracy: 0.0000e+00 - val_loss: 3.9644\n",
      "Epoch 172/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 3.8261 - val_accuracy: 0.0000e+00 - val_loss: 3.6583\n",
      "Epoch 173/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.0000e+00 - loss: 3.7460 - val_accuracy: 0.0000e+00 - val_loss: 3.5368\n",
      "Epoch 174/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 3.8073 - val_accuracy: 0.0000e+00 - val_loss: 3.5834\n",
      "Epoch 175/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.0000e+00 - loss: 3.7940 - val_accuracy: 0.0000e+00 - val_loss: 3.5935\n",
      "Epoch 176/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.0000e+00 - loss: 3.8847 - val_accuracy: 0.0000e+00 - val_loss: 4.2809\n",
      "Epoch 177/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 3.7698 - val_accuracy: 0.0000e+00 - val_loss: 4.1402\n",
      "Epoch 178/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.0000e+00 - loss: 3.7779 - val_accuracy: 0.0000e+00 - val_loss: 3.6040\n",
      "Epoch 179/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.0000e+00 - loss: 3.8066 - val_accuracy: 0.0000e+00 - val_loss: 3.5894\n",
      "Epoch 180/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 3.7796 - val_accuracy: 0.0000e+00 - val_loss: 4.4181\n",
      "Epoch 181/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 3.8866 - val_accuracy: 0.0000e+00 - val_loss: 3.5905\n",
      "Epoch 182/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0000e+00 - loss: 3.7414 - val_accuracy: 0.0000e+00 - val_loss: 3.8920\n",
      "Epoch 183/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 3.9313 - val_accuracy: 0.0000e+00 - val_loss: 3.7340\n",
      "Epoch 184/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.0000e+00 - loss: 3.7994 - val_accuracy: 0.0000e+00 - val_loss: 3.9133\n",
      "Epoch 185/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 3.6963 - val_accuracy: 0.0000e+00 - val_loss: 4.2924\n",
      "Epoch 186/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 3.8554 - val_accuracy: 0.0000e+00 - val_loss: 3.6565\n",
      "Epoch 187/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.0000e+00 - loss: 3.7851 - val_accuracy: 0.0000e+00 - val_loss: 3.7608\n",
      "Epoch 188/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.0000e+00 - loss: 3.7054 - val_accuracy: 0.0000e+00 - val_loss: 4.0331\n",
      "Epoch 189/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 3.8120 - val_accuracy: 0.0000e+00 - val_loss: 3.5886\n",
      "Epoch 190/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 3.7017 - val_accuracy: 0.0000e+00 - val_loss: 3.5340\n",
      "Epoch 191/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 3.7737 - val_accuracy: 0.0000e+00 - val_loss: 3.5762\n",
      "Epoch 192/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.0000e+00 - loss: 3.8741 - val_accuracy: 0.0000e+00 - val_loss: 3.6824\n",
      "Epoch 193/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.0000e+00 - loss: 3.8134 - val_accuracy: 0.0000e+00 - val_loss: 4.6805\n",
      "Epoch 194/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 3.9256 - val_accuracy: 0.0000e+00 - val_loss: 4.7798\n",
      "Epoch 195/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.0000e+00 - loss: 3.9187 - val_accuracy: 0.0000e+00 - val_loss: 3.8499\n",
      "Epoch 196/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 3.7304 - val_accuracy: 0.0000e+00 - val_loss: 3.8194\n",
      "Epoch 197/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 3.8969 - val_accuracy: 0.0000e+00 - val_loss: 4.5977\n",
      "Epoch 198/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.0000e+00 - loss: 3.8004 - val_accuracy: 0.0000e+00 - val_loss: 3.5855\n",
      "Epoch 199/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.0000e+00 - loss: 3.6861 - val_accuracy: 0.0000e+00 - val_loss: 3.6212\n",
      "Epoch 200/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 3.8071 - val_accuracy: 0.0000e+00 - val_loss: 3.4770\n",
      "Epoch 201/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 3.8457 - val_accuracy: 0.0000e+00 - val_loss: 3.6723\n",
      "Epoch 202/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.0000e+00 - loss: 3.7807 - val_accuracy: 0.0000e+00 - val_loss: 3.5202\n",
      "Epoch 203/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 3.7536 - val_accuracy: 0.0000e+00 - val_loss: 3.6476\n",
      "Epoch 204/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 3.8841 - val_accuracy: 0.0000e+00 - val_loss: 4.4768\n",
      "Epoch 205/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 3.9038 - val_accuracy: 0.0000e+00 - val_loss: 3.6324\n",
      "Epoch 206/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 0.0000e+00 - loss: 3.9302 - val_accuracy: 0.0000e+00 - val_loss: 3.5077\n",
      "Epoch 207/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 3.7700 - val_accuracy: 0.0000e+00 - val_loss: 3.5714\n",
      "Epoch 208/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 3.6810 - val_accuracy: 0.0000e+00 - val_loss: 4.2260\n",
      "Epoch 209/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.0000e+00 - loss: 3.8714 - val_accuracy: 0.0000e+00 - val_loss: 3.4600\n",
      "Epoch 210/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 0.0000e+00 - loss: 3.7870 - val_accuracy: 0.0000e+00 - val_loss: 3.7567\n",
      "Epoch 211/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.0000e+00 - loss: 3.7221 - val_accuracy: 0.0000e+00 - val_loss: 3.6847\n",
      "Epoch 212/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.0000e+00 - loss: 3.9875 - val_accuracy: 0.0000e+00 - val_loss: 3.5138\n",
      "Epoch 213/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.0000e+00 - loss: 3.7841 - val_accuracy: 0.0000e+00 - val_loss: 3.7125\n",
      "Epoch 214/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.0000e+00 - loss: 3.7299 - val_accuracy: 0.0000e+00 - val_loss: 3.5129\n",
      "Epoch 215/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 3.7077 - val_accuracy: 0.0000e+00 - val_loss: 3.6682\n",
      "Epoch 216/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 3.7152 - val_accuracy: 0.0000e+00 - val_loss: 3.6252\n",
      "Epoch 217/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 3.6260 - val_accuracy: 0.0000e+00 - val_loss: 3.8552\n",
      "Epoch 218/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.0000e+00 - loss: 3.8088 - val_accuracy: 0.0000e+00 - val_loss: 3.7695\n",
      "Epoch 219/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.0000e+00 - loss: 3.7885 - val_accuracy: 0.0000e+00 - val_loss: 3.7511\n",
      "Epoch 220/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.0000e+00 - loss: 3.7000 - val_accuracy: 0.0000e+00 - val_loss: 3.5912\n",
      "Epoch 221/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 3.7358 - val_accuracy: 0.0000e+00 - val_loss: 3.6811\n",
      "Epoch 222/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.0000e+00 - loss: 3.7495 - val_accuracy: 0.0000e+00 - val_loss: 4.0239\n",
      "Epoch 223/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 3.8487 - val_accuracy: 0.0000e+00 - val_loss: 3.8700\n",
      "Epoch 224/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.0000e+00 - loss: 3.7393 - val_accuracy: 0.0000e+00 - val_loss: 3.9788\n",
      "Epoch 225/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 3.6525 - val_accuracy: 0.0000e+00 - val_loss: 3.4812\n",
      "Epoch 226/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.0000e+00 - loss: 3.7545 - val_accuracy: 0.0000e+00 - val_loss: 3.4883\n",
      "Epoch 227/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.0000e+00 - loss: 3.7980 - val_accuracy: 0.0000e+00 - val_loss: 3.6776\n",
      "Epoch 228/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.0000e+00 - loss: 3.7727 - val_accuracy: 0.0000e+00 - val_loss: 3.4527\n",
      "Epoch 229/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.0000e+00 - loss: 3.7303 - val_accuracy: 0.0000e+00 - val_loss: 4.0809\n",
      "Epoch 230/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 3.7008 - val_accuracy: 0.0000e+00 - val_loss: 3.6693\n",
      "Epoch 231/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 3.6953 - val_accuracy: 0.0000e+00 - val_loss: 3.4668\n",
      "Epoch 232/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0000e+00 - loss: 3.7661 - val_accuracy: 0.0000e+00 - val_loss: 3.5334\n",
      "Epoch 233/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 3.6474 - val_accuracy: 0.0000e+00 - val_loss: 3.4897\n",
      "Epoch 234/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.0000e+00 - loss: 3.7217 - val_accuracy: 0.0000e+00 - val_loss: 3.5090\n",
      "Epoch 235/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.0000e+00 - loss: 3.6700 - val_accuracy: 0.0000e+00 - val_loss: 3.5029\n",
      "Epoch 236/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.0000e+00 - loss: 3.8173 - val_accuracy: 0.0000e+00 - val_loss: 3.6079\n",
      "Epoch 237/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 3.6492 - val_accuracy: 0.0000e+00 - val_loss: 3.4915\n",
      "Epoch 238/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 3.7420 - val_accuracy: 0.0000e+00 - val_loss: 4.4331\n",
      "Epoch 239/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 3.7941 - val_accuracy: 0.0000e+00 - val_loss: 4.1111\n",
      "Epoch 240/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.0000e+00 - loss: 3.8815 - val_accuracy: 0.0000e+00 - val_loss: 3.5022\n",
      "Epoch 241/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 3.8417 - val_accuracy: 0.0000e+00 - val_loss: 3.6553\n",
      "Epoch 242/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.0000e+00 - loss: 3.6744 - val_accuracy: 0.0000e+00 - val_loss: 3.5549\n",
      "Epoch 243/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 3.8920 - val_accuracy: 0.0000e+00 - val_loss: 3.6172\n",
      "Epoch 244/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.0000e+00 - loss: 3.6755 - val_accuracy: 0.0000e+00 - val_loss: 3.5507\n",
      "Epoch 245/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 3.6791 - val_accuracy: 0.0000e+00 - val_loss: 3.9207\n",
      "Epoch 246/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 3.7609 - val_accuracy: 0.0000e+00 - val_loss: 4.2358\n",
      "Epoch 247/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 3.8539 - val_accuracy: 0.0000e+00 - val_loss: 3.4875\n",
      "Epoch 248/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.0000e+00 - loss: 3.6953 - val_accuracy: 0.0000e+00 - val_loss: 4.8444\n",
      "Epoch 249/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.0000e+00 - loss: 3.8332 - val_accuracy: 0.0000e+00 - val_loss: 3.4824\n",
      "Epoch 250/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.0000e+00 - loss: 3.5575 - val_accuracy: 0.0000e+00 - val_loss: 3.5804\n",
      "Epoch 251/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 3.7706 - val_accuracy: 0.0000e+00 - val_loss: 3.7436\n",
      "Epoch 252/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 3.7789 - val_accuracy: 0.0000e+00 - val_loss: 3.5137\n",
      "Epoch 253/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 3.6121 - val_accuracy: 0.0000e+00 - val_loss: 3.8370\n",
      "Epoch 254/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 3.8598 - val_accuracy: 0.0000e+00 - val_loss: 3.5106\n",
      "Epoch 255/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.0000e+00 - loss: 3.7799 - val_accuracy: 0.0000e+00 - val_loss: 3.7387\n",
      "Epoch 256/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.0000e+00 - loss: 3.7626 - val_accuracy: 0.0000e+00 - val_loss: 3.6057\n",
      "Epoch 257/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 3.6516 - val_accuracy: 0.0000e+00 - val_loss: 3.4229\n",
      "Epoch 258/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 3.6453 - val_accuracy: 0.0000e+00 - val_loss: 3.6280\n",
      "Epoch 259/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 3.7024 - val_accuracy: 0.0000e+00 - val_loss: 3.6124\n",
      "Epoch 260/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 3.8242 - val_accuracy: 0.0000e+00 - val_loss: 3.8419\n",
      "Epoch 261/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 0.0000e+00 - loss: 3.7094 - val_accuracy: 0.0000e+00 - val_loss: 3.8607\n",
      "Epoch 262/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.0000e+00 - loss: 3.6805 - val_accuracy: 0.0000e+00 - val_loss: 3.4367\n",
      "Epoch 263/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.0000e+00 - loss: 3.7175 - val_accuracy: 0.0000e+00 - val_loss: 3.4645\n",
      "Epoch 264/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.0000e+00 - loss: 3.5996 - val_accuracy: 0.0000e+00 - val_loss: 4.0420\n",
      "Epoch 265/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.0000e+00 - loss: 3.7310 - val_accuracy: 0.0000e+00 - val_loss: 3.4071\n",
      "Epoch 266/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 3.7709 - val_accuracy: 0.0000e+00 - val_loss: 3.7885\n",
      "Epoch 267/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.0000e+00 - loss: 3.8122 - val_accuracy: 0.0000e+00 - val_loss: 3.6873\n",
      "Epoch 268/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.0000e+00 - loss: 3.7953 - val_accuracy: 0.0000e+00 - val_loss: 3.4850\n",
      "Epoch 269/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 3.7806 - val_accuracy: 0.0000e+00 - val_loss: 3.9203\n",
      "Epoch 270/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.0000e+00 - loss: 3.6984 - val_accuracy: 0.0000e+00 - val_loss: 3.8149\n",
      "Epoch 271/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.0000e+00 - loss: 3.6179 - val_accuracy: 0.0000e+00 - val_loss: 3.8905\n",
      "Epoch 272/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 3.7471 - val_accuracy: 0.0000e+00 - val_loss: 3.8450\n",
      "Epoch 273/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 3.6636 - val_accuracy: 0.0000e+00 - val_loss: 3.8019\n",
      "Epoch 274/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.0000e+00 - loss: 3.6808 - val_accuracy: 0.0000e+00 - val_loss: 3.8718\n",
      "Epoch 275/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.0000e+00 - loss: 3.6730 - val_accuracy: 0.0000e+00 - val_loss: 3.4361\n",
      "Epoch 276/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.0000e+00 - loss: 3.6657 - val_accuracy: 0.0000e+00 - val_loss: 3.9650\n",
      "Epoch 277/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.0000e+00 - loss: 3.6584 - val_accuracy: 0.0000e+00 - val_loss: 3.4065\n",
      "Epoch 278/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 3.6560 - val_accuracy: 0.0000e+00 - val_loss: 3.8163\n",
      "Epoch 279/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 3.8172 - val_accuracy: 0.0000e+00 - val_loss: 3.7472\n",
      "Epoch 280/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 3.7488 - val_accuracy: 0.0000e+00 - val_loss: 4.1551\n",
      "Epoch 281/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 3.7279 - val_accuracy: 0.0000e+00 - val_loss: 3.4719\n",
      "Epoch 282/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 3.6655 - val_accuracy: 0.0000e+00 - val_loss: 3.7093\n",
      "Epoch 283/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.0000e+00 - loss: 3.8013 - val_accuracy: 0.0000e+00 - val_loss: 3.5591\n",
      "Epoch 284/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.0000e+00 - loss: 3.6852 - val_accuracy: 0.0000e+00 - val_loss: 3.4227\n",
      "Epoch 285/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.0000e+00 - loss: 3.6839 - val_accuracy: 0.0000e+00 - val_loss: 3.6870\n",
      "Epoch 286/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 3.7136 - val_accuracy: 0.0000e+00 - val_loss: 3.7520\n",
      "Epoch 287/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.0000e+00 - loss: 3.6220 - val_accuracy: 0.0000e+00 - val_loss: 3.4963\n",
      "Epoch 288/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 3.7999 - val_accuracy: 0.0000e+00 - val_loss: 3.4654\n",
      "Epoch 289/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.0000e+00 - loss: 3.7858 - val_accuracy: 0.0000e+00 - val_loss: 3.4286\n",
      "Epoch 290/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.0000e+00 - loss: 3.7524 - val_accuracy: 0.0000e+00 - val_loss: 3.7180\n",
      "Epoch 291/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.0000e+00 - loss: 3.7418 - val_accuracy: 0.0000e+00 - val_loss: 3.8503\n",
      "Epoch 292/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.0000e+00 - loss: 3.7196 - val_accuracy: 0.0000e+00 - val_loss: 3.5201\n",
      "Epoch 293/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.0000e+00 - loss: 3.6905 - val_accuracy: 0.0000e+00 - val_loss: 3.7860\n",
      "Epoch 294/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.0000e+00 - loss: 3.6893 - val_accuracy: 0.0000e+00 - val_loss: 3.4379\n",
      "Epoch 295/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.0000e+00 - loss: 3.7196 - val_accuracy: 0.0000e+00 - val_loss: 3.5873\n",
      "Epoch 296/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 3.8128 - val_accuracy: 0.0000e+00 - val_loss: 4.0953\n",
      "Epoch 297/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.0000e+00 - loss: 3.7714 - val_accuracy: 0.0000e+00 - val_loss: 3.6107\n",
      "Epoch 298/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.0000e+00 - loss: 3.8770 - val_accuracy: 0.0000e+00 - val_loss: 3.3968\n",
      "Epoch 299/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.0000e+00 - loss: 3.7089 - val_accuracy: 0.0000e+00 - val_loss: 3.7404\n",
      "Epoch 300/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.0000e+00 - loss: 3.7428 - val_accuracy: 0.0000e+00 - val_loss: 3.4889\n",
      "Epoch 301/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.7795 - val_accuracy: 0.0000e+00 - val_loss: 3.4635\n",
      "Epoch 302/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 3.6516 - val_accuracy: 0.0000e+00 - val_loss: 3.6146\n",
      "Epoch 303/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 3.6518 - val_accuracy: 0.0000e+00 - val_loss: 4.3388\n",
      "Epoch 304/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 0.0000e+00 - loss: 3.8505 - val_accuracy: 0.0000e+00 - val_loss: 3.6743\n",
      "Epoch 305/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 3.6244 - val_accuracy: 0.0000e+00 - val_loss: 3.5417\n",
      "Epoch 306/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 3.6506 - val_accuracy: 0.0000e+00 - val_loss: 4.0717\n",
      "Epoch 307/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.0000e+00 - loss: 3.7492 - val_accuracy: 0.0000e+00 - val_loss: 3.6860\n",
      "Epoch 308/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.0000e+00 - loss: 3.6833 - val_accuracy: 0.0000e+00 - val_loss: 3.6555\n",
      "Epoch 309/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 3.6287 - val_accuracy: 0.0000e+00 - val_loss: 3.5730\n",
      "Epoch 310/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 3.7027 - val_accuracy: 0.0000e+00 - val_loss: 3.4759\n",
      "Epoch 311/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 3.7104 - val_accuracy: 0.0000e+00 - val_loss: 3.5935\n",
      "Epoch 312/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 3.5808 - val_accuracy: 0.0000e+00 - val_loss: 3.6989\n",
      "Epoch 313/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 3.6708 - val_accuracy: 0.0000e+00 - val_loss: 3.4045\n",
      "Epoch 314/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 3.6820 - val_accuracy: 0.0000e+00 - val_loss: 3.5843\n",
      "Epoch 315/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 3.6338 - val_accuracy: 0.0000e+00 - val_loss: 3.3813\n",
      "Epoch 316/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 3.5306 - val_accuracy: 0.0000e+00 - val_loss: 3.4942\n",
      "Epoch 317/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.0000e+00 - loss: 3.7068 - val_accuracy: 0.0000e+00 - val_loss: 3.4233\n",
      "Epoch 318/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 3.6243 - val_accuracy: 0.0000e+00 - val_loss: 3.8146\n",
      "Epoch 319/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.0000e+00 - loss: 3.6635 - val_accuracy: 0.0000e+00 - val_loss: 3.5149\n",
      "Epoch 320/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 3.7184 - val_accuracy: 0.0000e+00 - val_loss: 5.2298\n",
      "Epoch 321/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.0000e+00 - loss: 3.6755 - val_accuracy: 0.0000e+00 - val_loss: 3.7098\n",
      "Epoch 322/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.0000e+00 - loss: 3.6724 - val_accuracy: 0.0000e+00 - val_loss: 3.3870\n",
      "Epoch 323/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 3.6469 - val_accuracy: 0.0000e+00 - val_loss: 3.8466\n",
      "Epoch 324/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 3.6289 - val_accuracy: 0.0000e+00 - val_loss: 3.4356\n",
      "Epoch 325/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 3.6260 - val_accuracy: 0.0000e+00 - val_loss: 3.8294\n",
      "Epoch 326/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 3.7857 - val_accuracy: 0.0000e+00 - val_loss: 3.8604\n",
      "Epoch 327/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 3.6313 - val_accuracy: 0.0000e+00 - val_loss: 3.4490\n",
      "Epoch 328/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 3.6889 - val_accuracy: 0.0000e+00 - val_loss: 3.3999\n",
      "Epoch 329/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 3.7625 - val_accuracy: 0.0000e+00 - val_loss: 3.5136\n",
      "Epoch 330/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 3.6649 - val_accuracy: 0.0000e+00 - val_loss: 3.8535\n",
      "Epoch 331/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.0000e+00 - loss: 3.5929 - val_accuracy: 0.0000e+00 - val_loss: 3.3709\n",
      "Epoch 332/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 3.7003 - val_accuracy: 0.0000e+00 - val_loss: 3.3700\n",
      "Epoch 333/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 3.7043 - val_accuracy: 0.0000e+00 - val_loss: 4.4360\n",
      "Epoch 334/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.0000e+00 - loss: 3.7469 - val_accuracy: 0.0000e+00 - val_loss: 3.4129\n",
      "Epoch 335/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 3.7668 - val_accuracy: 0.0000e+00 - val_loss: 3.4052\n",
      "Epoch 336/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.0000e+00 - loss: 3.5782 - val_accuracy: 0.0000e+00 - val_loss: 3.9259\n",
      "Epoch 337/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.0000e+00 - loss: 3.6532 - val_accuracy: 0.0000e+00 - val_loss: 3.4608\n",
      "Epoch 338/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.0000e+00 - loss: 3.5986 - val_accuracy: 0.0000e+00 - val_loss: 3.5461\n",
      "Epoch 339/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.0000e+00 - loss: 3.6407 - val_accuracy: 0.0000e+00 - val_loss: 3.6953\n",
      "Epoch 340/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.0000e+00 - loss: 3.6597 - val_accuracy: 0.0000e+00 - val_loss: 3.9265\n",
      "Epoch 341/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 3.6988 - val_accuracy: 0.0000e+00 - val_loss: 3.5665\n",
      "Epoch 342/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.0000e+00 - loss: 3.6761 - val_accuracy: 0.0000e+00 - val_loss: 3.5966\n",
      "Epoch 343/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.0000e+00 - loss: 3.7812 - val_accuracy: 0.0000e+00 - val_loss: 3.3619\n",
      "Epoch 344/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 3.6866 - val_accuracy: 0.0000e+00 - val_loss: 3.8167\n",
      "Epoch 345/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 3.5725 - val_accuracy: 0.0000e+00 - val_loss: 3.6125\n",
      "Epoch 346/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 0.0000e+00 - loss: 3.7270 - val_accuracy: 0.0000e+00 - val_loss: 3.4393\n",
      "Epoch 347/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 3.7818 - val_accuracy: 0.0000e+00 - val_loss: 4.0140\n",
      "Epoch 348/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 3.6094 - val_accuracy: 0.0000e+00 - val_loss: 3.5102\n",
      "Epoch 349/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.0000e+00 - loss: 3.6867 - val_accuracy: 0.0000e+00 - val_loss: 3.3744\n",
      "Epoch 350/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 3.5870 - val_accuracy: 0.0000e+00 - val_loss: 3.3652\n",
      "Epoch 351/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.0000e+00 - loss: 3.6125 - val_accuracy: 0.0000e+00 - val_loss: 3.3541\n",
      "Epoch 352/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0000e+00 - loss: 3.5384 - val_accuracy: 0.0000e+00 - val_loss: 3.5025\n",
      "Epoch 353/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 3.6754 - val_accuracy: 0.0000e+00 - val_loss: 3.4788\n",
      "Epoch 354/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.0000e+00 - loss: 3.7842 - val_accuracy: 0.0000e+00 - val_loss: 3.4182\n",
      "Epoch 355/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.0000e+00 - loss: 3.6404 - val_accuracy: 0.0000e+00 - val_loss: 3.7560\n",
      "Epoch 356/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 3.6180 - val_accuracy: 0.0000e+00 - val_loss: 3.5152\n",
      "Epoch 357/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.6603 - val_accuracy: 0.0000e+00 - val_loss: 3.5022\n",
      "Epoch 358/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 3.5945 - val_accuracy: 0.0000e+00 - val_loss: 3.3906\n",
      "Epoch 359/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.0000e+00 - loss: 3.7395 - val_accuracy: 0.0000e+00 - val_loss: 3.5252\n",
      "Epoch 360/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.6134 - val_accuracy: 0.0000e+00 - val_loss: 3.4032\n",
      "Epoch 361/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 3.6351 - val_accuracy: 0.0000e+00 - val_loss: 4.0912\n",
      "Epoch 362/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 3.7405 - val_accuracy: 0.0000e+00 - val_loss: 3.7805\n",
      "Epoch 363/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 0.0000e+00 - loss: 3.6700 - val_accuracy: 0.0000e+00 - val_loss: 3.5618\n",
      "Epoch 364/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 3.6206 - val_accuracy: 0.0000e+00 - val_loss: 3.3718\n",
      "Epoch 365/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.0000e+00 - loss: 3.7588 - val_accuracy: 0.0000e+00 - val_loss: 3.3501\n",
      "Epoch 366/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.0000e+00 - loss: 3.6574 - val_accuracy: 0.0000e+00 - val_loss: 3.4379\n",
      "Epoch 367/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 3.6565 - val_accuracy: 0.0000e+00 - val_loss: 3.4108\n",
      "Epoch 368/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.0000e+00 - loss: 3.6692 - val_accuracy: 0.0000e+00 - val_loss: 3.4597\n",
      "Epoch 369/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.0000e+00 - loss: 3.5664 - val_accuracy: 0.0000e+00 - val_loss: 3.5946\n",
      "Epoch 370/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 3.6146 - val_accuracy: 0.0000e+00 - val_loss: 3.4476\n",
      "Epoch 371/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 0.0000e+00 - loss: 3.6207 - val_accuracy: 0.0000e+00 - val_loss: 3.3837\n",
      "Epoch 372/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0000e+00 - loss: 3.5285 - val_accuracy: 0.0000e+00 - val_loss: 3.9384\n",
      "Epoch 373/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 3.8607 - val_accuracy: 0.0000e+00 - val_loss: 3.6342\n",
      "Epoch 374/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.0000e+00 - loss: 3.6358 - val_accuracy: 0.0000e+00 - val_loss: 3.5499\n",
      "Epoch 375/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 3.6824 - val_accuracy: 0.0000e+00 - val_loss: 3.5692\n",
      "Epoch 376/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 3.5772 - val_accuracy: 0.0000e+00 - val_loss: 3.4518\n",
      "Epoch 377/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.0000e+00 - loss: 3.6664 - val_accuracy: 0.0000e+00 - val_loss: 3.6671\n",
      "Epoch 378/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 3.5551 - val_accuracy: 0.0000e+00 - val_loss: 3.4567\n",
      "Epoch 379/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - accuracy: 0.0000e+00 - loss: 3.5831 - val_accuracy: 0.0000e+00 - val_loss: 3.5224\n",
      "Epoch 380/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 3.5946 - val_accuracy: 0.0000e+00 - val_loss: 3.4992\n",
      "Epoch 381/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.0000e+00 - loss: 3.5969 - val_accuracy: 0.0000e+00 - val_loss: 3.6616\n",
      "Epoch 382/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.5501 - val_accuracy: 0.0000e+00 - val_loss: 3.4897\n",
      "Epoch 383/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.6725 - val_accuracy: 0.0000e+00 - val_loss: 3.8232\n",
      "Epoch 384/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 3.6423 - val_accuracy: 0.0000e+00 - val_loss: 4.9610\n",
      "Epoch 385/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.0000e+00 - loss: 3.5803 - val_accuracy: 0.0000e+00 - val_loss: 3.4322\n",
      "Epoch 386/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.0000e+00 - loss: 3.6935 - val_accuracy: 0.0000e+00 - val_loss: 3.9488\n",
      "Epoch 387/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.0000e+00 - loss: 3.6519 - val_accuracy: 0.0000e+00 - val_loss: 3.3780\n",
      "Epoch 388/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.0000e+00 - loss: 3.6199 - val_accuracy: 0.0000e+00 - val_loss: 3.6287\n",
      "Epoch 389/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 3.7175 - val_accuracy: 0.0000e+00 - val_loss: 3.6696\n",
      "Epoch 390/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - accuracy: 0.0000e+00 - loss: 3.6819 - val_accuracy: 0.0000e+00 - val_loss: 3.4170\n",
      "Epoch 391/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.0000e+00 - loss: 3.7294 - val_accuracy: 0.0000e+00 - val_loss: 3.4525\n",
      "Epoch 392/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 3.6216 - val_accuracy: 0.0000e+00 - val_loss: 3.5765\n",
      "Epoch 393/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.0000e+00 - loss: 3.5434 - val_accuracy: 0.0000e+00 - val_loss: 3.4472\n",
      "Epoch 394/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.0000e+00 - loss: 3.5226 - val_accuracy: 0.0000e+00 - val_loss: 3.6534\n",
      "Epoch 395/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 3.6361 - val_accuracy: 0.0000e+00 - val_loss: 3.6343\n",
      "Epoch 396/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.0000e+00 - loss: 3.5693 - val_accuracy: 0.0000e+00 - val_loss: 3.7339\n",
      "Epoch 397/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 3.6878 - val_accuracy: 0.0000e+00 - val_loss: 3.5860\n",
      "Epoch 398/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.0000e+00 - loss: 3.7744 - val_accuracy: 0.0000e+00 - val_loss: 3.6811\n",
      "Epoch 399/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.0000e+00 - loss: 3.6400 - val_accuracy: 0.0000e+00 - val_loss: 3.4001\n",
      "Epoch 400/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 3.5244 - val_accuracy: 0.0000e+00 - val_loss: 3.5365\n",
      "Epoch 401/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.0000e+00 - loss: 3.7394 - val_accuracy: 0.0000e+00 - val_loss: 3.6371\n",
      "Epoch 402/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 3.6601 - val_accuracy: 0.0000e+00 - val_loss: 4.3767\n",
      "Epoch 403/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.0000e+00 - loss: 3.7885 - val_accuracy: 0.0000e+00 - val_loss: 3.4089\n",
      "Epoch 404/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.5431 - val_accuracy: 0.0000e+00 - val_loss: 3.6909\n",
      "Epoch 405/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 3.6790 - val_accuracy: 0.0000e+00 - val_loss: 3.4108\n",
      "Epoch 406/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 3.7573 - val_accuracy: 0.0000e+00 - val_loss: 3.6310\n",
      "Epoch 407/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 0.0000e+00 - loss: 3.6454 - val_accuracy: 0.0000e+00 - val_loss: 3.3835\n",
      "Epoch 408/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 3.5007 - val_accuracy: 0.0000e+00 - val_loss: 4.3720\n",
      "Epoch 409/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.0000e+00 - loss: 3.6345 - val_accuracy: 0.0000e+00 - val_loss: 3.4976\n",
      "Epoch 410/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 3.5455 - val_accuracy: 0.0000e+00 - val_loss: 3.5065\n",
      "Epoch 411/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 3.6356 - val_accuracy: 0.0000e+00 - val_loss: 3.7100\n",
      "Epoch 412/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.5576 - val_accuracy: 0.0000e+00 - val_loss: 3.7631\n",
      "Epoch 413/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 3.6180 - val_accuracy: 0.0000e+00 - val_loss: 4.4877\n",
      "Epoch 414/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.0000e+00 - loss: 3.7523 - val_accuracy: 0.0000e+00 - val_loss: 3.6913\n",
      "Epoch 415/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 3.5978 - val_accuracy: 0.0000e+00 - val_loss: 3.5947\n",
      "Epoch 416/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 3.7246 - val_accuracy: 0.0000e+00 - val_loss: 3.5276\n",
      "Epoch 417/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.0000e+00 - loss: 3.6360 - val_accuracy: 0.0000e+00 - val_loss: 3.7707\n",
      "Epoch 418/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.0000e+00 - loss: 3.6871 - val_accuracy: 0.0000e+00 - val_loss: 4.3060\n",
      "Epoch 419/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - accuracy: 0.0000e+00 - loss: 3.7436 - val_accuracy: 0.0000e+00 - val_loss: 3.3847\n",
      "Epoch 420/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 3.6363 - val_accuracy: 0.0000e+00 - val_loss: 3.4228\n",
      "Epoch 421/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.0000e+00 - loss: 3.7662 - val_accuracy: 0.0000e+00 - val_loss: 3.7210\n",
      "Epoch 422/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 3.5919 - val_accuracy: 0.0000e+00 - val_loss: 4.4019\n",
      "Epoch 423/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.0000e+00 - loss: 3.6046 - val_accuracy: 0.0000e+00 - val_loss: 3.3325\n",
      "Epoch 424/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.0000e+00 - loss: 3.8027 - val_accuracy: 0.0000e+00 - val_loss: 3.5689\n",
      "Epoch 425/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.0000e+00 - loss: 3.5978 - val_accuracy: 0.0000e+00 - val_loss: 3.9559\n",
      "Epoch 426/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.0000e+00 - loss: 3.6366 - val_accuracy: 0.0000e+00 - val_loss: 3.5675\n",
      "Epoch 427/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.5833 - val_accuracy: 0.0000e+00 - val_loss: 3.3655\n",
      "Epoch 428/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.0000e+00 - loss: 3.6516 - val_accuracy: 0.0000e+00 - val_loss: 3.3776\n",
      "Epoch 429/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.0000e+00 - loss: 3.6402 - val_accuracy: 0.0000e+00 - val_loss: 3.6212\n",
      "Epoch 430/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.0000e+00 - loss: 3.6685 - val_accuracy: 0.0000e+00 - val_loss: 3.3425\n",
      "Epoch 431/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 3.6879 - val_accuracy: 0.0000e+00 - val_loss: 3.4305\n",
      "Epoch 432/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.0000e+00 - loss: 3.6917 - val_accuracy: 0.0000e+00 - val_loss: 3.3393\n",
      "Epoch 433/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.0000e+00 - loss: 3.6126 - val_accuracy: 0.0000e+00 - val_loss: 3.5377\n",
      "Epoch 434/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - accuracy: 0.0000e+00 - loss: 3.6511 - val_accuracy: 0.0000e+00 - val_loss: 3.6810\n",
      "Epoch 435/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.0000e+00 - loss: 3.6304 - val_accuracy: 0.0000e+00 - val_loss: 3.5501\n",
      "Epoch 436/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.6814 - val_accuracy: 0.0000e+00 - val_loss: 3.6645\n",
      "Epoch 437/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.0000e+00 - loss: 3.6528 - val_accuracy: 0.0000e+00 - val_loss: 3.6982\n",
      "Epoch 438/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.0000e+00 - loss: 3.6729 - val_accuracy: 0.0000e+00 - val_loss: 3.3867\n",
      "Epoch 439/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.0000e+00 - loss: 3.6007 - val_accuracy: 0.0000e+00 - val_loss: 4.0249\n",
      "Epoch 440/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 0.0000e+00 - loss: 3.6825 - val_accuracy: 0.0000e+00 - val_loss: 3.6897\n",
      "Epoch 441/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.0000e+00 - loss: 3.5476 - val_accuracy: 0.0000e+00 - val_loss: 3.3637\n",
      "Epoch 442/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 3.6714 - val_accuracy: 0.0000e+00 - val_loss: 3.3560\n",
      "Epoch 443/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.0000e+00 - loss: 3.6555 - val_accuracy: 0.0000e+00 - val_loss: 3.7953\n",
      "Epoch 444/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 3.6929 - val_accuracy: 0.0000e+00 - val_loss: 3.5476\n",
      "Epoch 445/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 0.0000e+00 - loss: 3.6344 - val_accuracy: 0.0000e+00 - val_loss: 3.4033\n",
      "Epoch 446/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.0000e+00 - loss: 3.5834 - val_accuracy: 0.0000e+00 - val_loss: 3.4088\n",
      "Epoch 447/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.0000e+00 - loss: 3.6833 - val_accuracy: 0.0000e+00 - val_loss: 3.5038\n",
      "Epoch 448/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.0000e+00 - loss: 3.6626 - val_accuracy: 0.0000e+00 - val_loss: 3.5722\n",
      "Epoch 449/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 3.6572 - val_accuracy: 0.0000e+00 - val_loss: 3.6233\n",
      "Epoch 450/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.0000e+00 - loss: 3.7318 - val_accuracy: 0.0000e+00 - val_loss: 3.4783\n",
      "Epoch 451/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.0000e+00 - loss: 3.6924 - val_accuracy: 0.0000e+00 - val_loss: 4.0896\n",
      "Epoch 452/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.0000e+00 - loss: 3.6981 - val_accuracy: 0.0000e+00 - val_loss: 3.4247\n",
      "Epoch 453/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 3.6206 - val_accuracy: 0.0000e+00 - val_loss: 4.4316\n",
      "Epoch 454/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.0000e+00 - loss: 3.7452 - val_accuracy: 0.0000e+00 - val_loss: 3.7431\n",
      "Epoch 455/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.0000e+00 - loss: 3.4864 - val_accuracy: 0.0000e+00 - val_loss: 3.4591\n",
      "Epoch 456/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.0000e+00 - loss: 3.7482 - val_accuracy: 0.0000e+00 - val_loss: 3.7014\n",
      "Epoch 457/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.6223 - val_accuracy: 0.0000e+00 - val_loss: 3.5059\n",
      "Epoch 458/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 3.8047 - val_accuracy: 0.0000e+00 - val_loss: 4.1714\n",
      "Epoch 459/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 3.5646 - val_accuracy: 0.0000e+00 - val_loss: 3.3571\n",
      "Epoch 460/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.0000e+00 - loss: 3.6463 - val_accuracy: 0.0000e+00 - val_loss: 3.3558\n",
      "Epoch 461/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.0000e+00 - loss: 3.6211 - val_accuracy: 0.0000e+00 - val_loss: 3.6064\n",
      "Epoch 462/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.0000e+00 - loss: 3.6507 - val_accuracy: 0.0000e+00 - val_loss: 3.9826\n",
      "Epoch 463/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.0000e+00 - loss: 3.6246 - val_accuracy: 0.0000e+00 - val_loss: 3.6838\n",
      "Epoch 464/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - accuracy: 0.0000e+00 - loss: 3.6957 - val_accuracy: 0.0000e+00 - val_loss: 4.2782\n",
      "Epoch 465/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 0.0000e+00 - loss: 3.7035 - val_accuracy: 0.0000e+00 - val_loss: 3.3607\n",
      "Epoch 466/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.0000e+00 - loss: 3.6888 - val_accuracy: 0.0000e+00 - val_loss: 3.6611\n",
      "Epoch 467/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.0000e+00 - loss: 3.4557 - val_accuracy: 0.0000e+00 - val_loss: 3.9304\n",
      "Epoch 468/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.7329 - val_accuracy: 0.0000e+00 - val_loss: 3.6156\n",
      "Epoch 469/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 3.6256 - val_accuracy: 0.0000e+00 - val_loss: 3.4419\n",
      "Epoch 470/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 3.5049 - val_accuracy: 0.0000e+00 - val_loss: 3.5085\n",
      "Epoch 471/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.0000e+00 - loss: 3.6881 - val_accuracy: 0.0000e+00 - val_loss: 3.9096\n",
      "Epoch 472/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.5756 - val_accuracy: 0.0000e+00 - val_loss: 3.5088\n",
      "Epoch 473/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 3.6198 - val_accuracy: 0.0000e+00 - val_loss: 3.5247\n",
      "Epoch 474/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.0000e+00 - loss: 3.7264 - val_accuracy: 0.0000e+00 - val_loss: 3.6642\n",
      "Epoch 475/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.0000e+00 - loss: 3.6789 - val_accuracy: 0.0000e+00 - val_loss: 3.4435\n",
      "Epoch 476/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step - accuracy: 0.0000e+00 - loss: 3.5969 - val_accuracy: 0.0000e+00 - val_loss: 3.3997\n",
      "Epoch 477/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.0000e+00 - loss: 3.6202 - val_accuracy: 0.0000e+00 - val_loss: 4.1980\n",
      "Epoch 478/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.0000e+00 - loss: 3.6934 - val_accuracy: 0.0000e+00 - val_loss: 3.5879\n",
      "Epoch 479/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.0000e+00 - loss: 3.6173 - val_accuracy: 0.0000e+00 - val_loss: 3.5769\n",
      "Epoch 480/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 3.7558 - val_accuracy: 0.0000e+00 - val_loss: 3.8301\n",
      "Epoch 481/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.0000e+00 - loss: 3.7089 - val_accuracy: 0.0000e+00 - val_loss: 3.3945\n",
      "Epoch 482/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.0000e+00 - loss: 3.7403 - val_accuracy: 0.0000e+00 - val_loss: 3.8719\n",
      "Epoch 483/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.0000e+00 - loss: 3.6514 - val_accuracy: 0.0000e+00 - val_loss: 3.8281\n",
      "Epoch 484/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.0000e+00 - loss: 3.6811 - val_accuracy: 0.0000e+00 - val_loss: 3.4760\n",
      "Epoch 485/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.0000e+00 - loss: 3.5964 - val_accuracy: 0.0000e+00 - val_loss: 3.3806\n",
      "Epoch 486/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.0000e+00 - loss: 3.6672 - val_accuracy: 0.0000e+00 - val_loss: 3.4170\n",
      "Epoch 487/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.0000e+00 - loss: 3.6516 - val_accuracy: 0.0000e+00 - val_loss: 3.4301\n",
      "Epoch 488/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 3.6049 - val_accuracy: 0.0000e+00 - val_loss: 3.7704\n",
      "Epoch 489/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.0000e+00 - loss: 3.7779 - val_accuracy: 0.0000e+00 - val_loss: 3.4750\n",
      "Epoch 490/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 3.6627 - val_accuracy: 0.0000e+00 - val_loss: 3.4140\n",
      "Epoch 491/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.0000e+00 - loss: 3.5783 - val_accuracy: 0.0000e+00 - val_loss: 3.6939\n",
      "Epoch 492/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.0000e+00 - loss: 3.7156 - val_accuracy: 0.0000e+00 - val_loss: 3.4692\n",
      "Epoch 493/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 0.0000e+00 - loss: 3.6988 - val_accuracy: 0.0000e+00 - val_loss: 3.4399\n",
      "Epoch 494/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.0000e+00 - loss: 3.8003 - val_accuracy: 0.0000e+00 - val_loss: 3.6931\n",
      "Epoch 495/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 3.7127 - val_accuracy: 0.0000e+00 - val_loss: 3.5372\n",
      "Epoch 496/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 3.6218 - val_accuracy: 0.0000e+00 - val_loss: 3.5620\n",
      "Epoch 497/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.0000e+00 - loss: 3.6593 - val_accuracy: 0.0000e+00 - val_loss: 3.5495\n",
      "Epoch 498/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 0.0000e+00 - loss: 3.7129 - val_accuracy: 0.0000e+00 - val_loss: 3.6979\n",
      "Epoch 499/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.0000e+00 - loss: 3.6035 - val_accuracy: 0.0000e+00 - val_loss: 3.3410\n",
      "Epoch 500/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 0.0000e+00 - loss: 3.5540 - val_accuracy: 0.0000e+00 - val_loss: 3.4794\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step\n",
      "Metrics:\n",
      "Accuracy: 0.305\n",
      "MSE: 3.479355301775379\n",
      "MAE: 1.3806138361553097\n",
      "RMSE: 1.865303005352047\n",
      "F1 Score: 0.2835\n",
      "Training Time: 236.86879301071167\n",
      "Inference Time: 0.12463164329528809\n",
      "Model type: multi_layer_perceptron\n",
      "dataset: integration_with_sin_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"integration_with_sin_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "#perceptron_config = [(1, 'dense')]\n",
    "mlp_config = [\n",
    "    ('dense', 64, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 32, 'selu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "mlp_config = [\n",
    "    ('dense', 3, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 6, 'relu'),\n",
    "    ('dense', 2, 'relu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "model = configure_model(mlp_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'],debugflag=False)\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,total_epoch=500,model_name='multi_layer_perceptron',dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akars\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 4642946.0000 - val_accuracy: 0.0000e+00 - val_loss: 11125946.0000\n",
      "Epoch 2/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 6633483.5000 - val_accuracy: 0.0000e+00 - val_loss: 11127982.0000\n",
      "Epoch 3/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 10390874.0000 - val_accuracy: 0.0000e+00 - val_loss: 11128689.0000\n",
      "Epoch 4/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.0000e+00 - loss: 31648572.0000 - val_accuracy: 0.0000e+00 - val_loss: 11131402.0000\n",
      "Epoch 5/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 17011800.0000 - val_accuracy: 0.0000e+00 - val_loss: 11133478.0000\n",
      "Epoch 6/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 25452952.0000 - val_accuracy: 0.0000e+00 - val_loss: 11135413.0000\n",
      "Epoch 7/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.0000e+00 - loss: 27950498.0000 - val_accuracy: 0.0000e+00 - val_loss: 11136058.0000\n",
      "Epoch 8/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 44611968.0000 - val_accuracy: 0.0000e+00 - val_loss: 11136047.0000\n",
      "Epoch 9/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.0000e+00 - loss: 24532258.0000 - val_accuracy: 0.0000e+00 - val_loss: 11136931.0000\n",
      "Epoch 10/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.0000e+00 - loss: 5867974.5000 - val_accuracy: 0.0000e+00 - val_loss: 11137533.0000\n",
      "Epoch 11/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.0000e+00 - loss: 6065195.0000 - val_accuracy: 0.0000e+00 - val_loss: 11138694.0000\n",
      "Epoch 12/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 82430104.0000 - val_accuracy: 0.0000e+00 - val_loss: 11139167.0000\n",
      "Epoch 13/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 15980410.0000 - val_accuracy: 0.0000e+00 - val_loss: 11139171.0000\n",
      "Epoch 14/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 8159230.0000 - val_accuracy: 0.0000e+00 - val_loss: 11140342.0000\n",
      "Epoch 15/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.0000e+00 - loss: 27477888.0000 - val_accuracy: 0.0000e+00 - val_loss: 11140400.0000\n",
      "Epoch 16/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.0000e+00 - loss: 8650421.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141604.0000\n",
      "Epoch 17/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0000e+00 - loss: 40179032.0000 - val_accuracy: 0.0000e+00 - val_loss: 11140379.0000\n",
      "Epoch 18/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 0.0000e+00 - loss: 10483658.0000 - val_accuracy: 0.0000e+00 - val_loss: 11138952.0000\n",
      "Epoch 19/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 22287752.0000 - val_accuracy: 0.0000e+00 - val_loss: 11139663.0000\n",
      "Epoch 20/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.0000e+00 - loss: 27974420.0000 - val_accuracy: 0.0000e+00 - val_loss: 11139942.0000\n",
      "Epoch 21/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.0000e+00 - loss: 30012856.0000 - val_accuracy: 0.0000e+00 - val_loss: 11140085.0000\n",
      "Epoch 22/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.0000e+00 - loss: 21482634.0000 - val_accuracy: 0.0000e+00 - val_loss: 11140315.0000\n",
      "Epoch 23/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.0000e+00 - loss: 33608640.0000 - val_accuracy: 0.0000e+00 - val_loss: 11140521.0000\n",
      "Epoch 24/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 26472928.0000 - val_accuracy: 0.0000e+00 - val_loss: 11138921.0000\n",
      "Epoch 25/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - accuracy: 0.0000e+00 - loss: 33169448.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141330.0000\n",
      "Epoch 26/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 19087268.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141175.0000\n",
      "Epoch 27/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 8848300.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142040.0000\n",
      "Epoch 28/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.0000e+00 - loss: 29495758.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142303.0000\n",
      "Epoch 29/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.0000e+00 - loss: 52175304.0000 - val_accuracy: 0.0000e+00 - val_loss: 11140896.0000\n",
      "Epoch 30/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.0000e+00 - loss: 5437217.5000 - val_accuracy: 0.0000e+00 - val_loss: 11140180.0000\n",
      "Epoch 31/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 6298416.5000 - val_accuracy: 0.0000e+00 - val_loss: 11142226.0000\n",
      "Epoch 32/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 27576510.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142142.0000\n",
      "Epoch 33/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 28373262.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141441.0000\n",
      "Epoch 34/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 6485625.5000 - val_accuracy: 0.0000e+00 - val_loss: 11143139.0000\n",
      "Epoch 35/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 0.0000e+00 - loss: 18627456.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142676.0000\n",
      "Epoch 36/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.0000e+00 - loss: 6038921.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143611.0000\n",
      "Epoch 37/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.0000e+00 - loss: 8476778.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143419.0000\n",
      "Epoch 38/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.0000e+00 - loss: 38416340.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142481.0000\n",
      "Epoch 39/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.0000e+00 - loss: 12000369.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142744.0000\n",
      "Epoch 40/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 6815479.5000 - val_accuracy: 0.0000e+00 - val_loss: 11143172.0000\n",
      "Epoch 41/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 12859584.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142669.0000\n",
      "Epoch 42/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 44364520.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142151.0000\n",
      "Epoch 43/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 10056941.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142553.0000\n",
      "Epoch 44/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 26876692.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141815.0000\n",
      "Epoch 45/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.0000e+00 - loss: 3503280.5000 - val_accuracy: 0.0000e+00 - val_loss: 11140252.0000\n",
      "Epoch 46/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.0000e+00 - loss: 6730043.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142690.0000\n",
      "Epoch 47/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.0000e+00 - loss: 14273558.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142799.0000\n",
      "Epoch 48/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.0000e+00 - loss: 16058080.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142669.0000\n",
      "Epoch 49/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 45617364.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141905.0000\n",
      "Epoch 50/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 21120394.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141601.0000\n",
      "Epoch 51/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 9379591.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142254.0000\n",
      "Epoch 52/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.0000e+00 - loss: 16309489.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142255.0000\n",
      "Epoch 53/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 16521637.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142540.0000\n",
      "Epoch 54/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 12369022.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142573.0000\n",
      "Epoch 55/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 6098739.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143009.0000\n",
      "Epoch 56/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 19830764.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142672.0000\n",
      "Epoch 57/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.0000e+00 - loss: 14362820.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142695.0000\n",
      "Epoch 58/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 6277243.5000 - val_accuracy: 0.0000e+00 - val_loss: 11143114.0000\n",
      "Epoch 59/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 19920530.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142806.0000\n",
      "Epoch 60/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.0000e+00 - loss: 11951977.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142406.0000\n",
      "Epoch 61/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.0000e+00 - loss: 39446516.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142085.0000\n",
      "Epoch 62/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.0000e+00 - loss: 19745564.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142058.0000\n",
      "Epoch 63/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.0000e+00 - loss: 6591124.5000 - val_accuracy: 0.0000e+00 - val_loss: 11142726.0000\n",
      "Epoch 64/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.0000e+00 - loss: 33480332.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141888.0000\n",
      "Epoch 65/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.0000e+00 - loss: 41163784.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141074.0000\n",
      "Epoch 66/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.0000e+00 - loss: 7031170.5000 - val_accuracy: 0.0000e+00 - val_loss: 11140084.0000\n",
      "Epoch 67/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.0000e+00 - loss: 11539898.0000 - val_accuracy: 0.0000e+00 - val_loss: 11140904.0000\n",
      "Epoch 68/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 40299528.0000 - val_accuracy: 0.0000e+00 - val_loss: 11140655.0000\n",
      "Epoch 69/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.0000e+00 - loss: 7522502.5000 - val_accuracy: 0.0000e+00 - val_loss: 11142163.0000\n",
      "Epoch 70/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.0000e+00 - loss: 12436377.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142809.0000\n",
      "Epoch 71/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.0000e+00 - loss: 36202540.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141871.0000\n",
      "Epoch 72/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 12028092.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142732.0000\n",
      "Epoch 73/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.0000e+00 - loss: 29645952.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142230.0000\n",
      "Epoch 74/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.0000e+00 - loss: 27021674.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141864.0000\n",
      "Epoch 75/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.0000e+00 - loss: 11461721.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142808.0000\n",
      "Epoch 76/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 44324788.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141505.0000\n",
      "Epoch 77/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 21095860.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141792.0000\n",
      "Epoch 78/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 36891296.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141152.0000\n",
      "Epoch 79/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 23046312.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141849.0000\n",
      "Epoch 80/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.0000e+00 - loss: 11963069.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142363.0000\n",
      "Epoch 81/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.0000e+00 - loss: 11443911.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142962.0000\n",
      "Epoch 82/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.0000e+00 - loss: 65284284.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142028.0000\n",
      "Epoch 83/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.0000e+00 - loss: 31286670.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141648.0000\n",
      "Epoch 84/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 17800890.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142843.0000\n",
      "Epoch 85/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.0000e+00 - loss: 25654292.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142020.0000\n",
      "Epoch 86/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 14322459.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141996.0000\n",
      "Epoch 87/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.0000e+00 - loss: 52601312.0000 - val_accuracy: 0.0000e+00 - val_loss: 11137738.0000\n",
      "Epoch 88/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.0000e+00 - loss: 39881880.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141279.0000\n",
      "Epoch 89/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 9060857.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141912.0000\n",
      "Epoch 90/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 18635390.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142104.0000\n",
      "Epoch 91/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.0000e+00 - loss: 26244576.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142140.0000\n",
      "Epoch 92/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.0000e+00 - loss: 80660168.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141015.0000\n",
      "Epoch 93/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.0000e+00 - loss: 18800846.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142517.0000\n",
      "Epoch 94/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.0000e+00 - loss: 56873088.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141323.0000\n",
      "Epoch 95/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.0000e+00 - loss: 4205563.5000 - val_accuracy: 0.0000e+00 - val_loss: 11141854.0000\n",
      "Epoch 96/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 4506746.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144233.0000\n",
      "Epoch 97/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 45259904.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143286.0000\n",
      "Epoch 98/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.0000e+00 - loss: 28476590.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141561.0000\n",
      "Epoch 99/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.0000e+00 - loss: 5013157.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143909.0000\n",
      "Epoch 100/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.0000e+00 - loss: 7880775.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144664.0000\n",
      "Epoch 101/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0000e+00 - loss: 5739307.5000 - val_accuracy: 0.0000e+00 - val_loss: 11145022.0000\n",
      "Epoch 102/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 10478393.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145325.0000\n",
      "Epoch 103/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.0000e+00 - loss: 2392244.7500 - val_accuracy: 0.0000e+00 - val_loss: 11145341.0000\n",
      "Epoch 104/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 48151504.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142577.0000\n",
      "Epoch 105/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.0000e+00 - loss: 12259108.0000 - val_accuracy: 0.0000e+00 - val_loss: 11140227.0000\n",
      "Epoch 106/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 27516420.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141328.0000\n",
      "Epoch 107/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 28664926.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143202.0000\n",
      "Epoch 108/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.0000e+00 - loss: 21033510.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143499.0000\n",
      "Epoch 109/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.0000e+00 - loss: 4368660.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143861.0000\n",
      "Epoch 110/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.0000e+00 - loss: 8400131.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144081.0000\n",
      "Epoch 111/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 34074048.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143302.0000\n",
      "Epoch 112/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 10960563.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143761.0000\n",
      "Epoch 113/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0000e+00 - loss: 22279222.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143629.0000\n",
      "Epoch 114/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.0000e+00 - loss: 29532566.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142768.0000\n",
      "Epoch 115/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 12926396.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141491.0000\n",
      "Epoch 116/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 40314624.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143439.0000\n",
      "Epoch 117/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 32517652.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143218.0000\n",
      "Epoch 118/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.0000e+00 - loss: 11942054.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143623.0000\n",
      "Epoch 119/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 37702176.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142352.0000\n",
      "Epoch 120/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.0000e+00 - loss: 22158774.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142703.0000\n",
      "Epoch 121/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.0000e+00 - loss: 36257356.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142514.0000\n",
      "Epoch 122/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.0000e+00 - loss: 12340936.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143645.0000\n",
      "Epoch 123/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.0000e+00 - loss: 16735758.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143307.0000\n",
      "Epoch 124/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.0000e+00 - loss: 15260472.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143666.0000\n",
      "Epoch 125/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.0000e+00 - loss: 13359229.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143613.0000\n",
      "Epoch 126/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.0000e+00 - loss: 23359434.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142499.0000\n",
      "Epoch 127/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 12552745.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143418.0000\n",
      "Epoch 128/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.0000e+00 - loss: 33686412.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142749.0000\n",
      "Epoch 129/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.0000e+00 - loss: 19430590.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142890.0000\n",
      "Epoch 130/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 7084169.5000 - val_accuracy: 0.0000e+00 - val_loss: 11143653.0000\n",
      "Epoch 131/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.0000e+00 - loss: 11527895.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143942.0000\n",
      "Epoch 132/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 61636012.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142863.0000\n",
      "Epoch 133/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 19254040.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144029.0000\n",
      "Epoch 134/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 59445880.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143128.0000\n",
      "Epoch 135/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.0000e+00 - loss: 4720329.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144009.0000\n",
      "Epoch 136/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.0000e+00 - loss: 14644263.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144622.0000\n",
      "Epoch 137/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.0000e+00 - loss: 12379188.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144147.0000\n",
      "Epoch 138/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 9790631.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143738.0000\n",
      "Epoch 139/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.0000e+00 - loss: 46957700.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143107.0000\n",
      "Epoch 140/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 8132066.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144319.0000\n",
      "Epoch 141/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.0000e+00 - loss: 45508424.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143691.0000\n",
      "Epoch 142/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.0000e+00 - loss: 33262332.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144308.0000\n",
      "Epoch 143/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.0000e+00 - loss: 17404598.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143305.0000\n",
      "Epoch 144/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.0000e+00 - loss: 10722611.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144181.0000\n",
      "Epoch 145/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 36519192.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142719.0000\n",
      "Epoch 146/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.0000e+00 - loss: 24570678.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142942.0000\n",
      "Epoch 147/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0000e+00 - loss: 61973976.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141102.0000\n",
      "Epoch 148/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.0000e+00 - loss: 10725234.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141778.0000\n",
      "Epoch 149/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.0000e+00 - loss: 16303107.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142420.0000\n",
      "Epoch 150/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.0000e+00 - loss: 19346994.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142412.0000\n",
      "Epoch 151/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.0000e+00 - loss: 24798466.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142925.0000\n",
      "Epoch 152/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.0000e+00 - loss: 25788378.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143010.0000\n",
      "Epoch 153/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.0000e+00 - loss: 71631048.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141970.0000\n",
      "Epoch 154/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.0000e+00 - loss: 30486356.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141885.0000\n",
      "Epoch 155/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.0000e+00 - loss: 14728906.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143937.0000\n",
      "Epoch 156/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.0000e+00 - loss: 24724032.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142671.0000\n",
      "Epoch 157/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.0000e+00 - loss: 34128740.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142153.0000\n",
      "Epoch 158/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.0000e+00 - loss: 22378954.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143079.0000\n",
      "Epoch 159/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.0000e+00 - loss: 12639051.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143116.0000\n",
      "Epoch 160/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 6310139.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143831.0000\n",
      "Epoch 161/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.0000e+00 - loss: 28053946.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143525.0000\n",
      "Epoch 162/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.0000e+00 - loss: 14229549.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144147.0000\n",
      "Epoch 163/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.0000e+00 - loss: 6588447.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144806.0000\n",
      "Epoch 164/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 5105250.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145659.0000\n",
      "Epoch 165/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.0000e+00 - loss: 25620644.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144186.0000\n",
      "Epoch 166/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 22698420.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144329.0000\n",
      "Epoch 167/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 34012452.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144508.0000\n",
      "Epoch 168/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 8915746.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143874.0000\n",
      "Epoch 169/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.0000e+00 - loss: 7317536.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145202.0000\n",
      "Epoch 170/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.0000e+00 - loss: 28964616.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144915.0000\n",
      "Epoch 171/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.0000e+00 - loss: 7107863.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144813.0000\n",
      "Epoch 172/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 0.0000e+00 - loss: 17046658.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144630.0000\n",
      "Epoch 173/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 9627786.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145712.0000\n",
      "Epoch 174/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.0000e+00 - loss: 11805791.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143686.0000\n",
      "Epoch 175/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.0000e+00 - loss: 19543300.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145270.0000\n",
      "Epoch 176/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.0000e+00 - loss: 10158942.0000 - val_accuracy: 0.0000e+00 - val_loss: 11139619.0000\n",
      "Epoch 177/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.0000e+00 - loss: 19315466.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145931.0000\n",
      "Epoch 178/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.0000e+00 - loss: 36767916.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145430.0000\n",
      "Epoch 179/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.0000e+00 - loss: 30847776.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145742.0000\n",
      "Epoch 180/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.0000e+00 - loss: 48221960.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145412.0000\n",
      "Epoch 181/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.0000e+00 - loss: 22309754.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145828.0000\n",
      "Epoch 182/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 23956548.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145780.0000\n",
      "Epoch 183/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 8264040.5000 - val_accuracy: 0.0000e+00 - val_loss: 11145752.0000\n",
      "Epoch 184/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.0000e+00 - loss: 4751527.5000 - val_accuracy: 0.0000e+00 - val_loss: 11147246.0000\n",
      "Epoch 185/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.0000e+00 - loss: 5709628.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146720.0000\n",
      "Epoch 186/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 15115466.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146666.0000\n",
      "Epoch 187/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 24922924.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145845.0000\n",
      "Epoch 188/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.0000e+00 - loss: 3223321.5000 - val_accuracy: 0.0000e+00 - val_loss: 11148198.0000\n",
      "Epoch 189/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.0000e+00 - loss: 7525966.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148130.0000\n",
      "Epoch 190/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 8348710.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146503.0000\n",
      "Epoch 191/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 27867384.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147458.0000\n",
      "Epoch 192/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 34489996.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146477.0000\n",
      "Epoch 193/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.0000e+00 - loss: 12771403.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147383.0000\n",
      "Epoch 194/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.0000e+00 - loss: 42519620.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145962.0000\n",
      "Epoch 195/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0000e+00 - loss: 14202989.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146830.0000\n",
      "Epoch 196/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.0000e+00 - loss: 2921398.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147379.0000\n",
      "Epoch 197/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.0000e+00 - loss: 4329299.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148521.0000\n",
      "Epoch 198/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 8288722.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143156.0000\n",
      "Epoch 199/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0000e+00 - loss: 10389796.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150306.0000\n",
      "Epoch 200/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.0000e+00 - loss: 10983239.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148203.0000\n",
      "Epoch 201/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.0000e+00 - loss: 18564354.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148831.0000\n",
      "Epoch 202/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.0000e+00 - loss: 9080909.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150239.0000\n",
      "Epoch 203/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.0000e+00 - loss: 4091026.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150575.0000\n",
      "Epoch 204/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.0000e+00 - loss: 19134180.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147096.0000\n",
      "Epoch 205/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 34306412.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147611.0000\n",
      "Epoch 206/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 9864103.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147502.0000\n",
      "Epoch 207/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 0.0000e+00 - loss: 36283012.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146591.0000\n",
      "Epoch 208/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.0000e+00 - loss: 49215680.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147571.0000\n",
      "Epoch 209/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 4760718.5000 - val_accuracy: 0.0000e+00 - val_loss: 11149831.0000\n",
      "Epoch 210/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.0000e+00 - loss: 102900160.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148214.0000\n",
      "Epoch 211/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 7624830.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148344.0000\n",
      "Epoch 212/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 16004214.0000 - val_accuracy: 0.0000e+00 - val_loss: 11139756.0000\n",
      "Epoch 213/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 25300188.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148554.0000\n",
      "Epoch 214/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 32741164.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146541.0000\n",
      "Epoch 215/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.0000e+00 - loss: 24356772.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149141.0000\n",
      "Epoch 216/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.0000e+00 - loss: 6824957.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148526.0000\n",
      "Epoch 217/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 2804791.5000 - val_accuracy: 0.0000e+00 - val_loss: 11146991.0000\n",
      "Epoch 218/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 25145752.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149596.0000\n",
      "Epoch 219/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.0000e+00 - loss: 71005392.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146439.0000\n",
      "Epoch 220/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 4346487.5000 - val_accuracy: 0.0000e+00 - val_loss: 11149785.0000\n",
      "Epoch 221/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 54855612.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147125.0000\n",
      "Epoch 222/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.0000e+00 - loss: 48566764.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146830.0000\n",
      "Epoch 223/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 29390562.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149503.0000\n",
      "Epoch 224/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.0000e+00 - loss: 21163494.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148358.0000\n",
      "Epoch 225/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.0000e+00 - loss: 21664826.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149053.0000\n",
      "Epoch 226/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.0000e+00 - loss: 23238872.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146926.0000\n",
      "Epoch 227/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.0000e+00 - loss: 16364087.0000 - val_accuracy: 0.0000e+00 - val_loss: 11132540.0000\n",
      "Epoch 228/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.0000e+00 - loss: 25595502.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149674.0000\n",
      "Epoch 229/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.0000e+00 - loss: 7732854.5000 - val_accuracy: 0.0000e+00 - val_loss: 11149523.0000\n",
      "Epoch 230/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.0000e+00 - loss: 4672408.5000 - val_accuracy: 0.0000e+00 - val_loss: 11144695.0000\n",
      "Epoch 231/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 15422090.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150512.0000\n",
      "Epoch 232/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.0000e+00 - loss: 14372691.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150682.0000\n",
      "Epoch 233/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 5992014.5000 - val_accuracy: 0.0000e+00 - val_loss: 11148494.0000\n",
      "Epoch 234/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 6993324.5000 - val_accuracy: 0.0000e+00 - val_loss: 11152090.0000\n",
      "Epoch 235/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.0000e+00 - loss: 14670099.0000 - val_accuracy: 0.0000e+00 - val_loss: 11152230.0000\n",
      "Epoch 236/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.0000e+00 - loss: 12399335.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150948.0000\n",
      "Epoch 237/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 11041956.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146199.0000\n",
      "Epoch 238/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 0.0000e+00 - loss: 47604148.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147673.0000\n",
      "Epoch 239/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.0000e+00 - loss: 32482132.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146371.0000\n",
      "Epoch 240/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.0000e+00 - loss: 66083144.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144068.0000\n",
      "Epoch 241/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.0000e+00 - loss: 14259746.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149263.0000\n",
      "Epoch 242/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.0000e+00 - loss: 42356912.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144438.0000\n",
      "Epoch 243/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 15388328.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151076.0000\n",
      "Epoch 244/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 44123960.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146049.0000\n",
      "Epoch 245/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.0000e+00 - loss: 43940676.0000 - val_accuracy: 0.0000e+00 - val_loss: 11141989.0000\n",
      "Epoch 246/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.0000e+00 - loss: 18355120.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143757.0000\n",
      "Epoch 247/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 27746776.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146745.0000\n",
      "Epoch 248/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 26374004.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145387.0000\n",
      "Epoch 249/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 28863776.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151010.0000\n",
      "Epoch 250/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 11389663.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143747.0000\n",
      "Epoch 251/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.0000e+00 - loss: 65959756.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145967.0000\n",
      "Epoch 252/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.0000e+00 - loss: 5449438.5000 - val_accuracy: 0.0000e+00 - val_loss: 11151519.0000\n",
      "Epoch 253/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 15422887.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151611.0000\n",
      "Epoch 254/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.0000e+00 - loss: 11750371.0000 - val_accuracy: 0.0000e+00 - val_loss: 11152885.0000\n",
      "Epoch 255/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 3336850.2500 - val_accuracy: 0.0000e+00 - val_loss: 11154204.0000\n",
      "Epoch 256/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 0.0000e+00 - loss: 44205464.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148155.0000\n",
      "Epoch 257/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 26067456.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148064.0000\n",
      "Epoch 258/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.0000e+00 - loss: 6113076.5000 - val_accuracy: 0.0000e+00 - val_loss: 11144354.0000\n",
      "Epoch 259/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.0000e+00 - loss: 60999348.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147928.0000\n",
      "Epoch 260/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.0000e+00 - loss: 2410685.7500 - val_accuracy: 0.0000e+00 - val_loss: 11153113.0000\n",
      "Epoch 261/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.0000e+00 - loss: 22004270.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150143.0000\n",
      "Epoch 262/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - accuracy: 0.0000e+00 - loss: 61183860.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147545.0000\n",
      "Epoch 263/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 57923660.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146059.0000\n",
      "Epoch 264/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 24823174.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143950.0000\n",
      "Epoch 265/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.0000e+00 - loss: 2337707.7500 - val_accuracy: 0.0000e+00 - val_loss: 11151694.0000\n",
      "Epoch 266/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 2920461.5000 - val_accuracy: 0.0000e+00 - val_loss: 11155411.0000\n",
      "Epoch 267/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.0000e+00 - loss: 6577097.0000 - val_accuracy: 0.0000e+00 - val_loss: 11156822.0000\n",
      "Epoch 268/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.0000e+00 - loss: 11460859.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155828.0000\n",
      "Epoch 269/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.0000e+00 - loss: 10425048.0000 - val_accuracy: 0.0000e+00 - val_loss: 11152953.0000\n",
      "Epoch 270/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.0000e+00 - loss: 67999144.0000 - val_accuracy: 0.0000e+00 - val_loss: 11152721.0000\n",
      "Epoch 271/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 18481306.0000 - val_accuracy: 0.0000e+00 - val_loss: 11153609.0000\n",
      "Epoch 272/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.0000e+00 - loss: 12005835.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150503.0000\n",
      "Epoch 273/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 35469664.0000 - val_accuracy: 0.0000e+00 - val_loss: 11152686.0000\n",
      "Epoch 274/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 13447287.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148890.0000\n",
      "Epoch 275/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.0000e+00 - loss: 4556964.0000 - val_accuracy: 0.0000e+00 - val_loss: 11152546.0000\n",
      "Epoch 276/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 2805549.2500 - val_accuracy: 0.0000e+00 - val_loss: 11159446.0000\n",
      "Epoch 277/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.0000e+00 - loss: 7912790.5000 - val_accuracy: 0.0000e+00 - val_loss: 11159185.0000\n",
      "Epoch 278/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.0000e+00 - loss: 32242804.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150520.0000\n",
      "Epoch 279/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 12827457.0000 - val_accuracy: 0.0000e+00 - val_loss: 11156218.0000\n",
      "Epoch 280/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 18160114.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155258.0000\n",
      "Epoch 281/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - accuracy: 0.0000e+00 - loss: 34007936.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148721.0000\n",
      "Epoch 282/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 6123337.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155566.0000\n",
      "Epoch 283/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 9000134.0000 - val_accuracy: 0.0000e+00 - val_loss: 11153313.0000\n",
      "Epoch 284/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 6643521.5000 - val_accuracy: 0.0000e+00 - val_loss: 11158831.0000\n",
      "Epoch 285/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.0000e+00 - loss: 12123109.0000 - val_accuracy: 0.0000e+00 - val_loss: 11156902.0000\n",
      "Epoch 286/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 38587152.0000 - val_accuracy: 0.0000e+00 - val_loss: 11152760.0000\n",
      "Epoch 287/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 17069110.0000 - val_accuracy: 0.0000e+00 - val_loss: 11156497.0000\n",
      "Epoch 288/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.0000e+00 - loss: 26010008.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145060.0000\n",
      "Epoch 289/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.0000e+00 - loss: 19567768.0000 - val_accuracy: 0.0000e+00 - val_loss: 11145395.0000\n",
      "Epoch 290/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.0000e+00 - loss: 3786628.2500 - val_accuracy: 0.0000e+00 - val_loss: 11149884.0000\n",
      "Epoch 291/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 21809122.0000 - val_accuracy: 0.0000e+00 - val_loss: 11153618.0000\n",
      "Epoch 292/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 69174808.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148170.0000\n",
      "Epoch 293/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.0000e+00 - loss: 15971364.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155333.0000\n",
      "Epoch 294/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.0000e+00 - loss: 27419354.0000 - val_accuracy: 0.0000e+00 - val_loss: 11152036.0000\n",
      "Epoch 295/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.0000e+00 - loss: 16203963.0000 - val_accuracy: 0.0000e+00 - val_loss: 11157669.0000\n",
      "Epoch 296/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.0000e+00 - loss: 44844440.0000 - val_accuracy: 0.0000e+00 - val_loss: 11154442.0000\n",
      "Epoch 297/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.0000e+00 - loss: 72078824.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143874.0000\n",
      "Epoch 298/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.0000e+00 - loss: 18761160.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158393.0000\n",
      "Epoch 299/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.0000e+00 - loss: 20582398.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155440.0000\n",
      "Epoch 300/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.0000e+00 - loss: 9355742.0000 - val_accuracy: 0.0000e+00 - val_loss: 11143067.0000\n",
      "Epoch 301/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.0000e+00 - loss: 13843245.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151515.0000\n",
      "Epoch 302/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.0000e+00 - loss: 12955231.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151814.0000\n",
      "Epoch 303/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.0000e+00 - loss: 11627998.0000 - val_accuracy: 0.0000e+00 - val_loss: 11156324.0000\n",
      "Epoch 304/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 6898827.5000 - val_accuracy: 0.0000e+00 - val_loss: 11156425.0000\n",
      "Epoch 305/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.0000e+00 - loss: 34540976.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146450.0000\n",
      "Epoch 306/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.0000e+00 - loss: 9840559.0000 - val_accuracy: 0.0000e+00 - val_loss: 11154497.0000\n",
      "Epoch 307/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 4114759.7500 - val_accuracy: 0.0000e+00 - val_loss: 11146089.0000\n",
      "Epoch 308/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.0000e+00 - loss: 40971548.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150942.0000\n",
      "Epoch 309/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.0000e+00 - loss: 8165846.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155461.0000\n",
      "Epoch 310/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.0000e+00 - loss: 11755891.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149640.0000\n",
      "Epoch 311/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 28307270.0000 - val_accuracy: 0.0000e+00 - val_loss: 11160125.0000\n",
      "Epoch 312/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.0000e+00 - loss: 11508327.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161927.0000\n",
      "Epoch 313/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 32416184.0000 - val_accuracy: 0.0000e+00 - val_loss: 11154451.0000\n",
      "Epoch 314/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.0000e+00 - loss: 19421626.0000 - val_accuracy: 0.0000e+00 - val_loss: 11152553.0000\n",
      "Epoch 315/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 24048590.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158706.0000\n",
      "Epoch 316/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 34267120.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142128.0000\n",
      "Epoch 317/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.0000e+00 - loss: 38598784.0000 - val_accuracy: 0.0000e+00 - val_loss: 11154055.0000\n",
      "Epoch 318/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 11276136.0000 - val_accuracy: 0.0000e+00 - val_loss: 11154002.0000\n",
      "Epoch 319/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 55420408.0000 - val_accuracy: 0.0000e+00 - val_loss: 11157185.0000\n",
      "Epoch 320/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.0000e+00 - loss: 8019054.5000 - val_accuracy: 0.0000e+00 - val_loss: 11154579.0000\n",
      "Epoch 321/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0000e+00 - loss: 5267181.5000 - val_accuracy: 0.0000e+00 - val_loss: 11156597.0000\n",
      "Epoch 322/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0000e+00 - loss: 25271228.0000 - val_accuracy: 0.0000e+00 - val_loss: 11153522.0000\n",
      "Epoch 323/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.0000e+00 - loss: 49192204.0000 - val_accuracy: 0.0000e+00 - val_loss: 11152143.0000\n",
      "Epoch 324/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 25393002.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149229.0000\n",
      "Epoch 325/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0000e+00 - loss: 4713653.0000 - val_accuracy: 0.0000e+00 - val_loss: 11160076.0000\n",
      "Epoch 326/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.0000e+00 - loss: 8070163.5000 - val_accuracy: 0.0000e+00 - val_loss: 11161568.0000\n",
      "Epoch 327/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.0000e+00 - loss: 18575198.0000 - val_accuracy: 0.0000e+00 - val_loss: 11160945.0000\n",
      "Epoch 328/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0000e+00 - loss: 9829355.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158766.0000\n",
      "Epoch 329/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.0000e+00 - loss: 19953496.0000 - val_accuracy: 0.0000e+00 - val_loss: 11154534.0000\n",
      "Epoch 330/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.0000e+00 - loss: 52467036.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147137.0000\n",
      "Epoch 331/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.0000e+00 - loss: 31210824.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161123.0000\n",
      "Epoch 332/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.0000e+00 - loss: 9442656.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155799.0000\n",
      "Epoch 333/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 12018186.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151423.0000\n",
      "Epoch 334/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.0000e+00 - loss: 63471144.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146306.0000\n",
      "Epoch 335/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.0000e+00 - loss: 46421544.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151410.0000\n",
      "Epoch 336/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 4693237.5000 - val_accuracy: 0.0000e+00 - val_loss: 11162711.0000\n",
      "Epoch 337/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 9206746.0000 - val_accuracy: 0.0000e+00 - val_loss: 11168678.0000\n",
      "Epoch 338/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.0000e+00 - loss: 29369938.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158639.0000\n",
      "Epoch 339/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.0000e+00 - loss: 71974184.0000 - val_accuracy: 0.0000e+00 - val_loss: 11153417.0000\n",
      "Epoch 340/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 12393517.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150832.0000\n",
      "Epoch 341/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 13115170.0000 - val_accuracy: 0.0000e+00 - val_loss: 11163656.0000\n",
      "Epoch 342/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 19697676.0000 - val_accuracy: 0.0000e+00 - val_loss: 11146441.0000\n",
      "Epoch 343/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.0000e+00 - loss: 37886176.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147579.0000\n",
      "Epoch 344/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.0000e+00 - loss: 10096121.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158896.0000\n",
      "Epoch 345/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.0000e+00 - loss: 25248298.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148800.0000\n",
      "Epoch 346/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.0000e+00 - loss: 5913056.5000 - val_accuracy: 0.0000e+00 - val_loss: 11169048.0000\n",
      "Epoch 347/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0000e+00 - loss: 22679382.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158305.0000\n",
      "Epoch 348/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 4905691.0000 - val_accuracy: 0.0000e+00 - val_loss: 11168203.0000\n",
      "Epoch 349/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.0000e+00 - loss: 43198968.0000 - val_accuracy: 0.0000e+00 - val_loss: 11163430.0000\n",
      "Epoch 350/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 7255613.5000 - val_accuracy: 0.0000e+00 - val_loss: 11166332.0000\n",
      "Epoch 351/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.0000e+00 - loss: 25077426.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150233.0000\n",
      "Epoch 352/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 104538496.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158887.0000\n",
      "Epoch 353/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0000e+00 - loss: 42229668.0000 - val_accuracy: 0.0000e+00 - val_loss: 11144366.0000\n",
      "Epoch 354/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.0000e+00 - loss: 10756049.0000 - val_accuracy: 0.0000e+00 - val_loss: 11167188.0000\n",
      "Epoch 355/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 27392298.0000 - val_accuracy: 0.0000e+00 - val_loss: 11157376.0000\n",
      "Epoch 356/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 42593816.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150913.0000\n",
      "Epoch 357/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.0000e+00 - loss: 11181848.0000 - val_accuracy: 0.0000e+00 - val_loss: 11164458.0000\n",
      "Epoch 358/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 31337920.0000 - val_accuracy: 0.0000e+00 - val_loss: 11153227.0000\n",
      "Epoch 359/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 4685327.5000 - val_accuracy: 0.0000e+00 - val_loss: 11162141.0000\n",
      "Epoch 360/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 82451720.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151580.0000\n",
      "Epoch 361/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 17823900.0000 - val_accuracy: 0.0000e+00 - val_loss: 11165848.0000\n",
      "Epoch 362/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.0000e+00 - loss: 15668436.0000 - val_accuracy: 0.0000e+00 - val_loss: 11159801.0000\n",
      "Epoch 363/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.0000e+00 - loss: 11678382.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161571.0000\n",
      "Epoch 364/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.0000e+00 - loss: 43015552.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161542.0000\n",
      "Epoch 365/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.0000e+00 - loss: 14565269.0000 - val_accuracy: 0.0000e+00 - val_loss: 11159372.0000\n",
      "Epoch 366/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 10372387.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161407.0000\n",
      "Epoch 367/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.0000e+00 - loss: 12034452.0000 - val_accuracy: 0.0000e+00 - val_loss: 11164647.0000\n",
      "Epoch 368/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.0000e+00 - loss: 20909814.0000 - val_accuracy: 0.0000e+00 - val_loss: 11160423.0000\n",
      "Epoch 369/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 10650063.0000 - val_accuracy: 0.0000e+00 - val_loss: 11165086.0000\n",
      "Epoch 370/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.0000e+00 - loss: 33253656.0000 - val_accuracy: 0.0000e+00 - val_loss: 11153677.0000\n",
      "Epoch 371/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.0000e+00 - loss: 9843871.0000 - val_accuracy: 0.0000e+00 - val_loss: 11170425.0000\n",
      "Epoch 372/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.0000e+00 - loss: 68503432.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151054.0000\n",
      "Epoch 373/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.0000e+00 - loss: 8614270.0000 - val_accuracy: 0.0000e+00 - val_loss: 11170526.0000\n",
      "Epoch 374/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.0000e+00 - loss: 35140328.0000 - val_accuracy: 0.0000e+00 - val_loss: 11153379.0000\n",
      "Epoch 375/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.0000e+00 - loss: 32258160.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149518.0000\n",
      "Epoch 376/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.0000e+00 - loss: 21376832.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161093.0000\n",
      "Epoch 377/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.0000e+00 - loss: 23594038.0000 - val_accuracy: 0.0000e+00 - val_loss: 11163484.0000\n",
      "Epoch 378/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.0000e+00 - loss: 6384923.0000 - val_accuracy: 0.0000e+00 - val_loss: 11147860.0000\n",
      "Epoch 379/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.0000e+00 - loss: 70133120.0000 - val_accuracy: 0.0000e+00 - val_loss: 11169632.0000\n",
      "Epoch 380/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 19597992.0000 - val_accuracy: 0.0000e+00 - val_loss: 11154843.0000\n",
      "Epoch 381/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.0000e+00 - loss: 2484904.7500 - val_accuracy: 0.0000e+00 - val_loss: 11164250.0000\n",
      "Epoch 382/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.0000e+00 - loss: 15325210.0000 - val_accuracy: 0.0000e+00 - val_loss: 11163885.0000\n",
      "Epoch 383/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.0000e+00 - loss: 25281750.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150409.0000\n",
      "Epoch 384/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.0000e+00 - loss: 18899108.0000 - val_accuracy: 0.0000e+00 - val_loss: 11142349.0000\n",
      "Epoch 385/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 5815856.0000 - val_accuracy: 0.0000e+00 - val_loss: 11175912.0000\n",
      "Epoch 386/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 23697280.0000 - val_accuracy: 0.0000e+00 - val_loss: 11174961.0000\n",
      "Epoch 387/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 9886490.0000 - val_accuracy: 0.0000e+00 - val_loss: 11166252.0000\n",
      "Epoch 388/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.0000e+00 - loss: 8982356.0000 - val_accuracy: 0.0000e+00 - val_loss: 11166882.0000\n",
      "Epoch 389/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.0000e+00 - loss: 23937040.0000 - val_accuracy: 0.0000e+00 - val_loss: 11167201.0000\n",
      "Epoch 390/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.0000e+00 - loss: 8510415.0000 - val_accuracy: 0.0000e+00 - val_loss: 11177310.0000\n",
      "Epoch 391/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.0000e+00 - loss: 18438146.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149904.0000\n",
      "Epoch 392/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.0000e+00 - loss: 83581960.0000 - val_accuracy: 0.0000e+00 - val_loss: 11159480.0000\n",
      "Epoch 393/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 34892388.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161410.0000\n",
      "Epoch 394/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.0000e+00 - loss: 12266953.0000 - val_accuracy: 0.0000e+00 - val_loss: 11163572.0000\n",
      "Epoch 395/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.0000e+00 - loss: 54056076.0000 - val_accuracy: 0.0000e+00 - val_loss: 11165745.0000\n",
      "Epoch 396/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 22194272.0000 - val_accuracy: 0.0000e+00 - val_loss: 11162112.0000\n",
      "Epoch 397/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.0000e+00 - loss: 18758066.0000 - val_accuracy: 0.0000e+00 - val_loss: 11168124.0000\n",
      "Epoch 398/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.0000e+00 - loss: 6595426.5000 - val_accuracy: 0.0000e+00 - val_loss: 11171202.0000\n",
      "Epoch 399/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 21922648.0000 - val_accuracy: 0.0000e+00 - val_loss: 11168158.0000\n",
      "Epoch 400/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - accuracy: 0.0000e+00 - loss: 44043340.0000 - val_accuracy: 0.0000e+00 - val_loss: 11150895.0000\n",
      "Epoch 401/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 19318728.0000 - val_accuracy: 0.0000e+00 - val_loss: 11173265.0000\n",
      "Epoch 402/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 17199930.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161692.0000\n",
      "Epoch 403/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.0000e+00 - loss: 73890832.0000 - val_accuracy: 0.0000e+00 - val_loss: 11156026.0000\n",
      "Epoch 404/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 12198471.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161736.0000\n",
      "Epoch 405/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.0000e+00 - loss: 27909630.0000 - val_accuracy: 0.0000e+00 - val_loss: 11166527.0000\n",
      "Epoch 406/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.0000e+00 - loss: 48309048.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148237.0000\n",
      "Epoch 407/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.0000e+00 - loss: 40194880.0000 - val_accuracy: 0.0000e+00 - val_loss: 11154566.0000\n",
      "Epoch 408/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 0.0000e+00 - loss: 69667144.0000 - val_accuracy: 0.0000e+00 - val_loss: 11154310.0000\n",
      "Epoch 409/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.0000e+00 - loss: 34145840.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161477.0000\n",
      "Epoch 410/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.0000e+00 - loss: 23744018.0000 - val_accuracy: 0.0000e+00 - val_loss: 11163408.0000\n",
      "Epoch 411/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 67849288.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155900.0000\n",
      "Epoch 412/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.0000e+00 - loss: 38335852.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161455.0000\n",
      "Epoch 413/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.0000e+00 - loss: 9118081.0000 - val_accuracy: 0.0000e+00 - val_loss: 11164587.0000\n",
      "Epoch 414/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.0000e+00 - loss: 12861124.0000 - val_accuracy: 0.0000e+00 - val_loss: 11169724.0000\n",
      "Epoch 415/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 69762888.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155149.0000\n",
      "Epoch 416/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.0000e+00 - loss: 13468802.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158082.0000\n",
      "Epoch 417/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0000e+00 - loss: 14433165.0000 - val_accuracy: 0.0000e+00 - val_loss: 11170150.0000\n",
      "Epoch 418/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.0000e+00 - loss: 25151438.0000 - val_accuracy: 0.0000e+00 - val_loss: 11174791.0000\n",
      "Epoch 419/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1000us/step - accuracy: 0.0000e+00 - loss: 22686992.0000 - val_accuracy: 0.0000e+00 - val_loss: 11163913.0000\n",
      "Epoch 420/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.0000e+00 - loss: 21146108.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161269.0000\n",
      "Epoch 421/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 0.0000e+00 - loss: 15298388.0000 - val_accuracy: 0.0000e+00 - val_loss: 11174292.0000\n",
      "Epoch 422/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.0000e+00 - loss: 22339328.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151832.0000\n",
      "Epoch 423/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.0000e+00 - loss: 26703926.0000 - val_accuracy: 0.0000e+00 - val_loss: 11171820.0000\n",
      "Epoch 424/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.0000e+00 - loss: 49825992.0000 - val_accuracy: 0.0000e+00 - val_loss: 11170257.0000\n",
      "Epoch 425/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 64155156.0000 - val_accuracy: 0.0000e+00 - val_loss: 11159167.0000\n",
      "Epoch 426/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 0.0000e+00 - loss: 37608812.0000 - val_accuracy: 0.0000e+00 - val_loss: 11149210.0000\n",
      "Epoch 427/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 29299358.0000 - val_accuracy: 0.0000e+00 - val_loss: 11165701.0000\n",
      "Epoch 428/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.0000e+00 - loss: 37004528.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148228.0000\n",
      "Epoch 429/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 26417210.0000 - val_accuracy: 0.0000e+00 - val_loss: 11175646.0000\n",
      "Epoch 430/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 12772063.0000 - val_accuracy: 0.0000e+00 - val_loss: 11164874.0000\n",
      "Epoch 431/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 6990152.0000 - val_accuracy: 0.0000e+00 - val_loss: 11162692.0000\n",
      "Epoch 432/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0000e+00 - loss: 35494880.0000 - val_accuracy: 0.0000e+00 - val_loss: 11174065.0000\n",
      "Epoch 433/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.0000e+00 - loss: 24025362.0000 - val_accuracy: 0.0000e+00 - val_loss: 11170542.0000\n",
      "Epoch 434/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.0000e+00 - loss: 8691886.0000 - val_accuracy: 0.0000e+00 - val_loss: 11174274.0000\n",
      "Epoch 435/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 0.0000e+00 - loss: 3133153.7500 - val_accuracy: 0.0000e+00 - val_loss: 11174822.0000\n",
      "Epoch 436/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 8862301.0000 - val_accuracy: 0.0000e+00 - val_loss: 11160822.0000\n",
      "Epoch 437/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 24933388.0000 - val_accuracy: 0.0000e+00 - val_loss: 11181202.0000\n",
      "Epoch 438/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.0000e+00 - loss: 27862454.0000 - val_accuracy: 0.0000e+00 - val_loss: 11174149.0000\n",
      "Epoch 439/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.0000e+00 - loss: 79644296.0000 - val_accuracy: 0.0000e+00 - val_loss: 11165096.0000\n",
      "Epoch 440/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - accuracy: 0.0000e+00 - loss: 6983477.5000 - val_accuracy: 0.0000e+00 - val_loss: 11155244.0000\n",
      "Epoch 441/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.0000e+00 - loss: 24743188.0000 - val_accuracy: 0.0000e+00 - val_loss: 11163514.0000\n",
      "Epoch 442/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 0.0000e+00 - loss: 18137470.0000 - val_accuracy: 0.0000e+00 - val_loss: 11166151.0000\n",
      "Epoch 443/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.0000e+00 - loss: 5298946.0000 - val_accuracy: 0.0000e+00 - val_loss: 11171132.0000\n",
      "Epoch 444/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.0000e+00 - loss: 11156975.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155571.0000\n",
      "Epoch 445/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.0000e+00 - loss: 13543427.0000 - val_accuracy: 0.0000e+00 - val_loss: 11179174.0000\n",
      "Epoch 446/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.0000e+00 - loss: 49278768.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158818.0000\n",
      "Epoch 447/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 10550735.0000 - val_accuracy: 0.0000e+00 - val_loss: 11163278.0000\n",
      "Epoch 448/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 29317466.0000 - val_accuracy: 0.0000e+00 - val_loss: 11175795.0000\n",
      "Epoch 449/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 0.0000e+00 - loss: 25957840.0000 - val_accuracy: 0.0000e+00 - val_loss: 11169435.0000\n",
      "Epoch 450/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.0000e+00 - loss: 50612420.0000 - val_accuracy: 0.0000e+00 - val_loss: 11156068.0000\n",
      "Epoch 451/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 20477566.0000 - val_accuracy: 0.0000e+00 - val_loss: 11172918.0000\n",
      "Epoch 452/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.0000e+00 - loss: 13864886.0000 - val_accuracy: 0.0000e+00 - val_loss: 11176347.0000\n",
      "Epoch 453/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.0000e+00 - loss: 9833853.0000 - val_accuracy: 0.0000e+00 - val_loss: 11172488.0000\n",
      "Epoch 454/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 42098004.0000 - val_accuracy: 0.0000e+00 - val_loss: 11170386.0000\n",
      "Epoch 455/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 36712492.0000 - val_accuracy: 0.0000e+00 - val_loss: 11154275.0000\n",
      "Epoch 456/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 0.0000e+00 - loss: 4607236.5000 - val_accuracy: 0.0000e+00 - val_loss: 11181433.0000\n",
      "Epoch 457/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.0000e+00 - loss: 24587018.0000 - val_accuracy: 0.0000e+00 - val_loss: 11151816.0000\n",
      "Epoch 458/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - accuracy: 0.0000e+00 - loss: 8878250.0000 - val_accuracy: 0.0000e+00 - val_loss: 11184424.0000\n",
      "Epoch 459/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 23251802.0000 - val_accuracy: 0.0000e+00 - val_loss: 11170558.0000\n",
      "Epoch 460/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.0000e+00 - loss: 23459164.0000 - val_accuracy: 0.0000e+00 - val_loss: 11165702.0000\n",
      "Epoch 461/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 0.0000e+00 - loss: 40764080.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161084.0000\n",
      "Epoch 462/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.0000e+00 - loss: 38176792.0000 - val_accuracy: 0.0000e+00 - val_loss: 11171402.0000\n",
      "Epoch 463/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.0000e+00 - loss: 9439041.0000 - val_accuracy: 0.0000e+00 - val_loss: 11172100.0000\n",
      "Epoch 464/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.0000e+00 - loss: 26332214.0000 - val_accuracy: 0.0000e+00 - val_loss: 11168101.0000\n",
      "Epoch 465/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.0000e+00 - loss: 24931742.0000 - val_accuracy: 0.0000e+00 - val_loss: 11172893.0000\n",
      "Epoch 466/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.0000e+00 - loss: 21548546.0000 - val_accuracy: 0.0000e+00 - val_loss: 11166093.0000\n",
      "Epoch 467/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 17182406.0000 - val_accuracy: 0.0000e+00 - val_loss: 11172930.0000\n",
      "Epoch 468/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.0000e+00 - loss: 31737856.0000 - val_accuracy: 0.0000e+00 - val_loss: 11165501.0000\n",
      "Epoch 469/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.0000e+00 - loss: 25696624.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158182.0000\n",
      "Epoch 470/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.0000e+00 - loss: 36157400.0000 - val_accuracy: 0.0000e+00 - val_loss: 11172291.0000\n",
      "Epoch 471/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.0000e+00 - loss: 81471424.0000 - val_accuracy: 0.0000e+00 - val_loss: 11155296.0000\n",
      "Epoch 472/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 11190722.0000 - val_accuracy: 0.0000e+00 - val_loss: 11176416.0000\n",
      "Epoch 473/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.0000e+00 - loss: 3494767.7500 - val_accuracy: 0.0000e+00 - val_loss: 11177231.0000\n",
      "Epoch 474/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 0.0000e+00 - loss: 27151784.0000 - val_accuracy: 0.0000e+00 - val_loss: 11174856.0000\n",
      "Epoch 475/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.0000e+00 - loss: 16962004.0000 - val_accuracy: 0.0000e+00 - val_loss: 11172769.0000\n",
      "Epoch 476/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.0000e+00 - loss: 45374604.0000 - val_accuracy: 0.0000e+00 - val_loss: 11156538.0000\n",
      "Epoch 477/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 67130328.0000 - val_accuracy: 0.0000e+00 - val_loss: 11179555.0000\n",
      "Epoch 478/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.0000e+00 - loss: 19102114.0000 - val_accuracy: 0.0000e+00 - val_loss: 11158502.0000\n",
      "Epoch 479/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.0000e+00 - loss: 15329967.0000 - val_accuracy: 0.0000e+00 - val_loss: 11182553.0000\n",
      "Epoch 480/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.0000e+00 - loss: 6715505.0000 - val_accuracy: 0.0000e+00 - val_loss: 11172695.0000\n",
      "Epoch 481/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 0.0000e+00 - loss: 10492427.0000 - val_accuracy: 0.0000e+00 - val_loss: 11160329.0000\n",
      "Epoch 482/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 5280074.5000 - val_accuracy: 0.0000e+00 - val_loss: 11173960.0000\n",
      "Epoch 483/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.0000e+00 - loss: 24829410.0000 - val_accuracy: 0.0000e+00 - val_loss: 11161682.0000\n",
      "Epoch 484/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.0000e+00 - loss: 48645996.0000 - val_accuracy: 0.0000e+00 - val_loss: 11168644.0000\n",
      "Epoch 485/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0000e+00 - loss: 17095938.0000 - val_accuracy: 0.0000e+00 - val_loss: 11171037.0000\n",
      "Epoch 486/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 24688642.0000 - val_accuracy: 0.0000e+00 - val_loss: 11164028.0000\n",
      "Epoch 487/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.0000e+00 - loss: 10029958.0000 - val_accuracy: 0.0000e+00 - val_loss: 11181564.0000\n",
      "Epoch 488/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.0000e+00 - loss: 20959858.0000 - val_accuracy: 0.0000e+00 - val_loss: 11157138.0000\n",
      "Epoch 489/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.0000e+00 - loss: 9642223.0000 - val_accuracy: 0.0000e+00 - val_loss: 11184985.0000\n",
      "Epoch 490/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.0000e+00 - loss: 22391814.0000 - val_accuracy: 0.0000e+00 - val_loss: 11179643.0000\n",
      "Epoch 491/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.0000e+00 - loss: 13311738.0000 - val_accuracy: 0.0000e+00 - val_loss: 11156113.0000\n",
      "Epoch 492/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 0.0000e+00 - loss: 27545718.0000 - val_accuracy: 0.0000e+00 - val_loss: 11170424.0000\n",
      "Epoch 493/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.0000e+00 - loss: 13610269.0000 - val_accuracy: 0.0000e+00 - val_loss: 11175653.0000\n",
      "Epoch 494/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.0000e+00 - loss: 6989575.5000 - val_accuracy: 0.0000e+00 - val_loss: 11176142.0000\n",
      "Epoch 495/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 62943380.0000 - val_accuracy: 0.0000e+00 - val_loss: 11167741.0000\n",
      "Epoch 496/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.0000e+00 - loss: 36389712.0000 - val_accuracy: 0.0000e+00 - val_loss: 11148810.0000\n",
      "Epoch 497/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.0000e+00 - loss: 23466896.0000 - val_accuracy: 0.0000e+00 - val_loss: 11166778.0000\n",
      "Epoch 498/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.0000e+00 - loss: 9073273.0000 - val_accuracy: 0.0000e+00 - val_loss: 11162564.0000\n",
      "Epoch 499/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.0000e+00 - loss: 47263824.0000 - val_accuracy: 0.0000e+00 - val_loss: 11167402.0000\n",
      "Epoch 500/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0000e+00 - loss: 28896272.0000 - val_accuracy: 0.0000e+00 - val_loss: 11165099.0000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step\n",
      "Metrics:\n",
      "Accuracy: 0.0105\n",
      "MSE: 11165097.1721773\n",
      "MAE: 232.69318606265873\n",
      "RMSE: 3341.4214298973575\n",
      "F1 Score: 0.012500000000000002\n",
      "Training Time: 235.31267929077148\n",
      "Inference Time: 0.124267578125\n",
      "Model type: multi_layer_perceptron\n",
      "dataset: integration_with_tan_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"integration_with_tan_dataset\"\n",
    "d_set = pd.read_csv('./../../Data/'+dataset_name+'.csv')\n",
    "dset_features = d_set.copy()\n",
    "dset_labels = dset_features.pop('result')\n",
    "dset_features = np.array(dset_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset_features, dset_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configure the model with multiple layers\n",
    "#layers_config = [(32, 'dense'), (0.2, 'dropout'), ('relu', 'activation')]\n",
    "#perceptron_config = [(1, 'dense')]\n",
    "mlp_config = [\n",
    "    ('dense', 64, 'linear', 'input', dset_features.shape[1]),\n",
    "    ('dense', 32, 'selu'),\n",
    "    ('dense', 1, 'linear')\n",
    "]\n",
    "\n",
    "model = configure_model(mlp_config, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'],debugflag=False)\n",
    "\n",
    "# Train the model\n",
    "model, history, predictions, training_time = train_model(model, X_train, y_train, X_test, y_test,total_epoch=500,model_name='multi_layer_perceptron',dataset_name=dataset_name)\n",
    "\n",
    "# Test the model\n",
    "test_metrics = test_model(model, X_test, y_test,model_name='multi_layer_perceptron',dataset_name=dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
